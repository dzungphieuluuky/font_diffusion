{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":127.636509,"end_time":"2025-12-30T18:55:25.961447","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-30T18:53:18.324938","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a95a46ef","cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git","metadata":{"id":"a95a46ef","outputId":"d76d28cd-6292-42bf-fffa-a8c7efb86ed0","papermill":{"duration":12.857369,"end_time":"2025-12-30T18:53:35.066181","exception":false,"start_time":"2025-12-30T18:53:22.208812","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-01T18:49:51.933417Z","iopub.execute_input":"2026-01-01T18:49:51.934424Z","iopub.status.idle":"2026-01-01T18:50:03.471627Z","shell.execute_reply.started":"2026-01-01T18:49:51.934372Z","shell.execute_reply":"2026-01-01T18:50:03.470920Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'FontDiffusion'...\nremote: Enumerating objects: 20573, done.\u001b[K\nremote: Counting objects: 100% (147/147), done.\u001b[K\nremote: Compressing objects: 100% (105/105), done.\u001b[K\nremote: Total 20573 (delta 91), reused 91 (delta 42), pack-reused 20426 (from 2)\u001b[K\nReceiving objects: 100% (20573/20573), 277.72 MiB | 39.46 MiB/s, done.\nResolving deltas: 100% (937/937), done.\nUpdating files: 100% (139/139), done.\n","output_type":"stream"}],"execution_count":8},{"id":"9cdd8666","cell_type":"code","source":"import os\nimport sys\nfrom IPython import get_ipython\nfrom typing import Optional\n\ndef configure_environment_paths():\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"‚úÖ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"‚úÖ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"üìÇ Data Path: {base_data_path}\")\n    print(f\"üì¶ Output Path: {base_output_path}\")\n    return base_data_path, base_output_path, environment_name\n\ndef load_secret(key_name: str) -> Optional[str]:\n    env = ENV_NAME\n    secret_value = None\n    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n    try:\n        if env == \"colab\":\n            from google.colab import userdata\n            secret_value = userdata.get(key_name)\n        elif env == \"kaggle\":\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            secret_value = user_secrets.get_secret(key_name)\n        else:\n            secret_value = os.getenv(key_name)\n        if not secret_value:\n            print(f\"‚ö†Ô∏è Secret '{key_name}' not found in the {env} environment.\")\n            return None\n        print(f\"‚úÖ Successfully loaded secret '{key_name}'.\")\n        return secret_value\n    except Exception as e:\n        print(f\"‚ùå An error occurred while loading secret '{key_name}': {e}\")\n        return None\n\ndef print_system_info():\n    print(\"\\nüîß System Information\")\n    print(f\"Python version: {sys.version.split()[0]}\")\n    try:\n        import torch\n        print(f\"PyTorch version: {torch.__version__}\")\n        if torch.cuda.is_available():\n            print(f\"CUDA version: {torch.version.cuda}\")\n            print(f\"GPU count: {torch.cuda.device_count()}\")\n            for i in range(torch.cuda.device_count()):\n                print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        else:\n            print(\"CUDA not available\")\n    except ImportError:\n        print(\"PyTorch not installed\")\n    finally:\n      !nvidia-smi\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\nis_kaggle = (\"kaggle\" in ENV_NAME)\nis_colab = not is_kaggle\nprint_system_info()\n\nos.environ[\"WANDB_API_KEY\"] = wandb_key = load_secret(\"WANDB_API_KEY\")\nos.environ[\"HF_TOKEN\"] = HF_TOKEN = load_secret('HF_TOKEN')\n\n# Now, these libraries will log in automatically\nimport wandb\nimport huggingface_hub\n\nwandb.login() \nhuggingface_hub.login(token=os.environ[\"HF_TOKEN\"]) ","metadata":{"id":"9cdd8666","outputId":"8834f4e4-fc28-455c-a66c-d15b00de080a","papermill":{"duration":0.019157,"end_time":"2025-12-30T18:53:35.092303","exception":false,"start_time":"2025-12-30T18:53:35.073146","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-01T18:38:14.198246Z","iopub.execute_input":"2026-01-01T18:38:14.198816Z","iopub.status.idle":"2026-01-01T18:38:27.931515Z","shell.execute_reply.started":"2026-01-01T18:38:14.198782Z","shell.execute_reply":"2026-01-01T18:38:27.930927Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Environment: Kaggle\nüìÇ Data Path: /kaggle/input/\nüì¶ Output Path: /kaggle/working/\n\nüîß System Information\nPython version: 3.11.13\nPyTorch version: 2.6.0+cu124\nCUDA version: 12.4\nGPU count: 2\n  GPU 0: Tesla T4\n  GPU 1: Tesla T4\nThu Jan  1 18:38:17 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   37C    P8             11W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   37C    P8             10W /   70W |       3MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nAttempting to load secret 'WANDB_API_KEY' from 'kaggle' environment...\n‚úÖ Successfully loaded secret 'WANDB_API_KEY'.\nAttempting to load secret 'HF_TOKEN' from 'kaggle' environment...\n‚úÖ Successfully loaded secret 'HF_TOKEN'.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\nNote: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","output_type":"stream"}],"execution_count":2},{"id":"a73b4150","cell_type":"code","source":"!uv pip install --upgrade pip\n# 3. Install PyTorch 1.13\n%cd {OUTPUT_PATH}\n# Force reinstall torch 1.13 to match the model's training environment\n# !uv pip uninstall torch torchvision\n# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n!uv pip install torch==2.9 torchvision\n# 4. Install other dependencies\n\nprint(\"\\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n!sudo apt-get update && sudo apt-get install dos2unix\n!uv pip install gdown tqdm\n!uv pip install wandb\n!uv pip install --upgrade pyarrow datasets\nprint(\"\\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"id":"a73b4150","outputId":"97db2cec-8e2d-438b-e5f8-38df08b7f59e","papermill":{"duration":61.239828,"end_time":"2025-12-30T18:54:36.338205","exception":false,"start_time":"2025-12-30T18:53:35.098377","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-01T18:38:27.932837Z","iopub.execute_input":"2026-01-01T18:38:27.933177Z","iopub.status.idle":"2026-01-01T18:40:05.726910Z","shell.execute_reply.started":"2026-01-01T18:38:27.933156Z","shell.execute_reply":"2026-01-01T18:40:05.726136Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 123ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 98ms\u001b[0m\u001b[0m                                               \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 123ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 15ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n/kaggle/working\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m40 packages\u001b[0m \u001b[2min 346ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m19 packages\u001b[0m \u001b[2min 34.75s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m17 packages\u001b[0m \u001b[2min 924ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m19 packages\u001b[0m \u001b[2min 272ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\n  \u001b[31m√ó\u001b[0m Failed to build `xformers==0.0.16`\n\u001b[31m  ‚îú‚îÄ‚ñ∂ \u001b[0mThe build backend returned an error\n\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n\u001b[31m      \u001b[0mstatus: 1)\n\n\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n\u001b[31m      \u001b[0mError in sitecustomize; set PYTHONVERBOSE for traceback:\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'wrapt'\n\u001b[31m      \u001b[0mTraceback (most recent call last):\n\u001b[31m      \u001b[0m  File \"<string>\", line 14, in <module>\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmp6C8j9N/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 331, in get_requires_for_build_wheel\n\u001b[31m      \u001b[0m    return self._get_build_requires(config_settings, requirements=[])\n\u001b[31m      \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmp6C8j9N/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 301, in _get_build_requires\n\u001b[31m      \u001b[0m    self.run_setup()\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmp6C8j9N/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 512, in run_setup\n\u001b[31m      \u001b[0m    super().run_setup(setup_script=setup_script)\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmp6C8j9N/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 317, in run_setup\n\u001b[31m      \u001b[0m    exec(code, locals())\n\u001b[31m      \u001b[0m  File \"<string>\", line 23, in <module>\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'torch'\n\n\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This error likely indicates that `\u001b[36mxformers@0.0.16\u001b[39m` depends\n\u001b[31m      \u001b[0mon `\u001b[36mtorch\u001b[39m`, but doesn't declare it as a build dependency. If\n\u001b[31m      \u001b[0m`\u001b[36mxformers\u001b[39m` is a first-party package, consider adding `\u001b[36mtorch\u001b[39m` to its\n\u001b[31m      \u001b[0m`\u001b[32mbuild-system.requires\u001b[39m`. Otherwise, `\u001b[32muv pip install torch\u001b[39m` into the\n\u001b[31m      \u001b[0menvironment and re-run with `\u001b[32m--no-build-isolation\u001b[39m`.\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m58 packages\u001b[0m \u001b[2min 174ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 394ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m4 packages\u001b[0m \u001b[2min 494ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 40ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.9.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==0.23.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.34.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.13.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.53.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.33.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m102 packages\u001b[0m \u001b[2min 326ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m8 packages\u001b[0m \u001b[2min 1.20s\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m7 packages\u001b[0m \u001b[2min 371ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m8 packages\u001b[0m \u001b[2min 77ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.38.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==0.7.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minfo-nce-pytorch\u001b[0m\u001b[2m==0.1.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==11.0.3\u001b[0m\n\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `typer==0.16.0` does not have an extra named `all`\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m49 packages\u001b[0m \u001b[2min 113ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m2 packages\u001b[0m \u001b[2min 18ms\u001b[0m\u001b[0m                                              \n\u001b[2K\u001b[2mInstalled \u001b[1m2 packages\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpytorch-fid\u001b[0m\u001b[2m==0.3.0\u001b[0m\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nGet:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\nGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\nGet:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \nHit:7 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB] \nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nHit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nGet:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\nGet:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,573 kB] \nGet:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\nGet:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\nGet:23 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\nGet:24 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\nFetched 38.5 MB in 9s (4,291 kB/s)                                             \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  dos2unix\n0 upgraded, 1 newly installed, 0 to remove and 192 not upgraded.\nNeed to get 384 kB of archives.\nAfter this operation, 1,367 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dos2unix amd64 7.4.2-2 [384 kB]\nFetched 384 kB in 0s (812 kB/s)  \ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\ndebconf: falling back to frontend: Readline\nSelecting previously unselected package dos2unix.\n(Reading database ... 128639 files and directories currently installed.)\nPreparing to unpack .../dos2unix_7.4.2-2_amd64.deb ...\nUnpacking dos2unix (7.4.2-2) ...\nSetting up dos2unix (7.4.2-2) ...\nProcessing triggers for man-db (2.10.2-1) ...\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 102ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 174ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 386ms\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m12 packages\u001b[0m \u001b[2min 315ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 12.96s\u001b[0m\u001b[0m                             \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==19.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\n","output_type":"stream"}],"execution_count":3},{"id":"bd517dfe","cell_type":"code","source":"# KAGGLE CELL #1: Download checkpoint\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\nimport os\nimport sys\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nos.chdir(OUTPUT_PATH)\n# Download from Hub\nif not os.path.exists(\"ckpt\") or not list(Path(\"ckpt\").glob(\"*.safetensors\")):\n    print(\"üì• Downloading checkpoint from Hugging Face Hub...\\n\")\n    from huggingface_hub import snapshot_download\n    snapshot_download(\n        repo_id=\"dzungpham/font-diffusion-weights\",\n        local_dir=\"ckpt\",\n        allow_patterns=\"*.safetensors\",\n        force_download=False\n    )\n    print(\"\\n‚úÖ Download complete!\")\nelse:\n    print(\"‚úÖ Checkpoint already downloaded\")\n# Verify\nprint(\"\\nüìÇ Files in ckpt/:\")\nfor file in os.listdir(\"ckpt\"):\n    if file.endswith(\".safetensors\"):\n        size = os.path.getsize(f\"ckpt/{file}\") / (1024**2)\n        print(f\"  ‚úì {file} ({size:.2f} MB)\")","metadata":{"id":"bd517dfe","outputId":"d83605e9-f5dc-4862-d1c9-b138a96ca47a","papermill":{"duration":12.524295,"end_time":"2025-12-30T18:54:48.878013","exception":false,"start_time":"2025-12-30T18:54:36.353718","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-01T18:40:09.807909Z","iopub.execute_input":"2026-01-01T18:40:09.808213Z","iopub.status.idle":"2026-01-01T18:40:15.655134Z","shell.execute_reply.started":"2026-01-01T18:40:09.808183Z","shell.execute_reply":"2026-01-01T18:40:15.654122Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m14 packages\u001b[0m \u001b[2min 102ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m4 packages\u001b[0m \u001b[2min 371ms\u001b[0m\u001b[0m                                             \n\u001b[2mUninstalled \u001b[1m4 packages\u001b[0m \u001b[2min 33ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 23ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.25.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==6.33.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==4.25.8\u001b[0m\nüì• Downloading checkpoint from Hugging Face Hub...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18559b0ead144f42b9946aa06b95f9dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"style_encoder.safetensors:   0%|          | 0.00/82.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af3de26b205a45aca395b21663f6fdfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"content_encoder.safetensors:   0%|          | 0.00/4.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1518a95575c24a8bb00d8f89fd2116ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"unet.safetensors:   0%|          | 0.00/315M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a21c4a7d2ee245799e4cd95683bd746b"}},"metadata":{}},{"name":"stdout","text":"\n‚úÖ Download complete!\n\nüìÇ Files in ckpt/:\n  ‚úì content_encoder.safetensors (4.54 MB)\n  ‚úì unet.safetensors (300.34 MB)\n  ‚úì style_encoder.safetensors (78.58 MB)\n","output_type":"stream"}],"execution_count":4},{"id":"767e8ea2","cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"id":"767e8ea2","outputId":"20185e27-e772-4823-e6bc-d9bd6d0b39a1","papermill":{"duration":0.023805,"end_time":"2025-12-30T18:54:48.917163","exception":false,"start_time":"2025-12-30T18:54:48.893358","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"51941368","cell_type":"code","source":"import pandas as pd\nimport os\ndef convert_csv_to_chars_txt(input_csv_path: str, output_txt_path: str, column_name: str = 'word'):\n    \"\"\"\n    Reads a CSV file, extracts text from a specified column, and writes each character\n    to a new line in a plain text file.\n    Args:\n        input_csv_path (str): The full path to the input CSV file.\n        output_txt_path (str): The full path for the output text file.\n        column_name (str): The name of the column in the CSV file containing the text.\n    \"\"\"\n    if not os.path.exists(input_csv_path):\n        print(f\"Error: Input CSV file not found at '{input_csv_path}'. Please ensure the file is uploaded.\")\n        return\n    try:\n        df = pd.read_csv(input_csv_path)\n    except Exception as e:\n        print(f\"Error reading CSV file '{input_csv_path}': {e}\")\n        return\n    if column_name not in df.columns:\n        print(f\"Error: Column '{column_name}' not found in the CSV file '{input_csv_path}'.\")\n        return\n    all_characters = []\n    for item in df[column_name].astype(str).dropna().tolist():\n        for char in item:\n            all_characters.append(char)\n    os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)\n    with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(all_characters))\n    print(f\"Successfully converted '{input_csv_path}' to '{output_txt_path}', with one character per line.\")\nprint(\"\\n--- Demonstrating function with a dummy CSV file ---\")\ndummy_csv_path = os.path.join(OUTPUT_PATH, \"dummy_data.csv\")\ndummy_output_txt_path = os.path.join(OUTPUT_PATH, \"dummy_chars.txt\")\ndummy_data = {'word': ['hello', 'world', 'python']}\npd.DataFrame(dummy_data).to_csv(dummy_csv_path, index=False)\nprint(f\"Created a dummy CSV file at: {dummy_csv_path}\")\nconvert_csv_to_chars_txt(dummy_csv_path, dummy_output_txt_path)","metadata":{"id":"51941368","outputId":"2a2c352c-968a-4e4d-b4cc-88a02c7eb788","papermill":{"duration":1.62157,"end_time":"2025-12-30T18:54:50.594793","exception":false,"start_time":"2025-12-30T18:54:48.973223","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"4f4cf20b","cell_type":"code","source":"print(\"Model files:\")\n!ls -larth {OUTPUT_PATH}/ckpt","metadata":{"id":"4f4cf20b","outputId":"335f4192-47e7-451a-e14f-e0bd69fbdfc9","papermill":{"duration":0.140282,"end_time":"2025-12-30T18:54:50.749810","exception":false,"start_time":"2025-12-30T18:54:50.609528","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"92cff682","cell_type":"code","source":"%cd {OUTPUT_PATH}\n# ==========================================\n# EXPORT / DOWNLOAD DATASET COMMANDS\n# ==========================================\nHF_USERNAME = \"dzungpham\"\n# Train Split\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train_original\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token HF_TOKEN\n\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token HF_TOKEN\n# Validation: Unseen Both\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token HF_TOKEN","metadata":{"id":"92cff682","papermill":{"duration":0.104394,"end_time":"2025-12-30T18:54:50.869230","exception":false,"start_time":"2025-12-30T18:54:50.764836","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T18:40:20.772812Z","iopub.execute_input":"2026-01-01T18:40:20.773375Z","iopub.status.idle":"2026-01-01T18:41:29.849755Z","shell.execute_reply.started":"2026-01-01T18:40:20.773345Z","shell.execute_reply":"2026-01-01T18:41:29.848971Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nüì• Loading dataset from Hub...\n   Repository: dzungpham/font-diffusion-generated-data\n   Split: train_original\nREADME.md: 3.05kB [00:00, 9.54MB/s]\ntrain_original-00000-of-00001.parquet: 100%|‚ñà| 117M/117M [00:07<00:00, 16.2MB/s]\ntrain-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77.1M/77.1M [00:05<00:00, 15.0MB/s]\nval-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.65M/3.65M [00:00<00:00, 29.6MB/s]\nGenerating train_original split: 100%|‚ñà| 8985/8985 [00:00<00:00, 30072.92 exampl\nGenerating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 5760/5760 [00:00<00:00, 30615.67 examples/s]\nGenerating val split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 357/357 [00:00<00:00, 35887.42 examples/s]\n‚úì Loaded dataset with 8985 samples from Hub\n\nExporting images from dataset...\n\nüé® Exporting images...\nExporting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8985/8985 [00:20<00:00, 435.80it/s]\n‚úì Exported 599 content images\n‚úì Exported 8985 target images\n\nüíæ Saving results_checkpoint.json...\n  ‚úì Saved results_checkpoint.json (8985 generations)\n\nüìä Metadata Statistics:\n  Total generations: 8985\n  Total characters: 599\n  Total styles: 15\n  Fonts: NomNaTong-Regular\n\n============================================================\n‚úÖ EXPORT COMPLETE!\n============================================================\n\nFiles created:\n  ‚úì my_dataset/train_original/ContentImage/\n  ‚úì my_dataset/train_original/TargetImage/\n  ‚úì my_dataset/train_original/results_checkpoint.json\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nüì• Loading dataset from Hub...\n   Repository: dzungpham/font-diffusion-generated-data\n   Split: train\n‚úì Loaded dataset with 5760 samples from Hub\n\nExporting images from dataset...\n\nüé® Exporting images...\nExporting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5760/5760 [00:13<00:00, 428.29it/s]\n‚úì Exported 480 content images\n‚úì Exported 5760 target images\n\nüíæ Saving results_checkpoint.json...\n  ‚úì Saved results_checkpoint.json (5760 generations)\n\nüìä Metadata Statistics:\n  Total generations: 5760\n  Total characters: 480\n  Total styles: 12\n  Fonts: NomNaTong-Regular\n\n============================================================\n‚úÖ EXPORT COMPLETE!\n============================================================\n\nFiles created:\n  ‚úì my_dataset/train/ContentImage/\n  ‚úì my_dataset/train/TargetImage/\n  ‚úì my_dataset/train/results_checkpoint.json\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nüì• Loading dataset from Hub...\n   Repository: dzungpham/font-diffusion-generated-data\n   Split: val\n‚úì Loaded dataset with 357 samples from Hub\n\nExporting images from dataset...\n\nüé® Exporting images...\nExporting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 357/357 [00:00<00:00, 388.06it/s]\n‚úì Exported 119 content images\n‚úì Exported 357 target images\n\nüíæ Saving results_checkpoint.json...\n  ‚úì Saved results_checkpoint.json (357 generations)\n\nüìä Metadata Statistics:\n  Total generations: 357\n  Total characters: 119\n  Total styles: 3\n  Fonts: NomNaTong-Regular\n\n============================================================\n‚úÖ EXPORT COMPLETE!\n============================================================\n\nFiles created:\n  ‚úì my_dataset/val/ContentImage/\n  ‚úì my_dataset/val/TargetImage/\n  ‚úì my_dataset/val/results_checkpoint.json\n","output_type":"stream"}],"execution_count":5},{"id":"6db9c1d6-dd60-479c-92c4-2f653e4d48fd","cell_type":"code","source":"print(\"Fonts currently in fonts/ folder\")\n!ls -lt FontDiffusion/fonts\nprint(\"Styles in style_images/ folder\")\n!ls -l FontDiffusion/styles_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T18:41:29.851361Z","iopub.execute_input":"2026-01-01T18:41:29.851629Z","iopub.status.idle":"2026-01-01T18:41:30.104833Z","shell.execute_reply.started":"2026-01-01T18:41:29.851588Z","shell.execute_reply":"2026-01-01T18:41:30.104168Z"}},"outputs":[{"name":"stdout","text":"Fonts currently in fonts/ folder\ntotal 332584\n-rw-r--r-- 1 root root 26929728 Jan  1 18:37  NomNaTongLight2.ttf\n-rw-r--r-- 1 root root 14574480 Jan  1 18:37  NomNaTongLight.ttf\n-rw-r--r-- 1 root root 31729820 Jan  1 18:37  NomNaTong-Regular2.otf\n-rw-r--r-- 1 root root 14574552 Jan  1 18:37  NomNaTong-Regular.ttf\n-rw-r--r-- 1 root root  9424552 Jan  1 18:37  NomNaTong-Regular.otf\n-rw-r--r-- 1 root root 12967288 Jan  1 18:37  HanaMinC.otf\n-rw-r--r-- 1 root root 30739236 Jan  1 18:37  HanaMinB.ttf\n-rw-r--r-- 1 root root 32201032 Jan  1 18:37  HanaMinB.otf\n-rw-r--r-- 1 root root 22761228 Jan  1 18:37  HanaMinA.ttf\n-rw-r--r-- 1 root root 31621108 Jan  1 18:37  HanaMinA.otf\n-rw-r--r-- 1 root root 18202176 Jan  1 18:37 'Han-nom Minh 1.42.otf'\n-rw-r--r-- 1 root root 19505228 Jan  1 18:37  Han-Nom-Khai-Regular-300623.ttf\n-rw-r--r-- 1 root root 20368044 Jan  1 18:37 'Han-Nom Kai 1.00.otf'\n-rw-r--r-- 1 root root 33815824 Jan  1 18:37 'HAN NOM B.ttf'\n-rw-r--r-- 1 root root 21320444 Jan  1 18:37 'HAN NOM A.ttf'\nStyles in style_images/ folder\ntotal 520\n-rw-r--r-- 1 root root  55480 Jan  1 18:37 1.png\n-rw-r--r-- 1 root root  73193 Jan  1 18:37 2.png\n-rw-r--r-- 1 root root  62305 Jan  1 18:37 3.png\n-rw-r--r-- 1 root root  47202 Jan  1 18:37 4.png\n-rw-r--r-- 1 root root  40943 Jan  1 18:37 5.png\n-rw-r--r-- 1 root root  11400 Jan  1 18:37 6.png\n-rw-r--r-- 1 root root  26508 Jan  1 18:37 hanh.png\n-rw-r--r-- 1 root root   1569 Jan  1 18:37 hanhthu1.jpg\n-rw-r--r-- 1 root root   1036 Jan  1 18:37 hanhthu2.jpg\n-rw-r--r-- 1 root root 100710 Jan  1 18:37 khai.png\n-rw-r--r-- 1 root root  36429 Jan  1 18:37 le.png\n-rw-r--r-- 1 root root   1086 Jan  1 18:37 lethu1.jpg\n-rw-r--r-- 1 root root   1182 Jan  1 18:37 lethu2.jpg\n-rw-r--r-- 1 root root  17600 Jan  1 18:37 thao.png\n-rw-r--r-- 1 root root  27078 Jan  1 18:37 trien.png\n","output_type":"stream"}],"execution_count":6},{"id":"eb05a6b7-6003-4377-bbd2-103bff55303b","cell_type":"code","source":"import json\nfrom pathlib import Path\nfrom typing import Set\n\ndef remove_unparseable_from_checkpoint(checkpoint_path: str, unparseable_txt_path: str) -> None:\n    \"\"\"\n    Removes generations referencing unparseable files from a results_checkpoint.json file.\n\n    Args:\n        checkpoint_path (str): Path to results_checkpoint.json.\n        unparseable_txt_path (str): Path to unparseable_files.txt (absolute paths, one per line).\n    \"\"\"\n    # Load unparseable file names into a set\n    with open(unparseable_txt_path, \"r\", encoding=\"utf-8\") as f:\n        unparseable_files: Set[str] = {Path(line.strip()).name for line in f if line.strip()}\n\n    # Load checkpoint JSON\n    with open(checkpoint_path, \"r\", encoding=\"utf-8\") as f:\n        results = json.load(f)\n\n    generations = results.get(\"generations\", [])\n    original_count = len(generations)\n\n    # Filter out generations whose target_image_path's filename is in unparseable_files\n    filtered_generations = [\n        gen for gen in generations\n        if os.path.join(\"kaggle/working/my_dataset/train_original\", gen.get(\"target_image_path\", \"\")) not in unparseable_files\n    ]\n\n    removed_count = original_count - len(filtered_generations)\n    results[\"generations\"] = filtered_generations\n\n    # Save updated checkpoint\n    with open(checkpoint_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(results, f, indent=2, ensure_ascii=False)\n\n    print(f\"Removed {removed_count} generations from {checkpoint_path}.\")\n\n# Example usage:\nremove_unparseable_from_checkpoint(\n    \"my_dataset/train_original/results_checkpoint.json\",\n    \"my_dataset/unparseable_files.txt\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b32b36ce-f246-4f86-b9f1-2ac844c7bec8","cell_type":"code","source":"!cat my_dataset/unparseable_files.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"29deed1d","cell_type":"code","source":"if is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\n%cd {OUTPUT_PATH}\n!accelerate launch --num_processes 1 \\\n    FontDiffusion/sample_batch.py \\\n    --characters \"FontDiffusion/NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --style_images \"FontDiffusion/styles_images\" \\\n    --ckpt_dir \"ckpt/\" \\\n    --ttf_path \"FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n    --output_dir \"my_dataset/train_original\" \\\n    --num_inference_steps 20 \\\n    --guidance_scale 7.5 \\\n    --start_line 1 \\\n    --end_line 500 \\\n    --batch_size 35 \\\n    --save_interval 1 \\\n    --channels_last \\\n    --seed 42 \\\n    --compile \\\n    --enable_xformers\n\nimport logging\nlogging.info(\"Updating Dataset after generation...\")\nHF_USERNAME = \"dzungpham\"\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train_original\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token {HF_TOKEN}\n","metadata":{"id":"29deed1d","outputId":"749b50d0-75e3-4d36-e509-919188feb64c","papermill":{"duration":10.53661,"end_time":"2025-12-30T18:55:01.421093","exception":false,"start_time":"2025-12-30T18:54:50.884483","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"997103e5-221c-40a1-a0d1-83a93e1030f7","cell_type":"code","source":"!find my_dataset/train_original/ContentImage -type f | wc -l\n!find my_dataset/train_original/TargetImage -type f | wc -l","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"619d3b79-f33c-41c6-be25-e80b2c1165a5","cell_type":"code","source":"# !ls -lt my_dataset/train_original/ContentImage/*3594*\n!ls -l my_dataset/train_original/TargetImage/*1*\n# !ls -lt my_dataset/train_original/TargetImage/*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"97c4a6a0-dba9-46be-b6df-d79cce0df689","cell_type":"code","source":"import re\nfrom pathlib import Path\n\n# Your valid pattern\nexpected_pattern = r\"U\\+[0-9A-F]{4,5}.*_[0-9a-f]{8}\\.png\"\n\n# Define the root directory ('.' for current directory)\nroot_dir = Path('./my_dataset/train_original/TargetImage')\n\n# .rglob('*') finds every file recursively\nfor path in root_dir.rglob('*'):\n    # Process only files (ignore directories)\n    if path.is_file():\n        # Check if the FILENAME (path.name) matches the regex\n        if not re.match(expected_pattern, path.name):\n            try:\n                print(f\"Deleting invalid file: {path}\")\n                # path.unlink() # This deletes the file\n            except Exception as e:\n                print(f\"Error deleting {path}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9250a14","cell_type":"code","source":"!python FontDiffusion/create_validation_split.py \\\n  --data_root my_dataset \\\n  --val_ratio 0.2 \\\n  --seed 42","metadata":{"id":"f9250a14","outputId":"0f834d09-da00-4aa4-f486-6e70981b4137","papermill":{"duration":0.236541,"end_time":"2025-12-30T18:55:01.673705","exception":false,"start_time":"2025-12-30T18:55:01.437164","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"79508d80-fac1-4318-9174-a32613a557e3","cell_type":"code","source":"!uv pip install --upgrade pyarrow datasets","metadata":{"trusted":true,"id":"79508d80-fac1-4318-9174-a32613a557e3"},"outputs":[],"execution_count":null},{"id":"48f97e84-cd8c-49a9-86bd-fce456be56a4","cell_type":"code","source":"# remove_unparseable_files.py\n\nwith open(\"my_dataset/unparseable_files.txt\", \"r\", encoding=\"utf-8\") as f:\n    paths = [line.strip() for line in f if line.strip()]\n\nimport os\n\nfor path in paths:\n    try:\n        if os.path.exists(path):\n            os.remove(path)\n            print(f\"Deleted: {path}\")\n        else:\n            print(f\"Not found: {path}\")\n    except Exception as e:\n        print(f\"Error deleting {path}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"vRL8QovYCvLY","cell_type":"code","source":"HF_USERNAME = \"dzungpham\"\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train_original\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/val\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token {HF_TOKEN}\n","metadata":{"id":"vRL8QovYCvLY","outputId":"08301c52-4ae1-4268-c516-2ff8bd834783","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"outputs":[],"execution_count":null},{"id":"a87caab2","cell_type":"code","source":"import torch, gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"a87caab2","papermill":{"duration":1.992585,"end_time":"2025-12-30T18:55:24.769269","exception":false,"start_time":"2025-12-30T18:55:22.776684","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"eb81a2db-1f85-4801-a96e-f0bda7f3f315","cell_type":"code","source":"!cp -r my_dataset/train_original/ my_dataset/train/\n!ls -l my_dataset/train/*/*/*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"267634e8","cell_type":"code","source":"# TRAINING PHASE 1\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\nimport wandb\n# Run the training script with the corrected flag syntax\n!accelerate launch FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=FontDiffuser_training_phase_1 \\\n    --phase_1_ckpt_dir=\"ckpt\" \\\n    --data_root=my_dataset \\\n    --output_dir=outputs/FontDiffuser \\\n    --report_to=wandb \\\n    \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --gradient_accumulation_steps=1 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.7 \\\n    \\\n    --max_train_steps=200 \\\n    --ckpt_interval=100 \\\n    --val_interval=100 \\\n    --log_interval=50 \\\n    \\\n    --learning_rate=1e-4 \\\n    --lr_scheduler=linear \\\n    --lr_warmup_steps=10000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=no","metadata":{"id":"267634e8","papermill":{"duration":0.021927,"end_time":"2025-12-30T18:55:24.807644","exception":false,"start_time":"2025-12-30T18:55:24.785717","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-01T18:50:08.998809Z","iopub.execute_input":"2026-01-01T18:50:08.999570Z","iopub.status.idle":"2026-01-01T18:50:35.291761Z","shell.execute_reply.started":"2026-01-01T18:50:08.999539Z","shell.execute_reply":"2026-01-01T18:50:35.291015Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 48ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.12ms\u001b[0m\u001b[0m\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-01 18:50:18.752214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2026-01-01 18:50:18.752245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767293418.774418    1304 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767293418.774542    1305 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767293418.782115    1304 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1767293418.782133    1305 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n\nüìÇ Discovering images from filesystem...\n============================================================\n\n======================================================================\nüîß IMAGE DISCOVERY DIAGNOSTICS\n======================================================================\n\nüìÅ Content Directory: my_dataset/train/ContentImage\n   Exists: True\n   Is directory: True\n   Absolute path: /kaggle/working/my_dataset/train/ContentImage\n   Items: 480\n   PNG files: 480\n   Sample files:\n\nüìÇ Discovering images from filesystem...\n============================================================\n     - U+20027_†Äß_34fa3964.png\n======================================================================\n\n     - U+20051_†Åë_b1a447cc.png\nüîß IMAGE DISCOVERY DIAGNOSTICS     - U+20078_†Å∏_fa17ec97.png\n\n     - U+200C5_†ÉÖ_8d88a9c3.png\n======================================================================     - U+200E3_†É£_84f62611.png\n\n\nüìÅ Target Directory: my_dataset/train/TargetImage\nüìÅ Content Directory: my_dataset/train/ContentImage\n\n   Exists: True   Exists: True\n\n   Is directory: True   Is directory: True\n\n   Absolute path: /kaggle/working/my_dataset/train/TargetImage   Absolute path: /kaggle/working/my_dataset/train/ContentImage\n\n   Style directories: 12\n   Items: 480\n   PNG files: 480\n   Sample files:\n     - U+20027_†Äß_34fa3964.png\n     - U+20051_†Åë_b1a447cc.png\n     - U+20078_†Å∏_fa17ec97.png\n     - 1: 480 images     - U+200C5_†ÉÖ_8d88a9c3.png\n\n     - U+200E3_†É£_84f62611.png\n\nüìÅ Target Directory: my_dataset/train/TargetImage\n   Exists: True\n   Is directory: True\n   Absolute path: /kaggle/working/my_dataset/train/TargetImage\n   Style directories: 12\n     - 2: 480 images\n     - 1: 480 images\n     - 2: 480 images\n     - 3: 480 images\n     - 3: 480 images\n     - 4: 480 images\n     - 4: 480 images\n     - 5: 480 images\n======================================================================\n\n\nüîç Discovering content images from my_dataset/train/ContentImage...\n     - 5: 480 images\n======================================================================\n   Full path: /kaggle/working/my_dataset/train/ContentImage\n\n\nüîç Discovering content images from my_dataset/train/ContentImage...\n   Full path: /kaggle/working/my_dataset/train/ContentImage\n  üìä Found 480 PNG files, parsing...\n  üìä Found 480 PNG files, parsing...\n  Scanning content: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 480/480 [00:00<00:00, 399536.80file/s]\n  ‚úì Found 480 valid content images\n    Sample characters: ['„ñî (U+3594)', '„ñ° (U+35A1)', '„ñ´ (U+35AB)', '„òá (U+3607)', '„ô¥ (U+3674)']\n\nüîç Discovering target images from my_dataset/train/TargetImage...\n   Full path: /kaggle/working/my_dataset/train/TargetImage\n  Scanning content: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 480/480 [00:00<00:00, 352031.11file/s]\n  ‚úì Found 480 valid content images\n  üìä Found 12 style directories\n    Sample characters: ['„ñî (U+3594)', '„ñ° (U+35A1)', '„ñ´ (U+35AB)', '„òá (U+3607)', '„ô¥ (U+3674)']\n\nüîç Discovering target images from my_dataset/train/TargetImage...\n   Full path: /kaggle/working/my_dataset/train/TargetImage\n  Scanning styles:   0%|                                                    | 0/12 [00:00<?, ?dir/s]  üìä Found 12 style directories\n  Scanning styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 151.61dir/s]\n  ‚úì Found 5760 valid target images\n    Unique styles: 12\n    Unique characters: 480\n\nüìã Validating image pairs...\n  Scanning styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 150.59dir/s]\n  ‚úì Found 5760 valid target images\n    Unique styles: 12\n    Unique characters: 480\n\nüìã Validating image pairs...\n  Content images:      480 characters\n  Target images:       5760 (char, style) pairs\n  Unique styles:       12\n  Unique chars in targets: 480\n  ‚úÖ All content images have corresponding targets!\n============================================================\n  Content images:      480 characters\n  Target images:       5760 (char, style) pairs\n  Unique styles:       12\n  Unique chars in targets: 480\n  ‚úÖ All content images have corresponding targets!\n============================================================\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0598_Û∞ñò_1_cfd80750.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0425_Û∞ê•_1_729ff986.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0199_Û∞Üô_1_b324bcb5.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F04F1_Û∞ì±_1_838495e1.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0586_Û∞ñÜ_1_52d88662.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F02C7_Û∞ãá_1_34e64141.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F041E_Û∞êû_1_f1ade516.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0598_Û∞ñò_2_19167cd3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0425_Û∞ê•_2_c3f92c49.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0199_Û∞Üô_2_bee10810.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F04F1_Û∞ì±_2_85b8a953.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0586_Û∞ñÜ_2_a4c4315b.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F02C7_Û∞ãá_2_dad0f39b.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F041E_Û∞êû_2_8520facf.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0598_Û∞ñò_3_0f44c186.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0425_Û∞ê•_3_a2d3adc0.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0199_Û∞Üô_3_34130dc1.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F04F1_Û∞ì±_3_a3248a10.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0586_Û∞ñÜ_3_98ed07b0.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F02C7_Û∞ãá_3_6c9c4d85.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F041E_Û∞êû_3_1639fe3d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0598_Û∞ñò_4_cd2f23e2.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0425_Û∞ê•_4_41c7c81f.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0199_Û∞Üô_4_6ae04258.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F04F1_Û∞ì±_4_e6784363.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0586_Û∞ñÜ_4_5b345594.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F02C7_Û∞ãá_4_9a2b8173.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F041E_Û∞êû_4_dba46a24.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0598_Û∞ñò_5_d96d5158.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0425_Û∞ê•_5_c63aad1c.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0199_Û∞Üô_5_c53be315.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F04F1_Û∞ì±_5_9cad8767.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0586_Û∞ñÜ_5_89eaac6d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F02C7_Û∞ãá_5_07b04cda.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F041E_Û∞êû_5_80f1d3b3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0598_Û∞ñò_6_32c60820.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0425_Û∞ê•_6_9f5d4bac.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0199_Û∞Üô_6_81682bb9.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F04F1_Û∞ì±_6_dff97a34.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0586_Û∞ñÜ_6_92039a78.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F02C7_Û∞ãá_6_62eaafe4.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F041E_Û∞êû_6_aed15998.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0598_Û∞ñò_hanh_7d19f554.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0425_Û∞ê•_hanh_8663405c.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0199_Û∞Üô_hanh_ce3760e8.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F04F1_Û∞ì±_hanh_f231ebce.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0586_Û∞ñÜ_hanh_b1f6cc17.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F02C7_Û∞ãá_hanh_d02a3fb4.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F041E_Û∞êû_hanh_2c195665.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0598_Û∞ñò_hanhthu2_5ead7ade.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0425_Û∞ê•_hanhthu2_b8c24085.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0199_Û∞Üô_hanhthu2_da70d85c.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F04F1_Û∞ì±_hanhthu2_5f9d2908.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0586_Û∞ñÜ_hanhthu2_29b8111a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F02C7_Û∞ãá_hanhthu2_8d8213b7.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F041E_Û∞êû_hanhthu2_22e69b97.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0598_Û∞ñò_khai_74c5e6ee.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0425_Û∞ê•_khai_0ff610ab.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0199_Û∞Üô_khai_374dc821.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F04F1_Û∞ì±_khai_2c4eb4f1.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0586_Û∞ñÜ_khai_59f80798.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F02C7_Û∞ãá_khai_46a0f48a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F041E_Û∞êû_khai_72cc0f44.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0598_Û∞ñò_lethu1_01efe025.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0425_Û∞ê•_lethu1_a41fec0d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0199_Û∞Üô_lethu1_c8eb994f.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F04F1_Û∞ì±_lethu1_7eaadbe7.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0586_Û∞ñÜ_lethu1_863701f3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F02C7_Û∞ãá_lethu1_9a4da594.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F041E_Û∞êû_lethu1_2ada017a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0598_Û∞ñò_thao_8d64d34a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0425_Û∞ê•_thao_dea32307.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0199_Û∞Üô_thao_1f66fec2.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F04F1_Û∞ì±_thao_ea7cc886.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0586_Û∞ñÜ_thao_feee9657.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F02C7_Û∞ãá_thao_4d8e23f3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F041E_Û∞êû_thao_0511510f.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0598_Û∞ñò_trien_0909978a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0425_Û∞ê•_trien_c2a4fe66.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0199_Û∞Üô_trien_62124bb7.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F04F1_Û∞ì±_trien_7db02e21.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0586_Û∞ñÜ_trien_fba8621d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F02C7_Û∞ãá_trien_71b8607e.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F041E_Û∞êû_trien_184bc811.png\n‚úì Loaded 5676 images from checkpoint\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F03BE_Û∞éæ_hanhthu1_7cd6d854.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F01D5_Û∞áï_hanhthu1_144a851d.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F0239_Û∞àπ_hanhthu1_0dab6505.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F04AD_Û∞í≠_hanhthu1_ce9372f8.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F03D0_Û∞èê_hanhthu1_22ce229c.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F03BE_Û∞éæ_le_a5d1f38b.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F01D5_Û∞áï_le_368c032a.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F0239_Û∞àπ_le_1b85a846.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F04AD_Û∞í≠_le_8b7f2c3e.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F03D0_Û∞èê_le_466e4b8d.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F03BE_Û∞éæ_lethu2_14334345.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F01D5_Û∞áï_lethu2_4f48feef.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F0239_Û∞àπ_lethu2_c8739240.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F04AD_Û∞í≠_lethu2_56bca946.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F03D0_Û∞èê_lethu2_9897cce3.png\n‚úì Loaded 342 images from checkpoint\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0598_Û∞ñò_1_cfd80750.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0425_Û∞ê•_1_729ff986.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0199_Û∞Üô_1_b324bcb5.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F04F1_Û∞ì±_1_838495e1.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F0586_Û∞ñÜ_1_52d88662.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F02C7_Û∞ãá_1_34e64141.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/1/U+F041E_Û∞êû_1_f1ade516.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0598_Û∞ñò_2_19167cd3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0425_Û∞ê•_2_c3f92c49.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0199_Û∞Üô_2_bee10810.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F04F1_Û∞ì±_2_85b8a953.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F0586_Û∞ñÜ_2_a4c4315b.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F02C7_Û∞ãá_2_dad0f39b.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/2/U+F041E_Û∞êû_2_8520facf.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0598_Û∞ñò_3_0f44c186.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0425_Û∞ê•_3_a2d3adc0.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0199_Û∞Üô_3_34130dc1.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F04F1_Û∞ì±_3_a3248a10.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F0586_Û∞ñÜ_3_98ed07b0.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F02C7_Û∞ãá_3_6c9c4d85.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/3/U+F041E_Û∞êû_3_1639fe3d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0598_Û∞ñò_4_cd2f23e2.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0425_Û∞ê•_4_41c7c81f.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0199_Û∞Üô_4_6ae04258.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F04F1_Û∞ì±_4_e6784363.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F0586_Û∞ñÜ_4_5b345594.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F02C7_Û∞ãá_4_9a2b8173.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/4/U+F041E_Û∞êû_4_dba46a24.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0598_Û∞ñò_5_d96d5158.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0425_Û∞ê•_5_c63aad1c.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0199_Û∞Üô_5_c53be315.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F04F1_Û∞ì±_5_9cad8767.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F0586_Û∞ñÜ_5_89eaac6d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F02C7_Û∞ãá_5_07b04cda.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/5/U+F041E_Û∞êû_5_80f1d3b3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0598_Û∞ñò_6_32c60820.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0425_Û∞ê•_6_9f5d4bac.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0199_Û∞Üô_6_81682bb9.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F04F1_Û∞ì±_6_dff97a34.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F0586_Û∞ñÜ_6_92039a78.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F02C7_Û∞ãá_6_62eaafe4.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/6/U+F041E_Û∞êû_6_aed15998.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0598_Û∞ñò_hanh_7d19f554.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0425_Û∞ê•_hanh_8663405c.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0199_Û∞Üô_hanh_ce3760e8.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F04F1_Û∞ì±_hanh_f231ebce.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F0586_Û∞ñÜ_hanh_b1f6cc17.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F02C7_Û∞ãá_hanh_d02a3fb4.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanh/U+F041E_Û∞êû_hanh_2c195665.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0598_Û∞ñò_hanhthu2_5ead7ade.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0425_Û∞ê•_hanhthu2_b8c24085.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0199_Û∞Üô_hanhthu2_da70d85c.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F04F1_Û∞ì±_hanhthu2_5f9d2908.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F0586_Û∞ñÜ_hanhthu2_29b8111a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F02C7_Û∞ãá_hanhthu2_8d8213b7.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/hanhthu2/U+F041E_Û∞êû_hanhthu2_22e69b97.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0598_Û∞ñò_khai_74c5e6ee.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0425_Û∞ê•_khai_0ff610ab.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0199_Û∞Üô_khai_374dc821.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F04F1_Û∞ì±_khai_2c4eb4f1.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F0586_Û∞ñÜ_khai_59f80798.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F02C7_Û∞ãá_khai_46a0f48a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/khai/U+F041E_Û∞êû_khai_72cc0f44.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0598_Û∞ñò_lethu1_01efe025.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0425_Û∞ê•_lethu1_a41fec0d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0199_Û∞Üô_lethu1_c8eb994f.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F04F1_Û∞ì±_lethu1_7eaadbe7.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F0586_Û∞ñÜ_lethu1_863701f3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F02C7_Û∞ãá_lethu1_9a4da594.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/lethu1/U+F041E_Û∞êû_lethu1_2ada017a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0598_Û∞ñò_thao_8d64d34a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0425_Û∞ê•_thao_dea32307.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0199_Û∞Üô_thao_1f66fec2.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F04F1_Û∞ì±_thao_ea7cc886.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F0586_Û∞ñÜ_thao_feee9657.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F02C7_Û∞ãá_thao_4d8e23f3.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/thao/U+F041E_Û∞êû_thao_0511510f.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0598_Û∞ñò_trien_0909978a.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0425_Û∞ê•_trien_c2a4fe66.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0199_Û∞Üô_trien_62124bb7.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F04F1_Û∞ì±_trien_7db02e21.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F0586_Û∞ñÜ_trien_fba8621d.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F02C7_Û∞ãá_trien_71b8607e.png\n‚ö†Ô∏è  File not found: my_dataset/train/TargetImage/trien/U+F041E_Û∞êû_trien_184bc811.png\n‚úì Loaded 5676 images from checkpoint\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F03BE_Û∞éæ_hanhthu1_7cd6d854.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F01D5_Û∞áï_hanhthu1_144a851d.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F0239_Û∞àπ_hanhthu1_0dab6505.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F04AD_Û∞í≠_hanhthu1_ce9372f8.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/hanhthu1/U+F03D0_Û∞èê_hanhthu1_22ce229c.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F03BE_Û∞éæ_le_a5d1f38b.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F01D5_Û∞áï_le_368c032a.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F0239_Û∞àπ_le_1b85a846.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F04AD_Û∞í≠_le_8b7f2c3e.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/le/U+F03D0_Û∞èê_le_466e4b8d.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F03BE_Û∞éæ_lethu2_14334345.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F01D5_Û∞áï_lethu2_4f48feef.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F0239_Û∞àπ_lethu2_c8739240.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F04AD_Û∞í≠_lethu2_56bca946.png\n‚ö†Ô∏è  File not found: my_dataset/val/TargetImage/lethu2/U+F03D0_Û∞èê_lethu2_9897cce3.png\n‚úì Loaded 342 images from checkpoint\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260101_185028-jdc7g0fd\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msweet-shadow-20\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/jdc7g0fd\u001b[0m\nSteps:   0%|                                            | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n/kaggle/working/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n  style_img_feature, _, _ = self.style_encoder(style_images)\n/kaggle/working/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n  style_img_feature, _, _ = self.style_encoder(style_images)\n/kaggle/working/FontDiffusion/src/model.py:42: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  content_img_feature, content_residual_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:42: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  content_img_feature, content_residual_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:47: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  style_content_feature, style_content_res_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:47: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  style_content_feature, style_content_res_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:59: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n  out = self.unet(\n/kaggle/working/FontDiffusion/src/model.py:59: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n  out = self.unet(\n[rank1]: Traceback (most recent call last):\n[rank1]:   File \"/kaggle/working/FontDiffusion/my_train.py\", line 1222, in <module>\n[rank1]:     main()\n[rank1]:   File \"/kaggle/working/FontDiffusion/my_train.py\", line 1078, in main\n[rank1]:     percep_loss = perceptual_loss(\n[rank1]:                   ^^^^^^^^^^^^^^^^\n[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n[rank1]:     return self._call_impl(*args, **kwargs)\n[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n[rank1]:     return forward_call(*args, **kwargs)\n[rank1]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank1]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 399, in _forward_unimplemented\n[rank1]:     raise NotImplementedError(\n[rank1]: NotImplementedError: Module [ContentPerceptualLoss] is missing the required \"forward\" function\nTraceback (most recent call last):\n  File \"/kaggle/working/FontDiffusion/my_train.py\", line 1222, in <module>\n    main()\n  File \"/kaggle/working/FontDiffusion/my_train.py\", line 1078, in main\n    percep_loss = perceptual_loss(\n                  ^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 399, in _forward_unimplemented\n    raise NotImplementedError(\nNotImplementedError: Module [ContentPerceptualLoss] is missing the required \"forward\" function\n[rank0]: Traceback (most recent call last):\n[rank0]:   File \"/kaggle/working/FontDiffusion/my_train.py\", line 1222, in <module>\n[rank0]:     main()\n[rank0]:   File \"/kaggle/working/FontDiffusion/my_train.py\", line 1078, in main\n[rank0]:     percep_loss = perceptual_loss(\n[rank0]:                   ^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1775, in _wrapped_call_impl\n[rank0]:     return self._call_impl(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1786, in _call_impl\n[rank0]:     return forward_call(*args, **kwargs)\n[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 399, in _forward_unimplemented\n[rank0]:     raise NotImplementedError(\n[rank0]: NotImplementedError: Module [ContentPerceptualLoss] is missing the required \"forward\" function\n\u001b[1;34mwandb\u001b[0m: \n\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33msweet-shadow-20\u001b[0m at: \u001b[34mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/jdc7g0fd\u001b[0m\n\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260101_185028-jdc7g0fd/logs\u001b[0m\nE0101 18:50:34.321000 1296 torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 0 (pid: 1304) of binary: /usr/bin/python3\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n    multi_gpu_launcher(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n    distrib_run.run(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 927, in run\n    elastic_launch(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 156, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 293, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\nFontDiffusion/my_train.py FAILED\n------------------------------------------------------------\nFailures:\n[1]:\n  time      : 2026-01-01_18:50:34\n  host      : 845e88e79f31\n  rank      : 1 (local_rank: 1)\n  exitcode  : 1 (pid: 1305)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2026-01-01_18:50:34\n  host      : 845e88e79f31\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 1304)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}],"execution_count":9},{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","cell_type":"code","source":"!ls -lr outputs/FontDiffuser","metadata":{"trusted":true,"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f"},"outputs":[],"execution_count":null},{"id":"97f8136e","cell_type":"code","source":"# TRAINING PHASE 2\n!wandb login\n!python FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_2\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --phase_2 \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_2000\" \\\n    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n    --sc_coefficient=0.05 \\\n    --num_neg=13 \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.4 \\\n    --max_train_steps=100 \\\n    --ckpt_interval=50 \\\n    --gradient_accumulation_steps=2 \\\n    --log_interval=50 \\\n    --learning_rate=1e-5 \\\n    --lr_scheduler=\"constant\" \\\n    --lr_warmup_steps=1000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"\n","metadata":{"id":"97f8136e","papermill":{"duration":0.022471,"end_time":"2025-12-30T18:55:24.845778","exception":false,"start_time":"2025-12-30T18:55:24.823307","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"88c45e2f","cell_type":"code","source":"!python FontDiffusion/pth2safetensors.py \\\n    --weights_dir \"ckpt\" \\\n    --repo_id \"dzungpham/font-diffusion-weights\" \\\n    --token \"{HF_TOKEN}\"","metadata":{"id":"88c45e2f","papermill":{"duration":0.217876,"end_time":"2025-12-30T18:55:25.079820","exception":false,"start_time":"2025-12-30T18:55:24.861944","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"5868b20b","cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\nfrom typing import List\ndef find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n\ndef zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n    folder_name = folder_path.name\n    zip_path = output_base_path / f\"{folder_name}.zip\"\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for file_path in folder_path.rglob(\"*\"):\n                if file_path.is_file():\n                    arcname = file_path.relative_to(folder_path.parent)\n                    zipf.write(file_path, arcname)\n        print(f\"   ‚úÖ Created ZIP: {zip_path.name}\")\n        return True\n    except Exception as exc:\n        print(f\"   ‚ùå Failed to zip {folder_name}: {exc}\")\n        return False\n\ndef zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n    base = Path(output_base_path)\n    base.mkdir(parents=True, exist_ok=True)\n    result_folders = find_result_folders(base, pattern_name)\n    if not result_folders:\n        print(f\"‚ö†Ô∏è No folders matching '*dataset' found in '{output_base_path}'.\")\n        return\n    print(f\"üîç Found {len(result_folders)} result folder(s) to zip.\")\n    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n    print(f\"\\n‚úÖ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        zip_stats_results_folders(\n            output_base_path=OUTPUT_PATH,\n            pattern_name=\"my_dataset\")\n    except Exception as e:\n        print(f\"‚ùå An error occurred: {e}\")","metadata":{"id":"5868b20b","papermill":{"duration":0.031197,"end_time":"2025-12-30T18:55:25.126961","exception":false,"start_time":"2025-12-30T18:55:25.095764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}