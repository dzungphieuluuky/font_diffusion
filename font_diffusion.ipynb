{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\n\n# 1. *** FIX: Clear problematic environment variable for matplotlib ***\n# This prevents the \"ValueError: Key backend: 'module://matplotlib_inline.backend_inline'\" error\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git\n\n!uv pip install --upgrade pip\n!uv pip install -r FontDiffusion/requirements.txt\n!uv pip install gdown\n# 3. Install PyTorch 1.13\nprint(\"\\n‚¨áÔ∏è Installing PyTorch 1.13 (Required for this model)...\")\n# Force reinstall torch 1.13 to match the model's training environment\n!uv pip uninstall torch torchvision\n!uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n\n# 4. Install other dependencies\nprint(\"\\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install huggingface-hub>=0.15.1,<1.0\n!uv pip install lpips scikit-image pytorch-fid\n!sudo apt-get update && sudo apt-get install dos2unix\nprint(\"\\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWFvN9XJxf9K","outputId":"ba1d7c30-ac4c-4271-fcf3-3ee6ed0fd72c","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:41:44.378903Z","iopub.execute_input":"2025-12-28T10:41:44.379383Z","iopub.status.idle":"2025-12-28T10:42:10.309903Z","shell.execute_reply.started":"2025-12-28T10:41:44.379353Z","shell.execute_reply":"2025-12-28T10:42:10.308650Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'FontDiffusion'...\nremote: Enumerating objects: 15094, done.\u001b[K\nremote: Counting objects: 100% (2907/2907), done.\u001b[K\nremote: Compressing objects: 100% (2825/2825), done.\u001b[K\nremote: Total 15094 (delta 111), reused 2863 (delta 80), pack-reused 12187 (from 3)\u001b[K\nReceiving objects: 100% (15094/15094), 246.94 MiB | 23.48 MiB/s, done.\nResolving deltas: 100% (499/499), done.\nUpdating files: 100% (122/122), done.\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 45ms\u001b[0m\u001b[0m                                           \u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.18ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m24 packages\u001b[0m \u001b[2min 116ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 101ms\u001b[0m\u001b[0m\n\n‚¨áÔ∏è Installing PyTorch 1.13 (Required for this model)...\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 341ms\u001b[0m\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K  \u001b[31m√ó\u001b[0m No solution found when resolving dependencies:                                  \u001b[0m\n\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mBecause torchvision==0.14.1+cu117 has no wheels with a matching Python\n\u001b[31m      \u001b[0mABI tag (e.g., `\u001b[36mcp311\u001b[39m`) and you require torchvision==0.14.1+cu117, we\n\u001b[31m      \u001b[0mcan conclude that your requirements are unsatisfiable.\n\n\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m `\u001b[36mtorchvision\u001b[39m` was found on \u001b[36mhttps://download.pytorch.org/whl/cu117\u001b[39m,\n\u001b[31m      \u001b[0mbut not at the requested version (\u001b[36mtorchvision==0.14.1+cu117\u001b[39m). A\n\u001b[31m      \u001b[0mcompatible version may be available on a subsequent index (e.g.,\n\u001b[31m      \u001b[0m\u001b[36mhttps://pypi.org/simple\u001b[39m). By default, uv will only consider versions\n\u001b[31m      \u001b[0mthat are published on the first index that contains a given package, to\n\u001b[31m      \u001b[0mavoid dependency confusion attacks. If all indexes are equally trusted,\n\u001b[31m      \u001b[0muse `\u001b[32m--index-strategy unsafe-best-match\u001b[39m` to consider all versions from\n\u001b[31m      \u001b[0mall indexes, regardless of the order in which they were defined.\n\n\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.11\u001b[39m (`\u001b[36mcp311\u001b[39m`), but we only found wheels\n\u001b[31m      \u001b[0mfor `\u001b[36mtorchvision\u001b[39m` (\u001b[36mv0.14.1+cu117\u001b[39m) with the following Python ABI tags:\n\u001b[31m      \u001b[0m`\u001b[36mcp37m\u001b[39m`, `\u001b[36mcp38\u001b[39m`, `\u001b[36mcp39\u001b[39m`, `\u001b[36mcp310\u001b[39m`\n\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\n  \u001b[31m√ó\u001b[0m Failed to build `xformers==0.0.16`\n\u001b[31m  ‚îú‚îÄ‚ñ∂ \u001b[0mThe build backend returned an error\n\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n\u001b[31m      \u001b[0mstatus: 1)\n\n\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n\u001b[31m      \u001b[0mError in sitecustomize; set PYTHONVERBOSE for traceback:\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'wrapt'\n\u001b[31m      \u001b[0mTraceback (most recent call last):\n\u001b[31m      \u001b[0m  File \"<string>\", line 14, in <module>\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpY8LpGU/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 331, in get_requires_for_build_wheel\n\u001b[31m      \u001b[0m    return self._get_build_requires(config_settings, requirements=[])\n\u001b[31m      \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpY8LpGU/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 301, in _get_build_requires\n\u001b[31m      \u001b[0m    self.run_setup()\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpY8LpGU/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 512, in run_setup\n\u001b[31m      \u001b[0m    super().run_setup(setup_script=setup_script)\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpY8LpGU/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 317, in run_setup\n\u001b[31m      \u001b[0m    exec(code, locals())\n\u001b[31m      \u001b[0m  File \"<string>\", line 23, in <module>\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'torch'\n\n\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This error likely indicates that `\u001b[36mxformers@0.0.16\u001b[39m` depends\n\u001b[31m      \u001b[0mon `\u001b[36mtorch\u001b[39m`, but doesn't declare it as a build dependency. If\n\u001b[31m      \u001b[0m`\u001b[36mxformers\u001b[39m` is a first-party package, consider adding `\u001b[36mtorch\u001b[39m` to its\n\u001b[31m      \u001b[0m`\u001b[32mbuild-system.requires\u001b[39m`. Otherwise, `\u001b[32muv pip install torch\u001b[39m` into the\n\u001b[31m      \u001b[0menvironment and re-run with `\u001b[32m--no-build-isolation\u001b[39m`.\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m46 packages\u001b[0m \u001b[2min 23ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 260ms\u001b[0m\u001b[0m                                \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 114ms\u001b[0m\u001b[0m\n/bin/bash: line 1: 1.0: No such file or directory\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m37 packages\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m                                  \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\nHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\nHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\nHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nHit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease               \nHit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease                 \nHit:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease          \nHit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease    \nHit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\nHit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\ndos2unix is already the newest version (7.4.2-2).\n0 upgraded, 0 newly installed, 0 to remove and 192 not upgraded.\n--- Setting up colab_style_env ---\n/bin/bash: line 1: conda: command not found\n/bin/bash: line 1: /opt/conda/envs/colab_style_env/bin/pip: No such file or directory\n/bin/bash: line 1: /opt/conda/envs/colab_style_env/bin/pip: No such file or directory\n/bin/bash: line 1: /opt/conda/envs/colab_style_env/bin/pip: No such file or directory\n--- Environment Ready. Running Script ---\n\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 1. Create a new Conda environment with Python 3.9\n# This handles the Linux + Python 3.9 requirement\n!conda create -n font_env python=3.9 -y\n\n# 2. Install PyTorch 1.13.1 with CUDA 11.7 binaries\n# We use the specific pytorch channel to ensure compatibility\n!/opt/conda/envs/font_env/bin/pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu117\n\n# 3. Install the FontDiffusion dependencies and the specific huggingface version\n# This prevents the 'cached_download' error you saw earlier\n!/opt/conda/envs/font_env/bin/pip install huggingface_hub==0.19.4 diffusers==0.14.0 transformers accelerate\n\n# 4. Verify the installation\nprint(\"--- Verification ---\")\n!/opt/conda/envs/font_env/bin/python -c \"import torch; print(f'Python Version: {torch.__ext_schema__}'); print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'CUDA version: {torch.version.cuda}')\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:45:02.407997Z","iopub.execute_input":"2025-12-28T10:45:02.408980Z","iopub.status.idle":"2025-12-28T10:45:02.872634Z","shell.execute_reply.started":"2025-12-28T10:45:02.408948Z","shell.execute_reply":"2025-12-28T10:45:02.871910Z"}},"outputs":[{"name":"stdout","text":"/bin/bash: line 1: conda: command not found\n/bin/bash: line 1: /opt/conda/envs/font_env/bin/pip: No such file or directory\n/bin/bash: line 1: /opt/conda/envs/font_env/bin/pip: No such file or directory\n--- Verification ---\n/bin/bash: line 1: /opt/conda/envs/font_env/bin/python: No such file or directory\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import os\nfrom IPython import get_ipython\n\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"‚úÖ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"‚úÖ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"üìÇ Data Path: {base_data_path}\")\n    print(f\"üì¶ Output Path: {base_output_path}\")\n\n    return base_data_path, base_output_path, environment_name\n\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxdyquWfaqdm","outputId":"aaf97a2b-65a4-4a29-c69f-5c0c38638c3e","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:29:48.372367Z","iopub.execute_input":"2025-12-28T10:29:48.372873Z","iopub.status.idle":"2025-12-28T10:29:48.380165Z","shell.execute_reply.started":"2025-12-28T10:29:48.372846Z","shell.execute_reply":"2025-12-28T10:29:48.379601Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Environment: Kaggle\nüìÇ Data Path: /kaggle/input/\nüì¶ Output Path: /kaggle/working/\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport wandb\n\nif \"colab\" in ENV_NAME:\n    from google.colab import userdata\n\n    try:\n        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n        wandb_key = userdata.get(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n\n# 2. Check if running in Kaggle\nelif \"kaggle\" in ENV_NAME:\n    try:\n        from kaggle_secrets import UserSecretsClient\n\n        user_secrets = UserSecretsClient()\n        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h06w314Jaqdm","outputId":"75176f26-5b20-4ea6-d788-ee5be8d780e3","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:29:48.381856Z","iopub.execute_input":"2025-12-28T10:29:48.382150Z","iopub.status.idle":"2025-12-28T10:29:50.899296Z","shell.execute_reply.started":"2025-12-28T10:29:48.382126Z","shell.execute_reply":"2025-12-28T10:29:50.898291Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Could not retrieve W&B API key from Kaggle Secrets: Unexpected response from the service. Response: {'errors': ['No user secrets exist for kernel id 103951363 and label WANDB_API_KEY.'], 'error': {'code': 5}, 'wasSuccessful': False}.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import gdown\n\nif not os.path.exists(\"ckpt\"):\n  url = \"https://drive.google.com/drive/folders/12hfuZ9MQvXqcteNuz7JQ2B_mUcTr-5jZ\"\n  gdown.download_folder(url, quiet=True, use_cookies=False)","metadata":{"id":"9PsLgUs0cYmO","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:29:50.900151Z","iopub.execute_input":"2025-12-28T10:29:50.900515Z","iopub.status.idle":"2025-12-28T10:30:11.203927Z","shell.execute_reply.started":"2025-12-28T10:29:50.900494Z","shell.execute_reply":"2025-12-28T10:30:11.203305Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -q -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecfc18e0","outputId":"06c02820-3c0c-4246-f079-945e7a40d742","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:30:11.205802Z","iopub.execute_input":"2025-12-28T10:30:11.206149Z","iopub.status.idle":"2025-12-28T10:30:11.212595Z","shell.execute_reply.started":"2025-12-28T10:30:11.206130Z","shell.execute_reply":"2025-12-28T10:30:11.211927Z"}},"outputs":[{"name":"stdout","text":"No .zip files found in /kaggle/input/.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# @title Checking checkpoint files (.pth)\nimport os\nimport time\n\nCHECKPOINT_DIR = os.path.join(INPUT_PATH, \"ckpt\")\nprint(CHECKPOINT_DIR)\n# Create the checkpoint directory\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n# Wait loop to check if files exist\nrequired_files = [\"unet.pth\", \"content_encoder.pth\", \"style_encoder.pth\"]\n\nwhile True:\n    missing = [f for f in required_files if not os.path.exists(f\"{CHECKPOINT_DIR}/{f}\")]\n\n    if not missing:\n        print(\"\\n‚úÖ All weights found! You can proceed to the next step.\")\n        break\n    else:\n        print(f\"Waiting for files... Missing: {missing}\")\n        print(\"Upload them to the 'ckpt' folder now.\")\n        time.sleep(10) # Checks every 10 seconds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBflCTABxlF4","outputId":"6b03581b-e20c-4d44-8d7c-bd3d63f5ff4e","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:30:11.213524Z","iopub.execute_input":"2025-12-28T10:30:11.213846Z","iopub.status.idle":"2025-12-28T10:30:11.248712Z","shell.execute_reply.started":"2025-12-28T10:30:11.213822Z","shell.execute_reply":"2025-12-28T10:30:11.247563Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ckpt\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1488183162.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Create the checkpoint directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Wait loop to check if files exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrequired_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"unet.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content_encoder.pth\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"style_encoder.pth\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/kaggle/input/ckpt'"],"ename":"OSError","evalue":"[Errno 30] Read-only file system: '/kaggle/input/ckpt'","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nnom_tu_tao_300_df = pd.read_csv(f\"{INPUT_PATH}/Ds_300_ChuNom_TuTao.csv\")\nnom_tu_tao = nom_tu_tao_300_df['word'].tolist()\n\nwith open(f\"{OUTPUT_PATH}/nom_tu_tao.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(nom_tu_tao))","metadata":{"id":"Mx5uS5WQaqdn","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"448e1707-8e07-4cdb-db28-f319e3a9d533","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:30:42.952259Z","iopub.execute_input":"2025-12-28T10:30:42.953132Z","iopub.status.idle":"2025-12-28T10:30:43.328221Z","shell.execute_reply.started":"2025-12-28T10:30:42.953098Z","shell.execute_reply":"2025-12-28T10:30:43.326792Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/691170046.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnom_tu_tao_300_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{INPUT_PATH}/Ds_300_ChuNom_TuTao.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnom_tu_tao\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnom_tu_tao_300_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{OUTPUT_PATH}/nom_tu_tao.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input//Ds_300_ChuNom_TuTao.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input//Ds_300_ChuNom_TuTao.csv'","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"%cd {OUTPUT_PATH}/FontDiffusion\n!python batch_sample_evaluate.py \\\n    --characters \"NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --start_line 1 \\\n    --end_line 100 \\\n    --style_images \"style_images/\" \\\n    --ckpt_dir \"../ckpt/\" \\\n    --ttf_path \"fonts/\" \\\n    --output_dir \"../output_1-100_10k\" \\\n    --batch_size 8 \\\n    --save_interval 5 \\\n    --fp16 \\\n    --channels_last","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gma02BZvhx8I","outputId":"a78c5252-10d9-4df7-e06a-ca46bbddc68c","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:42:25.671647Z","iopub.execute_input":"2025-12-28T10:42:25.672117Z","iopub.status.idle":"2025-12-28T10:42:25.799293Z","shell.execute_reply.started":"2025-12-28T10:42:25.672076Z","shell.execute_reply":"2025-12-28T10:42:25.798554Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/FontDiffusion\n/bin/bash: line 1: /opt/conda/envs/colab_style_env/bin/python: No such file or directory\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import os\nimport glob\nimport zipfile\nfrom typing import List\ndef find_result_folders(base_path: str) -> List[str]:\n    \"\"\"\n    Return a list of absolute paths to all directories under `base_path`\n    whose names start with 'results_'.\n    \"\"\"\n    pattern = os.path.join(base_path, \"output_*\")\n    # glob returns both files and directories; filter to directories only\n    return [p for p in glob.glob(pattern) if os.path.isdir(p)]\ndef zip_folder(folder_path: str, output_base_path: str) -> bool:\n    \"\"\"\n    Zip the contents of `folder_path` into a file named\n    <folder_name>.zip` inside `output_base_path`.\n\n    Returns True on success, False otherwise.\n    \"\"\"\n    folder_name = os.path.basename(folder_path)\n    zip_path = os.path.join(output_base_path, f\"{folder_name}.zip\")\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(\n            zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED\n        ) as zipf:\n            for root, _, files in os.walk(folder_path):\n                for file in files:\n                    full_path = os.path.join(root, file)\n                    # Preserve relative path inside the zip\n                    arcname = os.path.relpath(full_path, os.path.dirname(folder_path))\n                    zipf.write(full_path, arcname)\n        print(f\"   ‚úÖ Created ZIP: {os.path.basename(zip_path)}\")\n        return True\n    except Exception as exc:\n        print(f\"   ‚ùå Failed to zip {folder_name}: {exc}\")\n        return False\ndef zip_stats_results_folders(output_base_path: str) -> None:\n    \"\"\"\n    Main driver: locate all result folders and zip each one.\n    \"\"\"\n    # Ensure the output directory exists\n    os.makedirs(output_base_path, exist_ok=True)\n    result_folders = find_result_folders(output_base_path)\n    if not result_folders:\n        print(f\"‚ö†Ô∏è No folders starting with 'results_' found in '{output_base_path}'.\")\n        return\n    print(f\"üîç Found {len(result_folders)} result folder(s) to zip.\")\n    successful = 0\n    for folder in result_folders:\n        if zip_folder(folder, output_base_path):\n            successful += 1\n    print(\n        f\"\\n‚úÖ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\"\n    )\nif __name__ == \"__main__\":\n    try:\n        # Prefer an environment variable; fall back to a global if defined\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        # The script expects a sub‚Äëfolder named 'OuroTrace' under OUTPUT_PATH\n        target_path = os.path.join(output_root, \"\")\n        zip_stats_results_folders(target_path)\n    except Exception as e:\n        print(f\"‚ùå An error occurred: {e}\")\n","metadata":{"id":"kTz9WZ9ylBZx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"beee5c89-037b-4336-fe52-3499e403b128","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:30:43.330470Z","iopub.status.idle":"2025-12-28T10:30:43.330877Z","shell.execute_reply.started":"2025-12-28T10:30:43.330672Z","shell.execute_reply":"2025-12-28T10:30:43.330691Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# @title Happy Christmas‚ú®\n# !rm -r -f FontDiffusion","metadata":{"id":"SIH9c0l-mRqB","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T10:30:43.331996Z","iopub.status.idle":"2025-12-28T10:30:43.332314Z","shell.execute_reply.started":"2025-12-28T10:30:43.332143Z","shell.execute_reply":"2025-12-28T10:30:43.332159Z"}},"outputs":[],"execution_count":null}]}