{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":127.636509,"end_time":"2025-12-30T18:55:25.961447","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-30T18:53:18.324938","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a95a46ef","cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git","metadata":{"id":"BWFvN9XJxf9K","outputId":"1ca6b669-956b-493b-e7ce-6402053d5585","papermill":{"duration":12.857369,"end_time":"2025-12-30T18:53:35.066181","exception":false,"start_time":"2025-12-30T18:53:22.208812","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:09:51.354653Z","iopub.execute_input":"2025-12-31T12:09:51.355249Z","iopub.status.idle":"2025-12-31T12:10:02.853407Z","shell.execute_reply.started":"2025-12-31T12:09:51.355216Z","shell.execute_reply":"2025-12-31T12:10:02.852480Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'FontDiffusion'...\nremote: Enumerating objects: 20257, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (13/13), done.\u001b[K\nremote: Total 20257 (delta 9), reused 16 (delta 7), pack-reused 20237 (from 1)\u001b[K\nReceiving objects: 100% (20257/20257), 277.35 MiB | 39.52 MiB/s, done.\nResolving deltas: 100% (741/741), done.\nUpdating files: 100% (137/137), done.\n","output_type":"stream"}],"execution_count":14},{"id":"9cdd8666","cell_type":"code","source":"import os\nimport sys\nfrom IPython import get_ipython\nfrom typing import Optional\n\ndef configure_environment_paths():\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"‚úÖ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"‚úÖ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"üìÇ Data Path: {base_data_path}\")\n    print(f\"üì¶ Output Path: {base_output_path}\")\n    return base_data_path, base_output_path, environment_name\n\ndef load_secret(key_name: str) -> Optional[str]:\n    env = ENV_NAME\n    secret_value = None\n    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n    try:\n        if env == \"colab\":\n            from google.colab import userdata\n            secret_value = userdata.get(key_name)\n        elif env == \"kaggle\":\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            secret_value = user_secrets.get_secret(key_name)\n        else:\n            secret_value = os.getenv(key_name)\n        if not secret_value:\n            print(f\"‚ö†Ô∏è Secret '{key_name}' not found in the {env} environment.\")\n            return None\n        print(f\"‚úÖ Successfully loaded secret '{key_name}'.\")\n        return secret_value\n    except Exception as e:\n        print(f\"‚ùå An error occurred while loading secret '{key_name}': {e}\")\n        return None\n\ndef print_system_info():\n    print(\"\\nüîß System Information\")\n    print(f\"Python version: {sys.version.split()[0]}\")\n    try:\n        import torch\n        print(f\"PyTorch version: {torch.__version__}\")\n        if torch.cuda.is_available():\n            print(f\"CUDA version: {torch.version.cuda}\")\n            print(f\"GPU count: {torch.cuda.device_count()}\")\n            for i in range(torch.cuda.device_count()):\n                print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        else:\n            print(\"CUDA not available\")\n    except ImportError:\n        print(\"PyTorch not installed\")\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\nprint_system_info()","metadata":{"id":"sxdyquWfaqdm","outputId":"f4738958-8ecc-4e48-bfda-9a798d92165f","papermill":{"duration":0.019157,"end_time":"2025-12-30T18:53:35.092303","exception":false,"start_time":"2025-12-30T18:53:35.073146","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"a73b4150","cell_type":"code","source":"!uv pip install --upgrade pip\n# 3. Install PyTorch 1.13\n%cd {OUTPUT_PATH}\n# Force reinstall torch 1.13 to match the model's training environment\n# !uv pip uninstall torch torchvision\n# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n!uv pip install torch torchvision\n# 4. Install other dependencies\nprint(\"\\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n!sudo apt-get update && sudo apt-get install dos2unix\n!uv pip install gdown\n!uv pip install wandb\n!uv pip install --upgrade pyarrow datasets\nprint(\"\\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"id":"ET_mqyek9bwj","outputId":"aae81910-51d7-4409-b8d0-f862b1ea1fe7","papermill":{"duration":61.239828,"end_time":"2025-12-30T18:54:36.338205","exception":false,"start_time":"2025-12-30T18:53:35.098377","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"bd517dfe","cell_type":"code","source":"# KAGGLE CELL #1: Download checkpoint\n\nimport os\nimport sys\nfrom pathlib import Path\nos.chdir(OUTPUT_PATH)\n# Download from Hub\nif not os.path.exists(\"ckpt\") or not list(Path(\"ckpt\").glob(\"*.safetensors\")):\n    print(\"üì• Downloading checkpoint from Hugging Face Hub...\\n\")\n    from huggingface_hub import snapshot_download\n    snapshot_download(\n        repo_id=\"dzungpham/font-diffusion-weights\",\n        local_dir=\"ckpt\",\n        allow_patterns=\"*.safetensors\",\n        force_download=False\n    )\n    print(\"\\n‚úÖ Download complete!\")\nelse:\n    print(\"‚úÖ Checkpoint already downloaded\")\n# Verify\nprint(\"\\nüìÇ Files in ckpt/:\")\nfor file in os.listdir(\"ckpt\"):\n    if file.endswith(\".safetensors\"):\n        size = os.path.getsize(f\"ckpt/{file}\") / (1024**2)\n        print(f\"  ‚úì {file} ({size:.2f} MB)\")","metadata":{"id":"9PsLgUs0cYmO","outputId":"77e74ba9-f348-4ffb-e675-0717fd7e74a7","papermill":{"duration":12.524295,"end_time":"2025-12-30T18:54:48.878013","exception":false,"start_time":"2025-12-30T18:54:36.353718","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"767e8ea2","cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"id":"ecfc18e0","outputId":"7b925027-747c-4cb1-977e-2bee34d1865f","papermill":{"duration":0.023805,"end_time":"2025-12-30T18:54:48.917163","exception":false,"start_time":"2025-12-30T18:54:48.893358","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"51941368","cell_type":"code","source":"import pandas as pd\nimport os\n\ndef convert_csv_to_chars_txt(input_csv_path: str, output_txt_path: str, column_name: str = 'word'):\n    \"\"\"\n    Reads a CSV file, extracts text from a specified column, and writes each character\n    to a new line in a plain text file.\n\n    Args:\n        input_csv_path (str): The full path to the input CSV file.\n        output_txt_path (str): The full path for the output text file.\n        column_name (str): The name of the column in the CSV file containing the text.\n    \"\"\"\n    if not os.path.exists(input_csv_path):\n        print(f\"Error: Input CSV file not found at '{input_csv_path}'. Please ensure the file is uploaded.\")\n        return\n\n    try:\n        df = pd.read_csv(input_csv_path)\n    except Exception as e:\n        print(f\"Error reading CSV file '{input_csv_path}': {e}\")\n        return\n\n    if column_name not in df.columns:\n        print(f\"Error: Column '{column_name}' not found in the CSV file '{input_csv_path}'.\")\n        return\n\n    all_characters = []\n    # Ensure the column values are treated as strings before iterating over them\n    for item in df[column_name].astype(str).dropna().tolist():\n        for char in item:\n            all_characters.append(char)\n\n    # Ensure output directory exists\n    os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)\n\n    with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(all_characters))\n    print(f\"Successfully converted '{input_csv_path}' to '{output_txt_path}', with one character per line.\")\n\n# --- Example Usage (demonstration with a dummy file) ---\n# As the original file 'Ds_300_ChuNom_TuTao.csv' was not found in the previous execution,\n# let's create a dummy file to demonstrate the function's usage.\nprint(\"\\n--- Demonstrating function with a dummy CSV file ---\")\ndummy_csv_path = os.path.join(OUTPUT_PATH, \"dummy_data.csv\")\ndummy_output_txt_path = os.path.join(OUTPUT_PATH, \"dummy_chars.txt\")\n\n# Create a dummy CSV file\ndummy_data = {'word': ['hello', 'world', 'python']}\npd.DataFrame(dummy_data).to_csv(dummy_csv_path, index=False)\nprint(f\"Created a dummy CSV file at: {dummy_csv_path}\")\n\nconvert_csv_to_chars_txt(dummy_csv_path, dummy_output_txt_path)\n\n# --- How to use with your actual file ---\n# Uncomment the lines below and replace 'your_actual_file.csv' and 'your_output.txt'\n# with the correct paths for your use case.\n#\n# original_csv_file = os.path.join(INPUT_PATH, \"Ds_300_ChuNom_TuTao.csv\") # Or the full path to your CSV\n# original_output_txt = os.path.join(OUTPUT_PATH, \"nom_tu_tao.txt\") # Or your desired output path\n# convert_csv_to_chars_txt(original_csv_file, original_output_txt)\n","metadata":{"id":"Mx5uS5WQaqdn","outputId":"951a03aa-416d-4e8d-ca55-121d410bb302","papermill":{"duration":1.62157,"end_time":"2025-12-30T18:54:50.594793","exception":false,"start_time":"2025-12-30T18:54:48.973223","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"4f4cf20b","cell_type":"code","source":"!ls -larth {OUTPUT_PATH}/ckpt","metadata":{"id":"Sxz63qgifNlV","outputId":"c86d1ccf-dcc8-44ec-d61f-9035dd9d0369","papermill":{"duration":0.140282,"end_time":"2025-12-30T18:54:50.749810","exception":false,"start_time":"2025-12-30T18:54:50.609528","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"92cff682","cell_type":"code","source":"%cd {OUTPUT_PATH}\nfrom huggingface_hub import login\nHF_TOKEN = load_secret(\"HF_TOKEN\")\nlogin(HF_TOKEN)\nHF_USERNAME = \"dzungpham\"\n\n# ==========================================\n# EXPORT / DOWNLOAD DATASET COMMANDS\n# ==========================================\n\n# Train Split\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token HF_TOKEN \n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train_original\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token HF_TOKEN \n# Validation: Unseen Both\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val_unseen_both\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val_unseen_both\" \\\n  --token HF_TOKEN \n# Validation: Seen Style, Unseen Char\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val_seen_style_unseen_char\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val_seen_style_unseen_char\" \\\n  --token HF_TOKEN \n# Validation: Unseen Style, Seen Char\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val_unseen_style_seen_char\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val_unseen_style_seen_char\" \\\n  --token HF_TOKEN \n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/test\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"test\" \\\n  --token HF_TOKEN \nprint(\"SUCCESSFULLY EXPORT HF DATASET TO LOCAL DIRECTORY\")","metadata":{"id":"MvEJIiH5fNlV","outputId":"95a0a309-3e6b-482b-c971-cf93efac61bf","papermill":{"duration":0.104394,"end_time":"2025-12-30T18:54:50.869230","exception":false,"start_time":"2025-12-30T18:54:50.764836","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"d77b3a8e-60ec-4299-ad46-a82ee2852629","cell_type":"code","source":"!uv pip install \"huggingface-hub==0.25.2\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"29deed1d","cell_type":"code","source":"# already change sample_batch file to save all data in train_original\n%cd {OUTPUT_PATH}\n!python FontDiffusion/sample_batch.py \\\n    --characters \"FontDiffusion/NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --style_images \"FontDiffusion/styles_images\" \\\n    --ckpt_dir \"ckpt/\" \\\n    --ttf_path \"FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n    --output_dir \"my_dataset/train_original\" \\\n    --resume_from \"my_dataset/train_original/results_checkpoint.json\" \\\n    --num_inference_steps 20 \\\n    --guidance_scale 7.5 \\\n    --start_line 76 \\\n    --end_line 100 \\\n    --batch_size 24 \\\n    --save_interval 1 \\\n    --channels_last \\\n    --seed 42 \\\n    --compile \\\n    --enable_xformers","metadata":{"execution":{"iopub.status.busy":"2025-12-31T12:29:39.592177Z","iopub.execute_input":"2025-12-31T12:29:39.592560Z","iopub.status.idle":"2025-12-31T12:40:46.036972Z","shell.execute_reply.started":"2025-12-31T12:29:39.592524Z","shell.execute_reply":"2025-12-31T12:40:46.036057Z"},"id":"gma02BZvhx8I","outputId":"a8a54761-e26c-488d-d87d-cd14d686e77f","papermill":{"duration":10.53661,"end_time":"2025-12-30T18:55:01.421093","exception":false,"start_time":"2025-12-30T18:54:50.884483","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2025-12-31 12:29:43.985251: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767184184.006129    1483 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767184184.012524    1483 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n\n============================================================\nFONTDIFFUSER BATCH GENERATION SCRIPT\n============================================================\nLoading characters from lines 76 to 100 (total: 10174 lines)\nüìñ Reading character file: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:00<00:00, 264791.92line/s]\nSuccessfully loaded 25 single characters.\n\nüìÇ Loading 15 style images from directory...\n‚úì Verifying style images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 124091.83image/s]\n\nInitializing font manager...\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded font: NomNaTong-Regular\n\nüìä Configuration:\n  Dataset split: train_original\n  Number of Characters: 25 (lines 76-100)\n  Number of Styles: 15\n  Output Directory: my_dataset/train_original\n  Save Interval: Every 1 styles\n‚úì Loaded checkpoint (4875 generations)\n‚úì Loaded results.json:\n  Characters: 300\n  Styles: 15\n  Existing pairs: 4875\n\nLoading FontDiffuser pipeline...\nLoading FontDiffuser pipeline...\nLoad the down block  DownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n‚úì Loaded model state_dict successfully\nConverting to channels-last memory format...\n‚úì Model moved to device\n‚úì Loaded training DDPM scheduler successfully\n‚úì Loaded DPM-Solver pipeline successfully\n\n============================================================\nCompiling pipeline with torch.compile...\n============================================================\n‚ö†Ô∏è  Warning: torch.compile failed: \n  Continuing without compilation...\n  Note: torch.compile requires PyTorch 2.0+ and may not work with all models\nSetting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nLoading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/alex.pth\n\n‚úÖ All 25 content images already exist\nüì• Resuming: 4875 pairs already processed\n\n======================================================================\n                        BATCH IMAGE GENERATION                        \n======================================================================\nFont Number:          1\nFont Names:           NomNaTong-Regular\nStyles:               15\nCharacters:           25\nBatch size:           24\nGuidance scale:       7.5\nInference steps:      20\nOutput Dir:           my_dataset/train_original\n======================================================================\n\nUsing font: NomNaTong-Regular\n======================================================================\n\nüé® Generating styles:   0%|                                                  | 0/15 [00:00<?, ?it/s]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A/kaggle/working/FontDiffusion/src/model.py:99: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n  style_img_feature, _, style_residual_features = self.style_encoder(style_images)\n/kaggle/working/FontDiffusion/src/model.py:107: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n  content_img_feture, content_residual_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:112: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n  style_content_feature, style_content_res_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:124: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n  out = self.unet(\n\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:38<00:38, 38.03s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:40, 10.62s/batch]                                  \u001b[A\n  ‚úì style0: 25 images in 40.09s                                                                     \nüé® Generating styles:   0%|                                                  | 0/15 [00:41<?, ?it/s]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           1/15 styles\nGenerated:          25 pairs\nSkipped:            0 pairs\nElapsed time:       0.7 minutes\nEst. remaining:     9.8 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (4900 generations)\nüé® Generating styles:   7%|‚ñà‚ñà‚ñä                                       | 1/15 [00:41<09:46, 41.88s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.62s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.04s/batch]                                  \u001b[A\n  ‚úì style1: 25 images in 41.69s                                                                     \nüé® Generating styles:   7%|‚ñà‚ñà‚ñä                                       | 1/15 [01:25<09:46, 41.88s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           2/15 styles\nGenerated:          50 pairs\nSkipped:            0 pairs\nElapsed time:       1.4 minutes\nEst. remaining:     9.2 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (4925 generations)\nüé® Generating styles:  13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 2/15 [01:25<09:16, 42.80s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.81s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.08s/batch]                                  \u001b[A\n  ‚úì style2: 25 images in 41.85s                                                                     \nüé® Generating styles:  13%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                                    | 2/15 [02:08<09:16, 42.80s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           3/15 styles\nGenerated:          75 pairs\nSkipped:            0 pairs\nElapsed time:       2.1 minutes\nEst. remaining:     8.6 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (4950 generations)\nüé® Generating styles:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 3/15 [02:08<08:37, 43.16s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.73s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.05s/batch]                                  \u001b[A\n  ‚úì style3: 25 images in 41.76s                                                                     \nüé® Generating styles:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                 | 3/15 [02:52<08:37, 43.16s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           4/15 styles\nGenerated:          100 pairs\nSkipped:            0 pairs\nElapsed time:       2.9 minutes\nEst. remaining:     7.9 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (4975 generations)\nüé® Generating styles:  27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 4/15 [02:52<07:56, 43.31s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.84s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.08s/batch]                                  \u001b[A\n  ‚úì style4: 25 images in 41.88s                                                                     \nüé® Generating styles:  27%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                              | 4/15 [03:36<07:56, 43.31s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           5/15 styles\nGenerated:          125 pairs\nSkipped:            0 pairs\nElapsed time:       3.6 minutes\nEst. remaining:     7.2 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5000 generations)\nüé® Generating styles:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 5/15 [03:36<07:14, 43.43s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.74s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.06s/batch]                                  \u001b[A\n  ‚úì style5: 25 images in 41.78s                                                                     \nüé® Generating styles:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                            | 5/15 [04:19<07:14, 43.43s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           6/15 styles\nGenerated:          150 pairs\nSkipped:            0 pairs\nElapsed time:       4.3 minutes\nEst. remaining:     6.5 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5025 generations)\nüé® Generating styles:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 6/15 [04:19<06:31, 43.46s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.80s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.07s/batch]                                  \u001b[A\n  ‚úì style6: 25 images in 41.83s                                                                     \nüé® Generating styles:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                         | 6/15 [05:03<06:31, 43.46s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           7/15 styles\nGenerated:          175 pairs\nSkipped:            0 pairs\nElapsed time:       5.1 minutes\nEst. remaining:     5.8 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5050 generations)\nüé® Generating styles:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 7/15 [05:03<05:48, 43.50s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.79s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.07s/batch]                                  \u001b[A\n  ‚úì style7: 25 images in 41.82s                                                                     \nüé® Generating styles:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 7/15 [05:46<05:48, 43.50s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           8/15 styles\nGenerated:          200 pairs\nSkipped:            0 pairs\nElapsed time:       5.8 minutes\nEst. remaining:     5.1 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5075 generations)\nüé® Generating styles:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 8/15 [05:46<05:04, 43.51s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.86s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.09s/batch]                                  \u001b[A\n  ‚úì style8: 25 images in 41.89s                                                                     \nüé® Generating styles:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                   | 8/15 [06:30<05:04, 43.51s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           9/15 styles\nGenerated:          225 pairs\nSkipped:            0 pairs\nElapsed time:       6.5 minutes\nEst. remaining:     4.3 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5100 generations)\nüé® Generating styles:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 9/15 [06:30<04:21, 43.55s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.89s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.10s/batch]                                  \u001b[A\n  ‚úì style9: 25 images in 41.92s                                                                     \nüé® Generating styles:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 9/15 [07:13<04:21, 43.55s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           10/15 styles\nGenerated:          250 pairs\nSkipped:            0 pairs\nElapsed time:       7.2 minutes\nEst. remaining:     3.6 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5125 generations)\nüé® Generating styles:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 10/15 [07:14<03:37, 43.58s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.75s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.07s/batch]                                  \u001b[A\n  ‚úì style10: 25 images in 41.80s                                                                    \nüé® Generating styles:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé             | 10/15 [07:57<03:37, 43.58s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           11/15 styles\nGenerated:          275 pairs\nSkipped:            0 pairs\nElapsed time:       8.0 minutes\nEst. remaining:     2.9 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5150 generations)\nüé® Generating styles:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 11/15 [07:57<02:54, 43.57s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.84s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.08s/batch]                                  \u001b[A\n  ‚úì style11: 25 images in 41.88s                                                                    \nüé® Generating styles:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 11/15 [08:41<02:54, 43.57s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           12/15 styles\nGenerated:          300 pairs\nSkipped:            0 pairs\nElapsed time:       8.7 minutes\nEst. remaining:     2.2 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5175 generations)\nüé® Generating styles:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 12/15 [08:41<02:10, 43.59s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.76s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.06s/batch]                                  \u001b[A\n  ‚úì style12: 25 images in 41.80s                                                                    \nüé® Generating styles:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä        | 12/15 [09:24<02:10, 43.59s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           13/15 styles\nGenerated:          325 pairs\nSkipped:            0 pairs\nElapsed time:       9.4 minutes\nEst. remaining:     1.4 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5200 generations)\nüé® Generating styles:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 13/15 [09:24<01:27, 43.59s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.75s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.07s/batch]                                  \u001b[A\n  ‚úì style13: 25 images in 41.81s                                                                    \nüé® Generating styles:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå     | 13/15 [10:08<01:27, 43.59s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           14/15 styles\nGenerated:          350 pairs\nSkipped:            0 pairs\nElapsed time:       10.1 minutes\nEst. remaining:     0.7 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5225 generations)\nüé® Generating styles:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/15 [10:08<00:43, 43.58s/it]\n  üìù Preparing NomNaTong-Regular:   0%|                | 0/25 [00:00<?, ?char/s]\u001b[A\n                                                                                \u001b[A\n  üé® Inferencing:   0%|                                | 0/2 [00:00<?, ?batch/s]\u001b[A\n  üé® Inferencing:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà            | 1/2 [00:39<00:39, 39.81s/batch]\u001b[A\n  üé® Inferencing: 3batch [00:41, 11.07s/batch]                                  \u001b[A\n  ‚úì style14: 25 images in 41.84s                                                                    \nüé® Generating styles:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/15 [10:51<00:43, 43.58s/it]\n======================================================================\n                              CHECKPOINT                              \n======================================================================\nProgress:           15/15 styles\nGenerated:          375 pairs\nSkipped:            0 pairs\nElapsed time:       10.9 minutes\nEst. remaining:     0.0 minutes\n======================================================================\n  ‚úÖ Saved results_checkpoint.json (5250 generations)\nüé® Generating styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [10:51<00:00, 43.46s/it]\n\n======================================================================\n                         GENERATION COMPLETE                          \n======================================================================\n\nPair Statistics:\n  Total possible:     375\n  Generated (new):    375\n  Skipped (exist):    0\n  Failed (no font):   0\n\nTiming:\n  Total time:         10.9 minutes (652s)\n  Avg per pair:       1738.5ms\n======================================================================\n\nüìù Saving final checkpoint...\n  ‚úÖ Saved results_checkpoint.json (5250 generations)\n\n============================================================\n‚úÖ GENERATION COMPLETE!\n============================================================\n\nOutput structure:\n  my_dataset/train_original/\n    ‚îú‚îÄ‚îÄ ContentImage/\n    ‚îÇ   ‚îú‚îÄ‚îÄ char0.png\n    ‚îÇ   ‚îú‚îÄ‚îÄ char1.png\n    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n    ‚îú‚îÄ‚îÄ TargetImage/\n    ‚îÇ   ‚îú‚îÄ‚îÄ style0/\n    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ style0+char0.png\n    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...\n    ‚îÇ   ‚îî‚îÄ‚îÄ ...\n    ‚îî‚îÄ‚îÄ results_checkpoint.json ‚úÖ (single source of truth)\n","output_type":"stream"}],"execution_count":19},{"id":"f9250a14","cell_type":"code","source":"!python FontDiffusion/create_validation_split.py \\\n  --data_root my_dataset \\\n  --val_ratio 0.2 \\\n  --test_ratio 0.1 \\\n  --seed 42","metadata":{"execution":{"iopub.status.busy":"2025-12-31T12:41:13.490300Z","iopub.execute_input":"2025-12-31T12:41:13.491082Z","iopub.status.idle":"2025-12-31T12:41:14.952535Z","shell.execute_reply.started":"2025-12-31T12:41:13.491048Z","shell.execute_reply":"2025-12-31T12:41:14.951858Z"},"id":"XoppW2x5fNlW","outputId":"759bca6c-0025-454a-b3b6-ae8170f7edb4","papermill":{"duration":0.236541,"end_time":"2025-12-30T18:55:01.673705","exception":false,"start_time":"2025-12-30T18:55:01.437164","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n============================================================\nFONTDIFFUSION VALIDATION SPLIT CREATOR\n============================================================\n‚úì Using source directory: my_dataset/train_original\n\n============================================================\nCREATING DATA SPLITS\n============================================================\n\n============================================================\nANALYZING TRAINING DATA\n============================================================\n\n‚úì Found:\n  Styles: 15\n  Characters: 325\n  Valid (char, style) pairs: 4875\n\n‚úì After validation:\n  Characters with content images: 325\n  Valid (char, style) pairs: 4875\n\n============================================================\nCREATING VALIDATION SCENARIOS\n============================================================\n\nüìä Split Statistics:\n  Styles: 11 train + 3 val + 1 test\n  Chars:  228 train + 65 val + 32 test\n\nüìã Validation Scenarios:\n\n  train:\n    Description: Seen styles + Seen characters (training data)\n    Styles: ['style13', 'style7', 'style2', 'style8', 'style11', 'style12', 'style4', 'style9', 'style14', 'style3', 'style10']\n    Chars: ['char258', 'char230', 'char317', 'char83', 'char201']...\n\n  val_seen_style_unseen_char:\n    Description: Seen styles + Unseen characters\n    Styles: ['style13', 'style7', 'style2', 'style8', 'style11', 'style12', 'style4', 'style9', 'style14', 'style3', 'style10']\n    Chars: ['char249', 'char61', 'char47', 'char90', 'char229']...\n\n  val_unseen_style_seen_char:\n    Description: Unseen styles + Seen characters\n    Styles: ['style6', 'style1', 'style0']\n    Chars: ['char258', 'char230', 'char317', 'char83', 'char201']...\n\n  val_unseen_both:\n    Description: Unseen styles + Unseen characters\n    Styles: ['style6', 'style1', 'style0']\n    Chars: ['char249', 'char61', 'char47', 'char90', 'char229']...\n\n  test:\n    Description: Test set (hold-out)\n    Styles: ['style5']\n    Chars: ['char111', 'char304', 'char255', 'char22', 'char198']...\n\nüîß Creating directory structure...\n\nüìÅ Train split:\n  Valid pairs: 2508\n  Unique chars in valid pairs: 228\n  Unique styles in valid pairs: 11\n\n  üì• Copying content images...\n  üì• Copying target images...                                                   \n                                                                                \n  üîç Validating split...\n  ‚úì Validation passed: All 3069 targets have matching content images\n  ‚úì Copied 228 content + 2508 target images (skipped 0)\n\nüìÅ val_seen_style_unseen_char:\n  Valid pairs: 715\n  Unique chars in valid pairs: 65\n  Unique styles in valid pairs: 11\n\n  üì• Copying content images...\n  üì• Copying target images...                                                   \n                                                                                \n  üîç Validating split...\n  ‚úì Validation passed: All 1342 targets have matching content images\n  ‚úì Copied 65 content + 715 target images (skipped 0)\n\nüìÅ val_unseen_style_seen_char:\n  Valid pairs: 684\n  Unique chars in valid pairs: 228\n  Unique styles in valid pairs: 3\n\n  üì• Copying content images...\n  üì• Copying target images...                                                   \n                                                                                \n  üîç Validating split...\n  ‚úì Validation passed: All 837 targets have matching content images\n  ‚úì Copied 228 content + 684 target images (skipped 0)\n\nüìÅ val_unseen_both:\n  Valid pairs: 195\n  Unique chars in valid pairs: 65\n  Unique styles in valid pairs: 3\n\n  üì• Copying content images...\n  üì• Copying target images...                                                   \n                                                                                \n  üîç Validating split...\n  ‚úì Validation passed: All 366 targets have matching content images\n  ‚úì Copied 65 content + 195 target images (skipped 0)\n\nüìÅ test:\n  Valid pairs: 32\n  Unique chars in valid pairs: 32\n  Unique styles in valid pairs: 1\n\n  üì• Copying content images...\n  üì• Copying target images...                                                   \n                                                                                \n  üîç Validating split...\n  ‚úì Validation passed: All 48 targets have matching content images\n  ‚úì Copied 32 content + 32 target images (skipped 0)\n\n‚úì Saved scenario metadata to my_dataset/validation_scenarios.json\n\n============================================================\n‚úì VALIDATION SPLIT CREATION COMPLETE\n============================================================\n\n‚úÖ Created directories with validated pairs:\n  üìÅ train/ - Training data (matched content + targets)\n  üìÅ val_seen_style_unseen_char/ - Test new characters\n  üìÅ val_unseen_style_seen_char/ - Test new styles\n  üìÅ val_unseen_both/ - Test full generalization\n  üìÅ test/ - Hold-out test set\n\nüí° Each folder guarantees:\n  ‚úì For every charX+styleY.png target, charX.png content exists\n  ‚úì No orphaned target images without content\n  ‚úì No unused content images without targets\n","output_type":"stream"}],"execution_count":21},{"id":"79508d80-fac1-4318-9174-a32613a557e3","cell_type":"code","source":"!uv pip install --upgrade pyarrow datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T12:43:11.967796Z","iopub.execute_input":"2025-12-31T12:43:11.968477Z","iopub.status.idle":"2025-12-31T12:43:22.493086Z","shell.execute_reply.started":"2025-12-31T12:43:11.968416Z","shell.execute_reply":"2025-12-31T12:43:22.492187Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m39 packages\u001b[0m \u001b[2min 208ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m12 packages\u001b[0m \u001b[2min 428ms\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m12 packages\u001b[0m \u001b[2min 302ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m12 packages\u001b[0m \u001b[2min 9.33s\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.3.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==4.4.2\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.25.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==1.2.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.3.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==19.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==22.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtyper-slim\u001b[0m\u001b[2m==0.21.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2025.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n","output_type":"stream"}],"execution_count":23},{"id":"e92a9392","cell_type":"code","source":"# --- RAW DATA (Before Splitting) ---\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train_original\" \\\n  --repo_id \"{HF_USERNAME}/font-diffusion-generated-data\" \\\n  --split \"train_original\" \\\n  --private \\\n  --token \"{HF_TOKEN}\"\n\n# --- ORGANIZED SPLITS (After Splitting) ---\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train\" \\\n  --repo_id \"{HF_USERNAME}/font-diffusion-generated-data\" \\\n  --split \"train\" \\\n  --private \\\n  --token \"{HF_TOKEN}\"\n\n# Test Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/test\" \\\n  --repo_id \"{HF_USERNAME}/font-diffusion-generated-data\" \\\n  --split \"test\" \\\n  --private \\\n  --token \"{HF_TOKEN}\"\n\n# Validation: Unseen Both\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/val_unseen_both\" \\\n  --repo_id \"{HF_USERNAME}/font-diffusion-generated-data\" \\\n  --split \"val_unseen_both\" \\\n  --private \\\n  --token \"{HF_TOKEN}\"\n\n# Validation: Seen Style, Unseen Char\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/val_seen_style_unseen_char\" \\\n  --repo_id \"{HF_USERNAME}/font-diffusion-generated-data\" \\\n  --split \"val_seen_style_unseen_char\" \\\n  --private \\\n  --token \"{HF_TOKEN}\"\n\n# Validation: Unseen Style, Seen Char\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/val_unseen_style_seen_char\" \\\n  --repo_id \"{HF_USERNAME}/font-diffusion-generated-data\" \\\n  --split \"val_unseen_style_seen_char\" \\\n  --private \\\n  --token \"{HF_TOKEN}\"\nprint(\"SUCCESSFULLY UPLOAD LOCAL MY_DATASET TO HUGGINGFACE DATASETS SPACE\")","metadata":{"execution":{"iopub.status.busy":"2025-12-31T12:43:24.896976Z","iopub.execute_input":"2025-12-31T12:43:24.897792Z","iopub.status.idle":"2025-12-31T12:45:02.938686Z","shell.execute_reply.started":"2025-12-31T12:43:24.897742Z","shell.execute_reply":"2025-12-31T12:45:02.937689Z"},"id":"v-a7paEbfNlW","outputId":"c792e189-6d31-4114-be92-644d4372efa7","papermill":{"duration":21.070659,"end_time":"2025-12-30T18:55:22.760587","exception":false,"start_time":"2025-12-30T18:55:01.689928","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/train_original\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\n‚úì Validated directory structure\n  Content images: my_dataset/train_original/ContentImage\n  Target images: my_dataset/train_original/TargetImage\n\n============================================================\nBUILDING DATASET\n============================================================\n\nüñºÔ∏è  Discovering images from disk...\n  ‚úì Found 325 content images\n  ‚úì Found 4875 target images\n\nüìã Loading 4875 image pairs...\nLoading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4875/4875 [00:03<00:00, 1221.91pair/s]\n‚úì Loaded 4875 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: train_original\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                      | 0/4875 [00:00<?, ? examples/s]\u001b[A\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4875/4875 [00:00<00:00, 14103.23 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/1 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.02ba/s]\u001b[A\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :   1%|‚ñè             |  868kB / 74.3MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   1%|‚ñè             |  868kB / 74.3MB, 2.17MB/s  \u001b[A\u001b[A\nNew Data Upload               :   1%|‚ñè             |  525kB / 44.9MB, 1.31MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  33%|‚ñà‚ñà‚ñà‚ñà‚ñå         | 24.3MB / 74.3MB, 40.5MB/s  \u001b[A\u001b[A\nNew Data Upload               :  33%|‚ñà‚ñà‚ñà‚ñà‚ñå         | 14.7MB / 44.9MB, 24.5MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 62.5MB / 74.3MB, 78.1MB/s  \u001b[A\u001b[A\nNew Data Upload               :  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 37.8MB / 44.9MB, 47.3MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 73.7MB / 74.3MB, 73.7MB/s  \u001b[A\u001b[A\nNew Data Upload               :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 44.6MB / 44.9MB, 44.6MB/s  \u001b[A\n\n                              :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 73.7MB / 74.3MB            \u001b[A\u001b[A\n\n                              :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 73.7MB / 74.3MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.3MB / 74.3MB, 48.7MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.9MB / 44.9MB, 29.4MB/s  \u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.3MB / 74.3MB, 46.5MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.9MB / 44.9MB, 28.1MB/s  \n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 74.3MB / 74.3MB            \nUploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.88s/ shards]\nREADME.md: 1.29kB [00:00, 3.45MB/s]\n\n‚úì Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\n‚úÖ COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/train\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\n‚úì Validated directory structure\n  Content images: my_dataset/train/ContentImage\n  Target images: my_dataset/train/TargetImage\n\n============================================================\nBUILDING DATASET\n============================================================\n\nüñºÔ∏è  Discovering images from disk...\n  ‚úì Found 279 content images\n  ‚úì Found 3069 target images\n\nüìã Loading 3069 image pairs...\nLoading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3069/3069 [00:02<00:00, 1230.25pair/s]\n‚úì Loaded 3069 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: train\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                      | 0/3069 [00:00<?, ? examples/s]\u001b[A\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3069/3069 [00:00<00:00, 16783.58 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/1 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  8.66ba/s]\u001b[A\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :   0%|              |  187kB / 46.9MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   0%|              |  187kB / 46.9MB,   ???B/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :   2%|‚ñé             |  874kB / 46.9MB, 3.44MB/s  \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  19%|‚ñà‚ñà‚ñã           | 8.81MB / 46.9MB, 21.6MB/s  \u001b[A\u001b[A\nNew Data Upload               :  17%|‚ñà‚ñà‚ñç           | 5.25MB / 30.5MB, 13.1MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 45.3MB / 46.9MB, 75.2MB/s  \u001b[A\u001b[A\nNew Data Upload               :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 29.4MB / 30.5MB, 49.0MB/s  \u001b[A\n\nProcessing Files (0 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 46.9MB / 46.9MB, 58.4MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 30.5MB / 30.5MB, 38.1MB/s  \u001b[A\n\n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 46.9MB / 46.9MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.9MB / 46.9MB, 39.0MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30.5MB / 30.5MB, 25.4MB/s  \u001b[A\n\n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.9MB / 46.9MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.9MB / 46.9MB, 33.4MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30.5MB / 30.5MB, 21.8MB/s  \n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 46.9MB / 46.9MB            \nUploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.00s/ shards]\nREADME.md: 1.29kB [00:00, 3.48MB/s]\n\n‚úì Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\n‚úÖ COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/test\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\n‚úì Validated directory structure\n  Content images: my_dataset/test/ContentImage\n  Target images: my_dataset/test/TargetImage\n\n============================================================\nBUILDING DATASET\n============================================================\n\nüñºÔ∏è  Discovering images from disk...\n  ‚úì Found 48 content images\n  ‚úì Found 48 target images\n\nüìã Loading 48 image pairs...\nLoading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:00<00:00, 1046.09pair/s]\n‚úì Loaded 48 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: test\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48/48 [00:00<00:00, 8309.32 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 264.49ba/s]\u001b[A\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   |  562kB /  747kB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   |  562kB /  747kB,   ???B/s  \u001b[A\u001b[A\nNew Data Upload               :  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   |  525kB /  709kB,   ???B/s  \u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  747kB /  747kB,  922kB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  709kB /  709kB,  922kB/s  \u001b[A\n\n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  747kB /  747kB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  747kB /  747kB,  461kB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  709kB /  709kB,  461kB/s  \n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|  747kB /  747kB            \nUploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.12s/ shards]\nREADME.md: 1.29kB [00:00, 3.87MB/s]\n\n‚úì Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\n‚úÖ COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/val_unseen_both\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\n‚úì Validated directory structure\n  Content images: my_dataset/val_unseen_both/ContentImage\n  Target images: my_dataset/val_unseen_both/TargetImage\n\n============================================================\nBUILDING DATASET\n============================================================\n\nüñºÔ∏è  Discovering images from disk...\n  ‚úì Found 122 content images\n  ‚úì Found 366 target images\n\nüìã Loading 366 image pairs...\nLoading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:00<00:00, 1265.33pair/s]\n‚úì Loaded 366 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: val_unseen_both\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 366/366 [00:00<00:00, 20675.51 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 75.72ba/s]\u001b[A\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :  14%|‚ñà‚ñâ            |  535kB / 3.83MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  14%|‚ñà‚ñâ            |  535kB / 3.83MB,   ???B/s  \u001b[A\u001b[A\nNew Data Upload               :  14%|‚ñà‚ñâ            |  524kB / 3.82MB,   ???B/s  \u001b[A\n\nProcessing Files (0 / 1)      :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3.68MB / 3.83MB, 15.7MB/s  \u001b[A\u001b[A\nNew Data Upload               :  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 3.67MB / 3.82MB, 15.7MB/s  \u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.83MB / 3.83MB, 8.23MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.82MB / 3.82MB, 8.23MB/s  \u001b[A\n\n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.83MB / 3.83MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.83MB / 3.83MB, 5.49MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.82MB / 3.82MB, 5.49MB/s  \n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.83MB / 3.83MB            \nUploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.35s/ shards]\nREADME.md: 1.29kB [00:00, 4.22MB/s]\n\n‚úì Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\n‚úÖ COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/val_seen_style_unseen_char\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\n‚úì Validated directory structure\n  Content images: my_dataset/val_seen_style_unseen_char/ContentImage\n  Target images: my_dataset/val_seen_style_unseen_char/TargetImage\n\n============================================================\nBUILDING DATASET\n============================================================\n\nüñºÔ∏è  Discovering images from disk...\n  ‚úì Found 122 content images\n  ‚úì Found 1342 target images\n\nüìã Loading 1342 image pairs...\nLoading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1342/1342 [00:01<00:00, 1256.22pair/s]\n‚úì Loaded 1342 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: val_seen_style_unseen_char\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1342/1342 [00:00<00:00, 18284.44 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 33.91ba/s]\u001b[A\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :  11%|‚ñà‚ñå            | 1.31MB / 12.2MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  11%|‚ñà‚ñå            | 1.31MB / 12.2MB,   ???B/s  \u001b[A\u001b[A\nNew Data Upload               :   5%|‚ñã             |  524kB / 11.4MB,   ???B/s  \u001b[A\n\nProcessing Files (0 / 1)      :  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã     | 7.60MB / 12.2MB, 31.5MB/s  \u001b[A\u001b[A\nNew Data Upload               :  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç     | 6.82MB / 11.4MB, 31.5MB/s  \u001b[A\n\nProcessing Files (0 / 1)      :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 11.8MB / 12.2MB, 26.2MB/s  \u001b[A\u001b[A\nNew Data Upload               :  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 11.0MB / 11.4MB, 26.2MB/s  \u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.2MB / 12.2MB, 18.1MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.4MB / 11.4MB, 18.1MB/s  \u001b[A\n\n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.2MB / 12.2MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.2MB / 12.2MB, 13.6MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.4MB / 11.4MB, 13.6MB/s  \n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.2MB / 12.2MB            \nUploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.65s/ shards]\nREADME.md: 1.29kB [00:00, 2.85MB/s]\n\n‚úì Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\n‚úÖ COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/val_unseen_style_seen_char\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\n‚úì Validated directory structure\n  Content images: my_dataset/val_unseen_style_seen_char/ContentImage\n  Target images: my_dataset/val_unseen_style_seen_char/TargetImage\n\n============================================================\nBUILDING DATASET\n============================================================\n\nüñºÔ∏è  Discovering images from disk...\n  ‚úì Found 279 content images\n  ‚úì Found 837 target images\n\nüìã Loading 837 image pairs...\nLoading images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 837/837 [00:00<00:00, 1282.95pair/s]\n‚úì Loaded 837 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: val_unseen_style_seen_char\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 837/837 [00:00<00:00, 17928.04 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 39.27ba/s]\u001b[A\nProcessing Files (0 / 0)      : |                  |  0.00B /  0.00B            \nNew Data Upload               : |                  |  0.00B /  0.00B            \u001b[A\n\n                              :  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 6.16MB / 12.5MB            \u001b[A\u001b[A\n\nProcessing Files (0 / 1)      :  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ       | 6.16MB / 12.5MB,   ???B/s  \u001b[A\u001b[A\nNew Data Upload               :   8%|‚ñà             |  524kB / 6.90MB,   ???B/s  \u001b[A\n\nProcessing Files (0 / 1)      :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 12.5MB / 12.5MB, 31.6MB/s  \u001b[A\u001b[A\nNew Data Upload               :  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 6.82MB / 6.90MB, 31.6MB/s  \u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.5MB / 12.5MB, 15.9MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.90MB / 6.90MB, 15.9MB/s  \u001b[A\n\n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.5MB / 12.5MB            \u001b[A\u001b[A\n\nProcessing Files (1 / 1)      : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.5MB / 12.5MB, 10.6MB/s  \u001b[A\u001b[A\nNew Data Upload               : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.90MB / 6.90MB, 10.6MB/s  \n                              : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.5MB / 12.5MB            \nUploading the dataset shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01<00:00,  1.58s/ shards]\nREADME.md: 1.29kB [00:00, 1.82MB/s]\n\n‚úì Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\n‚úÖ COMPLETE!\nSUCCESSFULLY UPLOAD LOCAL MY_DATASET TO HUGGINGFACE DATASETS SPACE\n","output_type":"stream"}],"execution_count":24},{"id":"a87caab2","cell_type":"code","source":"import torch, gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"zXSQHJ3xVOSc","outputId":"4d89a176-c286-442f-eb6e-01b39c994e64","papermill":{"duration":1.992585,"end_time":"2025-12-30T18:55:24.769269","exception":false,"start_time":"2025-12-30T18:55:22.776684","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"267634e8","cell_type":"code","source":"# TRAINING PHASE 1\n!uv pip install \"huggingface-hub==0.25.2\"\nimport wandb\n\n# Load your Weights & Biases API key from a secure store\nwandb_key = load_secret(\"WANDB_API_KEY\")\nwandb.login(key=wandb_key)\n\n# Run the training script with the corrected flag syntax\n!accelerate launch FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=FontDiffuser_training_phase_1 \\\n    --data_root=my_dataset \\\n    --output_dir=outputs/FontDiffuser \\\n    --report_to=wandb \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.7 \\\n    --max_train_steps=200 \\\n    --ckpt_interval=100 \\\n    --val_interval=200 \\\n    --gradient_accumulation_steps=1 \\\n    --log_interval=50 \\\n    --learning_rate=1e-4 \\\n    --lr_scheduler=linear \\\n    --lr_warmup_steps=10000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=no","metadata":{"execution":{"iopub.status.busy":"2025-12-31T12:48:49.468622Z","iopub.execute_input":"2025-12-31T12:48:49.468916Z","iopub.status.idle":"2025-12-31T12:49:05.737480Z","shell.execute_reply.started":"2025-12-31T12:48:49.468888Z","shell.execute_reply":"2025-12-31T12:49:05.736719Z"},"id":"FxxJ9qy4KIZH","outputId":"f554de7b-f455-4a5b-f8e5-4b6cba3f756b","papermill":{"duration":0.021927,"end_time":"2025-12-30T18:55:24.807644","exception":false,"start_time":"2025-12-30T18:55:24.785717","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 4ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m25.2                              \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.36.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.25.2\u001b[0m\nAttempting to load secret 'WANDB_API_KEY' from 'kaggle' environment...\n‚úÖ Successfully loaded secret 'WANDB_API_KEY'.\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2025-12-31 12:48:59.155298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-12-31 12:48:59.155831: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767185339.187491    1834 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767185339.188524    1833 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767185339.198717    1833 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1767185339.199415    1834 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 33, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 8, in <module>\n    from keras.api import activations\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\", line 7, in <module>\n    from keras.src.activations import deserialize\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\", line 13, in <module>\n    from keras.src import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/__init__.py\", line 2, in <module>\n    from keras.src.visualization import plot_image_gallery\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_image_gallery.py\", line 13, in <module>\n    import matplotlib.pyplot as plt\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 33, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 8, in <module>\n    from keras.api import activations\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/activations/__init__.py\", line 7, in <module>\n    from keras.src.activations import deserialize\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/__init__.py\", line 13, in <module>\n    from keras.src import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/__init__.py\", line 2, in <module>\n    from keras.src.visualization import plot_image_gallery\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_image_gallery.py\", line 13, in <module>\n    import matplotlib.pyplot as plt\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\nAttributeError: _ARRAY_API not found\nAttributeError: _ARRAY_API not found\n\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 33, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 34, in <module>\n    from keras.api import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/visualization/__init__.py\", line 11, in <module>\n    from keras.src.visualization.plot_bounding_box_gallery import (\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_bounding_box_gallery.py\", line 12, in <module>\n    from matplotlib import patches  # For legend patches\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\nAttributeError: _ARRAY_API not found\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.4.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\nTraceback (most recent call last):  File \"/kaggle/working/FontDiffusion/my_train.py\", line 33, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 34, in <module>\n    from keras.api import visualization\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/visualization/__init__.py\", line 11, in <module>\n    from keras.src.visualization.plot_bounding_box_gallery import (\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/visualization/plot_bounding_box_gallery.py\", line 12, in <module>\n    from matplotlib import patches  # For legend patches\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/__init__.py\", line 129, in <module>\n    from . import _api, _version, cbook, _docstring, rcsetup\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/rcsetup.py\", line 27, in <module>\n    from matplotlib.colors import Colormap, is_color_like\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py\", line 56, in <module>\n    from matplotlib import _api, _cm, cbook, scale\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/scale.py\", line 22, in <module>\n    from matplotlib.ticker import (\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/ticker.py\", line 138, in <module>\n    from matplotlib import transforms as mtransforms\n  File \"/usr/local/lib/python3.11/dist-packages/matplotlib/transforms.py\", line 49, in <module>\n    from matplotlib._path import (\n^^^\nAttributeError:   File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n_ARRAY_API not found\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n    from ..integrations.deepspeed import is_deepspeed_zero3_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n    from .integration_utils import (\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n    from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    import tensorflow as tf\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    from keras.api import DTypePolicy\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 35, in <module>\n    from keras.api import wrappers\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/wrappers/__init__.py\", line 7, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/__init__.py\", line 1, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/sklearn_wrapper.py\", line 8, in <module>\n    from keras.src.wrappers.fixes import _routing_enabled\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/fixes.py\", line 2, in <module>\n    import sklearn\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\", line 82, in <module>\n    from .base import clone\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 17, in <module>\n    from .utils import _IS_32BIT\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\", line 19, in <module>\n    from .murmurhash import murmurhash3_32\n  File \"sklearn/utils/murmurhash.pyx\", line 1, in init sklearn.utils.murmurhash\nValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    return importlib.import_module(\".\" + module_name, self.__name__)\n         Traceback (most recent call last):\n    File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n    return importlib.import_module(\".\" + module_name, self.__name__)\n                    ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n^^^  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n^  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n^^  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n^^  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n           ^^^    ^from .generation import GenerationConfig, GenerationMixin\n^^^^^^  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n^^  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 27, in <module>\n        from ..integrations.deepspeed import is_deepspeed_zero3_enabledmodule = self._get_module(self._class_to_module[name])\n\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/__init__.py\", line 33, in <module>\n                 ^from .integration_utils import (^\n^^^^  File \"/usr/local/lib/python3.11/dist-packages/transformers/integrations/integration_utils.py\", line 71, in <module>\n^^^^^^^^^^^^^^^^^^^^^^^    ^from ..trainer_callback import ProgressCallback, TrainerCallback  # noqa: E402^\n^^^^^^^ ^ ^ ^ ^^^^^^^^\n^^  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^raise RuntimeError(^\n^^RuntimeError^: ^Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject^\n^\n^^The above exception was the direct cause of the following exception:\n^^\n^^Traceback (most recent call last):\n^^^^  File \"/kaggle/working/FontDiffusion/my_train.py\", line 33, in <module>\n^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_callback.py\", line 26, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .trainer_utils import IntervalStrategy, has_length\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer_utils.py\", line 49, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    import tensorflow as tf\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\", line 467, in <module>\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    importlib.import_module(\"keras.src.optimizers\")\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n    return _bootstrap._gcd_import(name[level:], package, level)  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/keras/__init__.py\", line 2, in <module>\n    value = getattr(module, name)\n          from keras.api import DTypePolicy \n     ^  File \"/usr/local/lib/python3.11/dist-packages/keras/api/__init__.py\", line 35, in <module>\n^^^^^^^^^^^^^^^^^    ^from keras.api import wrappers^\n^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n  File \"/usr/local/lib/python3.11/dist-packages/keras/api/wrappers/__init__.py\", line 7, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/__init__.py\", line 1, in <module>\n    from keras.src.wrappers.sklearn_wrapper import SKLearnClassifier\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/sklearn_wrapper.py\", line 8, in <module>\n    module = self._get_module(self._class_to_module[name])\n      from keras.src.wrappers.fixes import _routing_enabled \n      File \"/usr/local/lib/python3.11/dist-packages/keras/src/wrappers/fixes.py\", line 2, in <module>\n      ^^^^^^^^^^^^^^^    ^import sklearn^\n^^^  File \"/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\", line 82, in <module>\n^^^^^^^^^^^^^^^^    ^from .base import clone^\n^^^^^  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 17, in <module>\n^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    from .utils import _IS_32BIT\n  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\", line 19, in <module>\n    from .murmurhash import murmurhash3_32\n  File \"sklearn/utils/murmurhash.pyx\", line 1, in init sklearn.utils.murmurhash\nValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1184, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.models.clip.modeling_clip because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n    return importlib.import_module(\".\" + module_name, self.__name__)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/clip/modeling_clip.py\", line 27, in <module>\n    from ...modeling_utils import PreTrainedModel\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\", line 39, in <module>\n    from .generation import GenerationConfig, GenerationMixin\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/kaggle/working/FontDiffusion/my_train.py\", line 33, in <module>\n    from src import (\n  File \"/kaggle/working/FontDiffusion/src/__init__.py\", line 12, in <module>\n    from .build_optimized import (\n  File \"/kaggle/working/FontDiffusion/src/build_optimized.py\", line 8, in <module>\n    from diffusers.models.attention_processor import AttnProcessor2_0\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/attention_processor.py\", line 24, in <module>\n    from .lora import LoRACompatibleLinear, LoRALinearLayer\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/models/lora.py\", line 21, in <module>\n    from ..loaders import PatchedLoraProjection, text_encoder_attn_modules, text_encoder_mlp_modules\n  File \"/usr/local/lib/python3.11/dist-packages/diffusers/loaders.py\", line 55, in <module>\n    from transformers import CLIPTextModel, CLIPTextModelWithProjection, PreTrainedModel\n  File \"<frozen importlib._bootstrap>\", line 1229, in _handle_fromlist\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1175, in __getattr__\n    value = getattr(module, name)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1174, in __getattr__\n    module = self._get_module(self._class_to_module[name])\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/import_utils.py\", line 1186, in _get_module\n    raise RuntimeError(\nRuntimeError: Failed to import transformers.models.clip.modeling_clip because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nnumpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\nE1231 12:49:04.798000 1825 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 1833) of binary: /usr/bin/python3\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n    multi_gpu_launcher(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n    distrib_run.run(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 909, in run\n    elastic_launch(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\nFontDiffusion/my_train.py FAILED\n------------------------------------------------------------\nFailures:\n[1]:\n  time      : 2025-12-31_12:49:04\n  host      : bde74ed14eec\n  rank      : 1 (local_rank: 1)\n  exitcode  : 1 (pid: 1834)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-12-31_12:49:04\n  host      : bde74ed14eec\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 1833)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}],"execution_count":27},{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","cell_type":"code","source":"!ls -lr outputs/FontDiffuser","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"97f8136e","cell_type":"code","source":"# TRAINING PHASE 2\n!wandb login\n!python FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_2\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --phase_2 \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_2000\" \\\n    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n    --sc_coefficient=0.05 \\\n    --num_neg=13 \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.4 \\\n    --max_train_steps=100 \\\n    --ckpt_interval=50 \\\n    --gradient_accumulation_steps=2 \\\n    --log_interval=50 \\\n    --learning_rate=1e-5 \\\n    --lr_scheduler=\"constant\" \\\n    --lr_warmup_steps=1000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"\n","metadata":{"id":"J4bplsS6pQna","papermill":{"duration":0.022471,"end_time":"2025-12-30T18:55:24.845778","exception":false,"start_time":"2025-12-30T18:55:24.823307","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"88c45e2f","cell_type":"code","source":"!python FontDiffusion/pth2safetensors.py \\\n    --weights_dir \"ckpt\" \\\n    --repo_id \"dzungpham/font-diffusion-weights\" \\\n    --token \"{HF_TOKEN}\"","metadata":{"id":"nF8opWokKcMS","outputId":"2838655d-5d24-4808-813a-39f20ec239a8","papermill":{"duration":0.217876,"end_time":"2025-12-30T18:55:25.079820","exception":false,"start_time":"2025-12-30T18:55:24.861944","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"5868b20b","cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\nfrom typing import List\ndef find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n\ndef zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n    folder_name = folder_path.name\n    zip_path = output_base_path / f\"{folder_name}.zip\"\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for file_path in folder_path.rglob(\"*\"):\n                if file_path.is_file():\n                    arcname = file_path.relative_to(folder_path.parent)\n                    zipf.write(file_path, arcname)\n        print(f\"   ‚úÖ Created ZIP: {zip_path.name}\")\n        return True\n    except Exception as exc:\n        print(f\"   ‚ùå Failed to zip {folder_name}: {exc}\")\n        return False\n\ndef zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n    base = Path(output_base_path)\n    base.mkdir(parents=True, exist_ok=True)\n    result_folders = find_result_folders(base, pattern_name)\n    if not result_folders:\n        print(f\"‚ö†Ô∏è No folders matching '*dataset' found in '{output_base_path}'.\")\n        return\n    print(f\"üîç Found {len(result_folders)} result folder(s) to zip.\")\n    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n    print(f\"\\n‚úÖ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        zip_stats_results_folders(\n            output_base_path=OUTPUT_PATH,\n            pattern_name=\"my_dataset\")\n    except Exception as e:\n        print(f\"‚ùå An error occurred: {e}\")","metadata":{"id":"kTz9WZ9ylBZx","outputId":"ccb61bf4-7551-4269-aee7-b0742fe1517a","papermill":{"duration":0.031197,"end_time":"2025-12-30T18:55:25.126961","exception":false,"start_time":"2025-12-30T18:55:25.095764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}