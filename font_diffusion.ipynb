{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWFvN9XJxf9K",
        "outputId": "ba1d7c30-ac4c-4271-fcf3-3ee6ed0fd72c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MPLBACKEND environment variable cleared.\n",
            "Cloning into 'FontDiffusion'...\n",
            "remote: Enumerating objects: 15052, done.\u001b[K\n",
            "remote: Counting objects: 100% (2865/2865), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2792/2792), done.\u001b[K\n",
            "remote: Total 15052 (delta 92), reused 2838 (delta 71), pack-reused 12187 (from 3)\u001b[K\n",
            "Receiving objects: 100% (15052/15052), 246.86 MiB | 20.03 MiB/s, done.\n",
            "Resolving deltas: 100% (480/480), done.\n",
            "Updating files: 100% (110/110), done.\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 112ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 106ms\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m116 packages\u001b[0m \u001b[2min 659ms\u001b[0m\u001b[0m\n",
            "\u001b[2K  \u001b[31m√ó\u001b[0m Failed to build `tokenizers==0.13.3`\n",
            "\u001b[31m  ‚îú‚îÄ‚ñ∂ \u001b[0mThe build backend returned an error\n",
            "\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mCall to `setuptools.build_meta.build_wheel` failed (exit status: 1)\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stdout]\u001b[39m\n",
            "\u001b[31m      \u001b[0mrunning bdist_wheel\n",
            "\u001b[31m      \u001b[0mrunning build\n",
            "\u001b[31m      \u001b[0mrunning build_py\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/byte_level_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_unigram.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/char_level_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/base_tokenizer.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/bert_wordpiece.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer-styles.css ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mrunning build_ext\n",
            "\u001b[31m      \u001b[0mrunning build_rust\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n",
            "\u001b[31m      \u001b[0m/root/.cache/uv/builds-v0/.tmpsz6cXS/lib/python3.12/site-packages/setuptools/dist.py:759:\n",
            "\u001b[31m      \u001b[0mSetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "\u001b[31m      \u001b[0m!!\n",
            "\n",
            "\u001b[31m      \u001b[0m\n",
            "\u001b[31m      \u001b[0m********************************************************************************\n",
            "\u001b[31m      \u001b[0m        Please consider removing the following classifiers in favor of a\n",
            "\u001b[31m      \u001b[0mSPDX license expression:\n",
            "\n",
            "\u001b[31m      \u001b[0m        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "\u001b[31m      \u001b[0m        See\n",
            "\u001b[31m      \u001b[0mhttps://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license\n",
            "\u001b[31m      \u001b[0mfor details.\n",
            "\u001b[31m      \u001b[0m\n",
            "\u001b[31m      \u001b[0m********************************************************************************\n",
            "\n",
            "\u001b[31m      \u001b[0m!!\n",
            "\u001b[31m      \u001b[0m  self._finalize_license_expression()\n",
            "\u001b[31m      \u001b[0merror: can't find Rust compiler\n",
            "\n",
            "\u001b[31m      \u001b[0mIf you are using an outdated pip version, it is possible a prebuilt\n",
            "\u001b[31m      \u001b[0mwheel is available for this package but pip is not able to install from\n",
            "\u001b[31m      \u001b[0mit. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "\n",
            "\u001b[31m      \u001b[0mTo update pip, run:\n",
            "\n",
            "\u001b[31m      \u001b[0m    pip install --upgrade pip\n",
            "\n",
            "\u001b[31m      \u001b[0mand then retry package installation.\n",
            "\n",
            "\u001b[31m      \u001b[0mIf you did intend to build this package from source, try installing\n",
            "\u001b[31m      \u001b[0ma Rust compiler from your system package manager and ensure it is\n",
            "\u001b[31m      \u001b[0mon the PATH during installation. Alternatively, rustup (available at\n",
            "\u001b[31m      \u001b[0mhttps://rustup.rs) is the recommended way to download and update the\n",
            "\u001b[31m      \u001b[0mRust compiler toolchain.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n",
            "\u001b[31m      \u001b[0menvironment.\n",
            "\u001b[36m  help: \u001b[0m`\u001b[36mtokenizers\u001b[39m` (\u001b[36mv0.13.3\u001b[39m) was included because `\u001b[36mtransformers\u001b[39m` (\u001b[36mv4.33.1\u001b[39m)\n",
            "        depends on `\u001b[36mtokenizers\u001b[39m`\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m\n",
            "\n",
            "‚¨áÔ∏è Installing PyTorch 1.13 (Required for this model)...\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 806ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0+cu126\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0+cu126\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K  \u001b[31m√ó\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mBecause torch==1.13.1+cu117 has no wheels with a matching Python ABI\n",
            "\u001b[31m      \u001b[0mtag (e.g., `\u001b[36mcp312\u001b[39m`) and you require torch==1.13.1+cu117, we can conclude\n",
            "\u001b[31m      \u001b[0mthat your requirements are unsatisfiable.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m `\u001b[36mtorch\u001b[39m` was found on \u001b[36mhttps://download.pytorch.org/whl/cu117\u001b[39m, but\n",
            "\u001b[31m      \u001b[0mnot at the requested version (\u001b[36mtorch==1.13.1+cu117\u001b[39m). A compatible version\n",
            "\u001b[31m      \u001b[0mmay be available on a subsequent index (e.g., \u001b[36mhttps://pypi.org/simple\u001b[39m).\n",
            "\u001b[31m      \u001b[0mBy default, uv will only consider versions that are published on the\n",
            "\u001b[31m      \u001b[0mfirst index that contains a given package, to avoid dependency confusion\n",
            "\u001b[31m      \u001b[0mattacks. If all indexes are equally trusted, use `\u001b[32m--index-strategy\n",
            "\u001b[31m      \u001b[0munsafe-best-match\u001b[39m` to consider all versions from all indexes, regardless\n",
            "\u001b[31m      \u001b[0mof the order in which they were defined.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.12\u001b[39m (`\u001b[36mcp312\u001b[39m`), but we only found wheels for\n",
            "\u001b[31m      \u001b[0m`\u001b[36mtorch\u001b[39m` (\u001b[36mv1.13.1+cu117\u001b[39m) with the following Python ABI tags: `\u001b[36mcp37m\u001b[39m`,\n",
            "\u001b[31m      \u001b[0m`\u001b[36mcp38\u001b[39m`, `\u001b[36mcp39\u001b[39m`, `\u001b[36mcp310\u001b[39m`, `\u001b[36mcp311\u001b[39m`\n",
            "\n",
            "‚¨áÔ∏è Installing Dependencies (Manually fixed)...\n",
            "  \u001b[31m√ó\u001b[0m No solution found when resolving dependencies:\n",
            "\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mBecause torch==1.13.1 has no wheels with a matching Python ABI tag\n",
            "\u001b[31m      \u001b[0m(e.g., `\u001b[36mcp312\u001b[39m`) and xformers==0.0.16 depends on torch==1.13.1, we can\n",
            "\u001b[31m      \u001b[0mconclude that xformers==0.0.16 cannot be used.\n",
            "\u001b[31m      \u001b[0mAnd because you require xformers==0.0.16, we can conclude that your\n",
            "\u001b[31m      \u001b[0mrequirements are unsatisfiable.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.12\u001b[39m (`\u001b[36mcp312\u001b[39m`), but we only found wheels for\n",
            "\u001b[31m      \u001b[0m`\u001b[36mtorch\u001b[39m` (\u001b[36mv1.13.1\u001b[39m) with the following Python ABI tags: `\u001b[36mcp37m\u001b[39m`, `\u001b[36mcp38\u001b[39m`,\n",
            "\u001b[31m      \u001b[0m`\u001b[36mcp39\u001b[39m`, `\u001b[36mcp310\u001b[39m`, `\u001b[36mcp311\u001b[39m`\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m47 packages\u001b[0m \u001b[2min 87ms\u001b[0m\u001b[0m\n",
            "\u001b[2K  \u001b[31m√ó\u001b[0m Failed to build `tokenizers==0.13.3`\n",
            "\u001b[31m  ‚îú‚îÄ‚ñ∂ \u001b[0mThe build backend returned an error\n",
            "\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mCall to `setuptools.build_meta.build_wheel` failed (exit status: 1)\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stdout]\u001b[39m\n",
            "\u001b[31m      \u001b[0mrunning bdist_wheel\n",
            "\u001b[31m      \u001b[0mrunning build\n",
            "\u001b[31m      \u001b[0mrunning build_py\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/byte_level_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_unigram.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/char_level_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_bpe.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/base_tokenizer.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/bert_wordpiece.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/__init__.py ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.pyi ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n",
            "\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer-styles.css ->\n",
            "\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n",
            "\u001b[31m      \u001b[0mrunning build_ext\n",
            "\u001b[31m      \u001b[0mrunning build_rust\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n",
            "\u001b[31m      \u001b[0m/root/.cache/uv/builds-v0/.tmpXIlyt8/lib/python3.12/site-packages/setuptools/dist.py:759:\n",
            "\u001b[31m      \u001b[0mSetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
            "\u001b[31m      \u001b[0m!!\n",
            "\n",
            "\u001b[31m      \u001b[0m\n",
            "\u001b[31m      \u001b[0m********************************************************************************\n",
            "\u001b[31m      \u001b[0m        Please consider removing the following classifiers in favor of a\n",
            "\u001b[31m      \u001b[0mSPDX license expression:\n",
            "\n",
            "\u001b[31m      \u001b[0m        License :: OSI Approved :: Apache Software License\n",
            "\n",
            "\u001b[31m      \u001b[0m        See\n",
            "\u001b[31m      \u001b[0mhttps://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license\n",
            "\u001b[31m      \u001b[0mfor details.\n",
            "\u001b[31m      \u001b[0m\n",
            "\u001b[31m      \u001b[0m********************************************************************************\n",
            "\n",
            "\u001b[31m      \u001b[0m!!\n",
            "\u001b[31m      \u001b[0m  self._finalize_license_expression()\n",
            "\u001b[31m      \u001b[0merror: can't find Rust compiler\n",
            "\n",
            "\u001b[31m      \u001b[0mIf you are using an outdated pip version, it is possible a prebuilt\n",
            "\u001b[31m      \u001b[0mwheel is available for this package but pip is not able to install from\n",
            "\u001b[31m      \u001b[0mit. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "\n",
            "\u001b[31m      \u001b[0mTo update pip, run:\n",
            "\n",
            "\u001b[31m      \u001b[0m    pip install --upgrade pip\n",
            "\n",
            "\u001b[31m      \u001b[0mand then retry package installation.\n",
            "\n",
            "\u001b[31m      \u001b[0mIf you did intend to build this package from source, try installing\n",
            "\u001b[31m      \u001b[0ma Rust compiler from your system package manager and ensure it is\n",
            "\u001b[31m      \u001b[0mon the PATH during installation. Alternatively, rustup (available at\n",
            "\u001b[31m      \u001b[0mhttps://rustup.rs) is the recommended way to download and update the\n",
            "\u001b[31m      \u001b[0mRust compiler toolchain.\n",
            "\n",
            "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n",
            "\u001b[31m      \u001b[0menvironment.\n",
            "\u001b[36m  help: \u001b[0m`\u001b[36mtokenizers\u001b[39m` (\u001b[36mv0.13.3\u001b[39m) was included because `\u001b[36mtransformers\u001b[39m` (\u001b[36mv4.33.1\u001b[39m)\n",
            "        depends on `\u001b[36mtokenizers\u001b[39m`\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m91 packages\u001b[0m \u001b[2min 55ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m13 packages\u001b[0m \u001b[2min 33.61s\u001b[0m\u001b[0m\n",
            "\u001b[2mUninstalled \u001b[1m21 packages\u001b[0m \u001b[2min 241ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m25 packages\u001b[0m \u001b[2min 238ms\u001b[0m\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==24.1.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.50.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.14.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==0.7.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1minfo-nce-pytorch\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia\u001b[0m\u001b[2m==0.8.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mkornia-rs\u001b[0m\u001b[2m==0.1.10\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.1\u001b[0m\n",
            " \u001b[31m-\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==11.0.3\u001b[0m\n",
            "\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `typer==0.20.0` does not have an extra named `all`\u001b[0m\n",
            "\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n",
            "\u001b[2K\u001b[2mResolved \u001b[1m38 packages\u001b[0m \u001b[2min 72ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m\n",
            "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mpytorch-fid\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
            " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n",
            "Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://cli.github.com/packages stable/main amd64 Packages [345 B]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n",
            "Fetched 38.3 MB in 5s (8,199 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  dos2unix\n",
            "0 upgraded, 1 newly installed, 0 to remove and 54 not upgraded.\n",
            "Need to get 384 kB of archives.\n",
            "After this operation, 1,367 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dos2unix amd64 7.4.2-2 [384 kB]\n",
            "Fetched 384 kB in 1s (336 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package dos2unix.\n",
            "(Reading database ... 121689 files and directories currently installed.)\n",
            "Preparing to unpack .../dos2unix_7.4.2-2_amd64.deb ...\n",
            "Unpacking dos2unix (7.4.2-2) ...\n",
            "Setting up dos2unix (7.4.2-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\n",
            "‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\n"
          ]
        }
      ],
      "source": [
        "# @title Environment Setup\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. *** FIX: Clear problematic environment variable for matplotlib ***\n",
        "# This prevents the \"ValueError: Key backend: 'module://matplotlib_inline.backend_inline'\" error\n",
        "if 'MPLBACKEND' in os.environ:\n",
        "    del os.environ['MPLBACKEND']\n",
        "    print(\"MPLBACKEND environment variable cleared.\")\n",
        "\n",
        "# 2. Clone the repository\n",
        "!rm -rf FontDiffusion\n",
        "!git clone https://github.com/dzungphieuluuky/FontDiffusion.git\n",
        "\n",
        "!uv pip install --upgrade pip\n",
        "!uv pip install -r FontDiffusion/requirements.txt\n",
        "!uv pip install gdown\n",
        "# 3. Install PyTorch 1.13\n",
        "print(\"\\n‚¨áÔ∏è Installing PyTorch 1.13 (Required for this model)...\")\n",
        "# Force reinstall torch 1.13 to match the model's training environment\n",
        "!uv pip uninstall torch torchvision\n",
        "!uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "# 4. Install other dependencies\n",
        "print(\"\\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\")\n",
        "# Install xformers compatible with Torch 1.13\n",
        "!uv pip install xformers==0.0.16 -q\n",
        "\n",
        "# Install original dependencies\n",
        "!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n",
        "!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n",
        "# -----------------------------------------------------------------\n",
        "!uv pip install lpips scikit-image pytorch-fid\n",
        "!sudo apt-get update && sudo apt-get install dos2unix\n",
        "print(\"\\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxdyquWfaqdm",
        "outputId": "aaf97a2b-65a4-4a29-c69f-5c0c38638c3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Environment: Google Colab\n",
            "üìÇ Data Path: /content/\n",
            "üì¶ Output Path: /content/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from IPython import get_ipython\n",
        "\n",
        "def configure_environment_paths():\n",
        "    \"\"\"Detect environment and configure paths\"\"\"\n",
        "    try:\n",
        "        if \"google.colab\" in str(get_ipython()):\n",
        "            print(\"‚úÖ Environment: Google Colab\")\n",
        "            base_data_path = \"/content/\"\n",
        "            base_output_path = \"/content/\"\n",
        "            environment_name = \"colab\"\n",
        "        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
        "            print(\"‚úÖ Environment: Kaggle\")\n",
        "            base_data_path = \"/kaggle/input/\"\n",
        "            base_output_path = \"/kaggle/working/\"\n",
        "            environment_name = \"kaggle\"\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n",
        "            base_data_path = \"./data/\"\n",
        "            base_output_path = \"./output/\"\n",
        "            environment_name = \"local\"\n",
        "    except NameError:\n",
        "        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n",
        "        base_data_path = \"./data/\"\n",
        "        base_output_path = \"./output/\"\n",
        "        environment_name = \"local\"\n",
        "\n",
        "    os.makedirs(base_output_path, exist_ok=True)\n",
        "    print(f\"üìÇ Data Path: {base_data_path}\")\n",
        "    print(f\"üì¶ Output Path: {base_output_path}\")\n",
        "\n",
        "    return base_data_path, base_output_path, environment_name\n",
        "\n",
        "\n",
        "INPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h06w314Jaqdm",
        "outputId": "75176f26-5b20-4ea6-d788-ee5be8d780e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import wandb\n",
        "\n",
        "if \"colab\" in ENV_NAME:\n",
        "    from google.colab import userdata\n",
        "\n",
        "    try:\n",
        "        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n",
        "        wandb_key = userdata.get(\"WANDB_API_KEY\")\n",
        "        wandb.login(key=wandb_key)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n",
        "\n",
        "# 2. Check if running in Kaggle\n",
        "elif \"kaggle\" in ENV_NAME:\n",
        "    try:\n",
        "        from kaggle_secrets import UserSecretsClient\n",
        "\n",
        "        user_secrets = UserSecretsClient()\n",
        "        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n",
        "        wandb.login(key=wandb_key)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "\n",
        "if not os.path.exists(\"ckpt\"):\n",
        "  url = \"https://drive.google.com/drive/folders/12hfuZ9MQvXqcteNuz7JQ2B_mUcTr-5jZ\"\n",
        "  gdown.download_folder(url, quiet=True, use_cookies=False)"
      ],
      "metadata": {
        "id": "9PsLgUs0cYmO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecfc18e0",
        "outputId": "06c02820-3c0c-4246-f079-945e7a40d742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No .zip files found in /content/.\n"
          ]
        }
      ],
      "source": [
        "# @title Unzipping all archived files\n",
        "import os\n",
        "import glob\n",
        "from zipfile import ZipFile\n",
        "\n",
        "zip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n",
        "\n",
        "if not zip_file_paths:\n",
        "    print(f'No .zip files found in {INPUT_PATH}.')\n",
        "else:\n",
        "    for zip_file_path in zip_file_paths:\n",
        "        if os.path.exists(zip_file_path):\n",
        "            print(f'Unzipping {zip_file_path}...')\n",
        "            !unzip -q -o {zip_file_path} -d ./\n",
        "            print(f'Unzipping of {zip_file_path} complete.')\n",
        "        else:\n",
        "            print(f'Error: The file {zip_file_path} was not found (post-glob check).')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBflCTABxlF4",
        "outputId": "6b03581b-e20c-4d44-8d7c-bd3d63f5ff4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ckpt\n",
            "\n",
            "‚úÖ All weights found! You can proceed to the next step.\n"
          ]
        }
      ],
      "source": [
        "# @title Checking checkpoint files (.pth)\n",
        "import os\n",
        "import time\n",
        "\n",
        "CHECKPOINT_DIR = os.path.join(INPUT_PATH, \"ckpt\")\n",
        "print(CHECKPOINT_DIR)\n",
        "# Create the checkpoint directory\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "# Wait loop to check if files exist\n",
        "required_files = [\"unet.pth\", \"content_encoder.pth\", \"style_encoder.pth\"]\n",
        "\n",
        "while True:\n",
        "    missing = [f for f in required_files if not os.path.exists(f\"{CHECKPOINT_DIR}/{f}\")]\n",
        "\n",
        "    if not missing:\n",
        "        print(\"\\n‚úÖ All weights found! You can proceed to the next step.\")\n",
        "        break\n",
        "    else:\n",
        "        print(f\"Waiting for files... Missing: {missing}\")\n",
        "        print(\"Upload them to the 'ckpt' folder now.\")\n",
        "        time.sleep(10) # Checks every 10 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Mx5uS5WQaqdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "448e1707-8e07-4cdb-db28-f319e3a9d533"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid non-printable character U+F07B8 (ipython-input-1462724732.py, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1462724732.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    kieu = [§æì,¢Ü•,•™û,ÊèÜ,†äõ,‰∫õ,°¶Ç,Êâç,°¶Ç,ÂëΩ,Á™ñ,±∫µ,ÊÅÑ,È•í,£¶Ü,Êàà,Ê≤°,Â±Ä,£∑≠,Ê©∑,‰ªç,Ë™ø,¨ñâ,ß°ä,„êå,§¥¨,Áñ∏,¢ö∏,®îç,‰πã,ÂΩº,Âóá,ÊñØ,Ë±ä,°ó∂,Êíë,Ê∂ì,Ë≤ù,¶üê,Á¥Ö,Êâì,„≠¥,Á®ø,¶π≥,Âêù,±†é,†ìÄ,Áïë,È¢®,ÊÉÖ,Âõ∫,ÈåÑ,Áæ§,ÂÇ≥,Âè≤,Êíë,Êµ™,¢Ü•,Û∞û∏,Èùñ,Êúù,Êòé,¶äö,Êñπ,™πö,£ºΩ,†Ñ©,‰∫¨,Âá≠,ÈêÑ,Âõ∫,Ëåπ,Âì°,Â§ñ,Êà∑,Áéã,ÂÆ∂,Ë≥á,Êì¨,Êã±,Â∏∏,Â∏∏,Â†õ,‰∏≠]\u001b[0m\n\u001b[0m                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+F07B8\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "nom_tu_tao_300_df = pd.read_csv(f\"{INPUT_PATH}/Ds_300_ChuNom_TuTao.csv\")\n",
        "nom_tu_tao = nom_tu_tao_300_df['word'].tolist()\n",
        "\n",
        "with open(f\"{OUTPUT_PATH}/nom_tu_tao.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(\"\\n\".join(nom_tu_tao))\n",
        "kieu = [§æì,¢Ü•,•™û,ÊèÜ,†äõ,‰∫õ,°¶Ç,Êâç,°¶Ç,ÂëΩ,Á™ñ,±∫µ,ÊÅÑ,È•í,£¶Ü,Êàà,Ê≤°,Â±Ä,£∑≠,Ê©∑,‰ªç,Ë™ø,¨ñâ,ß°ä,„êå,§¥¨,Áñ∏,¢ö∏,®îç,‰πã,ÂΩº,Âóá,ÊñØ,Ë±ä,°ó∂,Êíë,Ê∂ì,Ë≤ù,¶üê,Á¥Ö,Êâì,„≠¥,Á®ø,¶π≥,Âêù,±†é,†ìÄ,Áïë,È¢®,ÊÉÖ,Âõ∫,ÈåÑ,Áæ§,ÂÇ≥,Âè≤,Êíë,Êµ™,¢Ü•,Û∞û∏,Èùñ,Êúù,Êòé,¶äö,Êñπ,™πö,£ºΩ,†Ñ©,‰∫¨,Âá≠,ÈêÑ,Âõ∫,Ëåπ,Âì°,Â§ñ,Êà∑,Áéã,ÂÆ∂,Ë≥á,Êì¨,Êã±,Â∏∏,Â∏∏,Â†õ,‰∏≠]\n",
        "print(\",\".join(kieu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gma02BZvhx8I",
        "outputId": "a78c5252-10d9-4df7-e06a-ca46bbddc68c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'FontDiffusion'\n",
            "/content/FontDiffusion\n",
            "pygame 2.6.1 (SDL 2.28.4, Python 3.12.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "\n",
            "============================================================\n",
            "FONTDIFFUSER - OPTIMIZED SAMPLING\n",
            "============================================================\n",
            "Model: ../ckpt/\n",
            "Device: cuda:0\n",
            "FP16: False\n",
            "Channels Last: True\n",
            "Batch Size: 1\n",
            "============================================================\n",
            "\n",
            "Loading FontDiffuser pipeline...\n",
            "Load the down block  DownBlock2D\n",
            "Load the down block  MCADownBlock2D\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "Load the down block  MCADownBlock2D\n",
            "The style_attention cross attention dim in Down Block 1 layer is 1024\n",
            "The style_attention cross attention dim in Down Block 2 layer is 1024\n",
            "Load the down block  DownBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  StyleRSIUpBlock2D\n",
            "Load the up block  UpBlock2D\n",
            "Param count for Ds initialized parameters: 20591296\n",
            "Get CG-GAN Style Encoder!\n",
            "Param count for Ds initialized parameters: 1187008\n",
            "Get CG-GAN Content Encoder!\n",
            "‚úì Loaded model state_dict successfully\n",
            "Converting to channels-last memory format...\n",
            "2025-12-28 09:38:05.460578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766914685.478906   11059 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766914685.485995   11059 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766914685.504579   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766914685.504606   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766914685.504610   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766914685.504616   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-28 09:38:05.509381: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "‚úì Model moved to device\n",
            "‚úì Loaded training DDPM scheduler successfully\n",
            "‚úì Loaded DPM-Solver pipeline successfully\n",
            "\n",
            "============================================================\n",
            "BATCH MODE ACTIVATED\n",
            "Characters: 84\n",
            "============================================================\n",
            "‚úì Font loaded: NomNaTong-Regular\n",
            "\n",
            "[Font 1/1] NomNaTong-Regular\n",
            "------------------------------------------------------------\n",
            "Available characters: 84/84\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "Sampling 84 characters with DPM-Solver++ ...\n",
            "/content/FontDiffusion/src/model.py:88: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n",
            "  style_img_feature, _, style_residual_features = self.style_encoder(style_images)\n",
            "/content/FontDiffusion/src/model.py:94: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  content_img_feture, content_residual_features = self.content_encoder(content_images)\n",
            "/content/FontDiffusion/src/model.py:97: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n",
            "  style_content_feature, style_content_res_features = self.content_encoder(style_images)\n",
            "/content/FontDiffusion/src/model.py:102: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n",
            "  out = self.unet(\n",
            "‚úì Generated 84 images in 171.99s (2.048s/img)\n",
            "‚úì Saved 84 images to ../kieu_output/NomNaTong-Regular\n",
            "\n",
            "============================================================\n",
            "‚úì BATCH PROCESSING COMPLETE\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "%cd FontDiffusion\n",
        "!python sample_optimized.py \\\n",
        "    --ckpt_dir=\"../ckpt/\" \\\n",
        "    --style_image_path=\"/content/FontDiffusion/DVSKTT_ref.jpg\" \\\n",
        "    --save_image \\\n",
        "    --ttf_path=\"/content/FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n",
        "    --character_input \\\n",
        "    --content_character=\"§æì,¢Ü•,•™û,ÊèÜ,†äõ,‰∫õ,°¶Ç,Êâç,°¶Ç,ÂëΩ,Á™ñ,±∫µ,ÊÅÑ,È•í,£¶Ü,Êàà,Ê≤°,Â±Ä,£∑≠,Ê©∑,‰ªç,Ë™ø,¨ñâ,ß°ä,„êå,§¥¨,Áñ∏,¢ö∏,®îç,‰πã,ÂΩº,Âóá,ÊñØ,Ë±ä,°ó∂,Êíë,Ê∂ì,Ë≤ù,¶üê,Á¥Ö,Êâì,„≠¥,Á®ø,¶π≥,Âêù,±†é,†ìÄ,Áïë,È¢®,ÊÉÖ,Âõ∫,ÈåÑ,Áæ§,ÂÇ≥,Âè≤,Êíë,Êµ™,¢Ü•,Û∞û∏,Èùñ,Êúù,Êòé,¶äö,Êñπ,™πö,£ºΩ,†Ñ©,‰∫¨,Âá≠,ÈêÑ,Âõ∫,Ëåπ,Âì°,Â§ñ,Êà∑,Áéã,ÂÆ∂,Ë≥á,Êì¨,Êã±,Â∏∏,Â∏∏,Â†õ,‰∏≠\" \\\n",
        "    --save_image_dir=\"../kieu_output/\" \\\n",
        "    --device=\"cuda:0\" \\\n",
        "    --algorithm_type=\"dpmsolver++\" \\\n",
        "    --guidance_type=\"classifier-free\" \\\n",
        "    --guidance_scale=7.5 \\\n",
        "    --num_inference_steps=20 \\\n",
        "    --method=\"multistep\" \\\n",
        "    --channels_last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kTz9WZ9ylBZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beee5c89-037b-4336-fe52-3499e403b128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content//kieu_output/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ê©∑/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ê©∑/out_single.png (deflated 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/†Ñ©/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/†Ñ©/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â∏∏/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â∏∏/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áïë/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áïë/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/™πö/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/™πö/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊÉÖ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊÉÖ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êíë/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êíë/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Èùñ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Èùñ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ê≤°/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ê≤°/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¶äö/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¶äö/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÈåÑ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÈåÑ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂÇ≥/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂÇ≥/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊñØ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊñØ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â±Ä/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â±Ä/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êâì/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êâì/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/„≠¥/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/„≠¥/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰∏≠/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰∏≠/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/£¶Ü/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/£¶Ü/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/§¥¨/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/§¥¨/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰∫õ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰∫õ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/±∫µ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/±∫µ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êã±/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êã±/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ëåπ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ëåπ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âá≠/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âá≠/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Û∞û∏/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Û∞û∏/out_single.png (deflated 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÈêÑ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÈêÑ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/£ºΩ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/£ºΩ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/±†é/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/±†é/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/„êå/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/„êå/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¶üê/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¶üê/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Á™ñ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Á™ñ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/°ó∂/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/°ó∂/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âõ∫/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âõ∫/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êñπ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êñπ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áñ∏/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áñ∏/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂÆ∂/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂÆ∂/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰∫¨/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰∫¨/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂëΩ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂëΩ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âóá/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âóá/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êúù/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êúù/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/£∑≠/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/£∑≠/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/®îç/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/®îç/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/°¶Ç/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/°¶Ç/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰ªç/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰ªç/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë≥á/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë≥á/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/È•í/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/È•í/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â§ñ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â§ñ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊèÜ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊèÜ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áéã/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áéã/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êâç/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êâç/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¢ö∏/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¢ö∏/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¶π≥/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¶π≥/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êàà/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êàà/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âì°/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âì°/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊÅÑ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÊÅÑ/out_single.png (deflated 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Á®ø/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Á®ø/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂΩº/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ÂΩº/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¢Ü•/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¢Ü•/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Á¥Ö/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Á¥Ö/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ß°ä/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/ß°ä/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êµ™/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êµ™/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¨ñâ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/¨ñâ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë≤ù/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë≤ù/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/•™û/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/•™û/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë±ä/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë±ä/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â†õ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Â†õ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áæ§/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Áæ§/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/§æì/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/§æì/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/†ìÄ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/†ìÄ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/È¢®/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/È¢®/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êà∑/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êà∑/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êì¨/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êì¨/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âè≤/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âè≤/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êòé/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Êòé/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ê∂ì/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ê∂ì/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/†äõ/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/†äõ/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰πã/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/‰πã/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âêù/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Âêù/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë™ø/ (stored 0%)\n",
            "  adding: content//kieu_output/NomNaTong-Regular/Ë™ø/out_single.png (stored 0%)\n",
            "  adding: content//kieu_output/sampling_config.yaml (deflated 50%)\n",
            "Finish zipped the output data, ready for downloading\n"
          ]
        }
      ],
      "source": [
        "                                                        # @title Zipping the results folder\n",
        "!zip -r {OUTPUT_PATH}/kieu_output.zip {OUTPUT_PATH}/kieu_output\n",
        "print(f\"Finish zipped the output data, ready for downloading\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "SIH9c0l-mRqB"
      },
      "outputs": [],
      "source": [
        "# @title Happy Christmas‚ú®\n",
        "# !rm -r -f FontDiffusion"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}