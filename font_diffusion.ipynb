{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":127.636509,"end_time":"2025-12-30T18:55:25.961447","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-12-30T18:53:18.324938","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"a95a46ef","cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git","metadata":{"id":"a95a46ef","outputId":"d76d28cd-6292-42bf-fffa-a8c7efb86ed0","papermill":{"duration":12.857369,"end_time":"2025-12-30T18:53:35.066181","exception":false,"start_time":"2025-12-30T18:53:22.208812","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"9cdd8666","cell_type":"code","source":"import os\nimport sys\nfrom IPython import get_ipython\nfrom typing import Optional\n\ndef configure_environment_paths():\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"âœ… Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"âœ… Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"âš ï¸ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"âš ï¸ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"ðŸ“‚ Data Path: {base_data_path}\")\n    print(f\"ðŸ“¦ Output Path: {base_output_path}\")\n    return base_data_path, base_output_path, environment_name\n\ndef load_secret(key_name: str) -> Optional[str]:\n    env = ENV_NAME\n    secret_value = None\n    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n    try:\n        if env == \"colab\":\n            from google.colab import userdata\n            secret_value = userdata.get(key_name)\n        elif env == \"kaggle\":\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            secret_value = user_secrets.get_secret(key_name)\n        else:\n            secret_value = os.getenv(key_name)\n        if not secret_value:\n            print(f\"âš ï¸ Secret '{key_name}' not found in the {env} environment.\")\n            return None\n        print(f\"âœ… Successfully loaded secret '{key_name}'.\")\n        return secret_value\n    except Exception as e:\n        print(f\"âŒ An error occurred while loading secret '{key_name}': {e}\")\n        return None\n\ndef print_system_info():\n    print(\"\\nðŸ”§ System Information\")\n    print(f\"Python version: {sys.version.split()[0]}\")\n    try:\n        import torch\n        print(f\"PyTorch version: {torch.__version__}\")\n        if torch.cuda.is_available():\n            print(f\"CUDA version: {torch.version.cuda}\")\n            print(f\"GPU count: {torch.cuda.device_count()}\")\n            for i in range(torch.cuda.device_count()):\n                print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n        else:\n            print(\"CUDA not available\")\n    except ImportError:\n        print(\"PyTorch not installed\")\n    finally:\n      !nvidia-smi\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()\nis_kaggle = (\"kaggle\" in ENV_NAME)\nis_colab = not is_kaggle\nprint_system_info()\n\nos.environ[\"WANDB_API_KEY\"] = wandb_key = load_secret(\"WANDB_API_KEY\")\nos.environ[\"HF_TOKEN\"] = HF_TOKEN = load_secret('HF_TOKEN')\n\n# Now, these libraries will log in automatically\nimport wandb\nimport huggingface_hub\n\nwandb.login() \nhuggingface_hub.login(token=os.environ[\"HF_TOKEN\"]) ","metadata":{"id":"9cdd8666","outputId":"8834f4e4-fc28-455c-a66c-d15b00de080a","papermill":{"duration":0.019157,"end_time":"2025-12-30T18:53:35.092303","exception":false,"start_time":"2025-12-30T18:53:35.073146","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"a73b4150","cell_type":"code","source":"!uv pip install --upgrade pip\n# 3. Install PyTorch 1.13\n%cd {OUTPUT_PATH}\n# Force reinstall torch 1.13 to match the model's training environment\n# !uv pip uninstall torch torchvision\n# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n!uv pip install torch==2.9 torchvision\n# 4. Install other dependencies\n\nprint(\"\\nâ¬‡ï¸ Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n!sudo apt-get update && sudo apt-get install dos2unix\n!uv pip install gdown tqdm\n!uv pip install wandb\n!uv pip install --upgrade pyarrow datasets\nprint(\"\\nâœ… Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"id":"a73b4150","outputId":"97db2cec-8e2d-438b-e5f8-38df08b7f59e","papermill":{"duration":61.239828,"end_time":"2025-12-30T18:54:36.338205","exception":false,"start_time":"2025-12-30T18:53:35.098377","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"bd517dfe","cell_type":"code","source":"# KAGGLE CELL #1: Download checkpoint\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\nimport os\nimport sys\nfrom tqdm.auto import tqdm\nfrom pathlib import Path\nos.chdir(OUTPUT_PATH)\n# Download from Hub\nif not os.path.exists(\"ckpt\") or not list(Path(\"ckpt\").glob(\"*.safetensors\")):\n    print(\"ðŸ“¥ Downloading checkpoint from Hugging Face Hub...\\n\")\n    from huggingface_hub import snapshot_download\n    snapshot_download(\n        repo_id=\"dzungpham/font-diffusion-weights\",\n        local_dir=\"ckpt\",\n        allow_patterns=\"*.safetensors\",\n        force_download=False\n    )\n    print(\"\\nâœ… Download complete!\")\nelse:\n    print(\"âœ… Checkpoint already downloaded\")\n# Verify\nprint(\"\\nðŸ“‚ Files in ckpt/:\")\nfor file in os.listdir(\"ckpt\"):\n    if file.endswith(\".safetensors\"):\n        size = os.path.getsize(f\"ckpt/{file}\") / (1024**2)\n        print(f\"  âœ“ {file} ({size:.2f} MB)\")","metadata":{"id":"bd517dfe","outputId":"d83605e9-f5dc-4862-d1c9-b138a96ca47a","papermill":{"duration":12.524295,"end_time":"2025-12-30T18:54:48.878013","exception":false,"start_time":"2025-12-30T18:54:36.353718","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"767e8ea2","cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"id":"767e8ea2","outputId":"20185e27-e772-4823-e6bc-d9bd6d0b39a1","papermill":{"duration":0.023805,"end_time":"2025-12-30T18:54:48.917163","exception":false,"start_time":"2025-12-30T18:54:48.893358","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"51941368","cell_type":"code","source":"import pandas as pd\nimport os\ndef convert_csv_to_chars_txt(input_csv_path: str, output_txt_path: str, column_name: str = 'word'):\n    \"\"\"\n    Reads a CSV file, extracts text from a specified column, and writes each character\n    to a new line in a plain text file.\n    Args:\n        input_csv_path (str): The full path to the input CSV file.\n        output_txt_path (str): The full path for the output text file.\n        column_name (str): The name of the column in the CSV file containing the text.\n    \"\"\"\n    if not os.path.exists(input_csv_path):\n        print(f\"Error: Input CSV file not found at '{input_csv_path}'. Please ensure the file is uploaded.\")\n        return\n    try:\n        df = pd.read_csv(input_csv_path)\n    except Exception as e:\n        print(f\"Error reading CSV file '{input_csv_path}': {e}\")\n        return\n    if column_name not in df.columns:\n        print(f\"Error: Column '{column_name}' not found in the CSV file '{input_csv_path}'.\")\n        return\n    all_characters = []\n    for item in df[column_name].astype(str).dropna().tolist():\n        for char in item:\n            all_characters.append(char)\n    os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)\n    with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(all_characters))\n    print(f\"Successfully converted '{input_csv_path}' to '{output_txt_path}', with one character per line.\")\nprint(\"\\n--- Demonstrating function with a dummy CSV file ---\")\ndummy_csv_path = os.path.join(OUTPUT_PATH, \"dummy_data.csv\")\ndummy_output_txt_path = os.path.join(OUTPUT_PATH, \"dummy_chars.txt\")\ndummy_data = {'word': ['hello', 'world', 'python']}\npd.DataFrame(dummy_data).to_csv(dummy_csv_path, index=False)\nprint(f\"Created a dummy CSV file at: {dummy_csv_path}\")\nconvert_csv_to_chars_txt(dummy_csv_path, dummy_output_txt_path)","metadata":{"id":"51941368","outputId":"2a2c352c-968a-4e4d-b4cc-88a02c7eb788","papermill":{"duration":1.62157,"end_time":"2025-12-30T18:54:50.594793","exception":false,"start_time":"2025-12-30T18:54:48.973223","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"4f4cf20b","cell_type":"code","source":"print(\"Model files:\")\n!ls -larth {OUTPUT_PATH}/ckpt","metadata":{"id":"4f4cf20b","outputId":"335f4192-47e7-451a-e14f-e0bd69fbdfc9","papermill":{"duration":0.140282,"end_time":"2025-12-30T18:54:50.749810","exception":false,"start_time":"2025-12-30T18:54:50.609528","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"92cff682","cell_type":"code","source":"%cd {OUTPUT_PATH}\n# ==========================================\n# EXPORT / DOWNLOAD DATASET COMMANDS\n# ==========================================\nHF_USERNAME = \"dzungpham\"\n# Train Split\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train_original\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token HF_TOKEN\n\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token HF_TOKEN\n# Validation: Unseen Both\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token HF_TOKEN","metadata":{"id":"92cff682","papermill":{"duration":0.104394,"end_time":"2025-12-30T18:54:50.869230","exception":false,"start_time":"2025-12-30T18:54:50.764836","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"6db9c1d6-dd60-479c-92c4-2f653e4d48fd","cell_type":"code","source":"print(\"Fonts currently in fonts/ folder\")\n!ls -lt FontDiffusion/fonts\nprint(\"Styles in style_images/ folder\")\n!ls -l FontDiffusion/styles_images","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"eb05a6b7-6003-4377-bbd2-103bff55303b","cell_type":"code","source":"import json\nfrom pathlib import Path\nfrom typing import Set\n\ndef remove_unparseable_from_checkpoint(checkpoint_path: str, unparseable_txt_path: str) -> None:\n    \"\"\"\n    Removes generations referencing unparseable files from a results_checkpoint.json file.\n\n    Args:\n        checkpoint_path (str): Path to results_checkpoint.json.\n        unparseable_txt_path (str): Path to unparseable_files.txt (absolute paths, one per line).\n    \"\"\"\n    # Load unparseable file names into a set\n    with open(unparseable_txt_path, \"r\", encoding=\"utf-8\") as f:\n        unparseable_files: Set[str] = {Path(line.strip()).name for line in f if line.strip()}\n\n    # Load checkpoint JSON\n    with open(checkpoint_path, \"r\", encoding=\"utf-8\") as f:\n        results = json.load(f)\n\n    generations = results.get(\"generations\", [])\n    original_count = len(generations)\n\n    # Filter out generations whose target_image_path's filename is in unparseable_files\n    filtered_generations = [\n        gen for gen in generations\n        if os.path.join(\"kaggle/working/my_dataset/train_original\", gen.get(\"target_image_path\", \"\")) not in unparseable_files\n    ]\n\n    removed_count = original_count - len(filtered_generations)\n    results[\"generations\"] = filtered_generations\n\n    # Save updated checkpoint\n    with open(checkpoint_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(results, f, indent=2, ensure_ascii=False)\n\n    print(f\"Removed {removed_count} generations from {checkpoint_path}.\")\n\n# Example usage:\nremove_unparseable_from_checkpoint(\n    \"my_dataset/train_original/results_checkpoint.json\",\n    \"my_dataset/unparseable_files.txt\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b32b36ce-f246-4f86-b9f1-2ac844c7bec8","cell_type":"code","source":"!cat my_dataset/unparseable_files.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"29deed1d","cell_type":"code","source":"if is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\" \"protobuf<5.0.0\" \"numpy<2.0.0\"\n%cd {OUTPUT_PATH}\n!accelerate launch --num_processes 1 \\\n    FontDiffusion/sample_batch.py \\\n    --characters \"FontDiffusion/NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --style_images \"FontDiffusion/styles_images\" \\\n    --ckpt_dir \"ckpt/\" \\\n    --ttf_path \"FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n    --output_dir \"my_dataset/train_original\" \\\n    --num_inference_steps 20 \\\n    --guidance_scale 7.5 \\\n    --start_line 301 \\\n    --end_line 600 \\\n    --batch_size 35 \\\n    --save_interval 1 \\\n    --channels_last \\\n    --seed 42 \\\n    --compile \\\n    --enable_xformers","metadata":{"id":"29deed1d","outputId":"749b50d0-75e3-4d36-e509-919188feb64c","papermill":{"duration":10.53661,"end_time":"2025-12-30T18:55:01.421093","exception":false,"start_time":"2025-12-30T18:54:50.884483","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":null},{"id":"997103e5-221c-40a1-a0d1-83a93e1030f7","cell_type":"code","source":"!find my_dataset/train_original/ContentImage -type f | wc -l\n!find my_dataset/train_original/TargetImage -type f | wc -l","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"619d3b79-f33c-41c6-be25-e80b2c1165a5","cell_type":"code","source":"# !ls -lt my_dataset/train_original/ContentImage/*\n# !ls -l my_dataset/train_original/TargetImage/*hanhthu*\n# !ls -lt my_dataset/train_original/TargetImage/*","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"97c4a6a0-dba9-46be-b6df-d79cce0df689","cell_type":"code","source":"import re\nfrom pathlib import Path\n\n# Your valid pattern\nexpected_pattern = r\"U\\+[0-9A-F]{4,5}.*_[0-9a-f]{8}\\.png\"\n\n# Define the root directory ('.' for current directory)\nroot_dir = Path('./my_dataset/train_original/TargetImage')\n\n# .rglob('*') finds every file recursively\nfor path in root_dir.rglob('*'):\n    # Process only files (ignore directories)\n    if path.is_file():\n        # Check if the FILENAME (path.name) matches the regex\n        if not re.match(expected_pattern, path.name):\n            try:\n                print(f\"Deleting invalid file: {path}\")\n                # path.unlink() # This deletes the file\n            except Exception as e:\n                print(f\"Error deleting {path}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f9250a14","cell_type":"code","source":"!python FontDiffusion/create_validation_split.py \\\n  --data_root my_dataset \\\n  --val_ratio 0.2 \\\n  --seed 42","metadata":{"id":"f9250a14","outputId":"0f834d09-da00-4aa4-f486-6e70981b4137","papermill":{"duration":0.236541,"end_time":"2025-12-30T18:55:01.673705","exception":false,"start_time":"2025-12-30T18:55:01.437164","status":"completed"},"tags":[],"trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2026-01-02T04:39:25.243143Z","iopub.execute_input":"2026-01-02T04:39:25.243505Z","iopub.status.idle":"2026-01-02T04:39:27.551960Z","shell.execute_reply.started":"2026-01-02T04:39:25.243445Z","shell.execute_reply":"2026-01-02T04:39:27.551218Z"}},"outputs":[{"name":"stdout","text":"2026-01-02 04:39:25,499 | INFO | âœ“ Using source directory: my_dataset/train_original\n2026-01-02 04:39:25,504 | INFO | \n============================================================\n2026-01-02 04:39:25,504 | INFO | FONTDIFFUSION VALIDATION SPLIT CREATOR\n2026-01-02 04:39:25,504 | INFO | ============================================================\n2026-01-02 04:39:25,504 | INFO | \n============================================================\n2026-01-02 04:39:25,504 | INFO | ANALYZING TRAINING DATA\n2026-01-02 04:39:25,504 | INFO | ============================================================\n2026-01-02 04:39:25,504 | INFO | \nðŸ” Scanning content images...\nContent images: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 599/599 [00:00<00:00, 482687.43img/s]\n2026-01-02 04:39:25,509 | INFO |   âœ“ Found 599 content images\n2026-01-02 04:39:25,510 | INFO | \nðŸ” Scanning target images...\nStyles: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:00<00:00, 343.89style/s]\n2026-01-02 04:39:25,554 | INFO |   âœ“ Found 8985 valid target images\n2026-01-02 04:39:25,554 | INFO | \nðŸ” Validating content â†” target pairs...\nValidating pairs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8985/8985 [00:00<00:00, 2455902.34pair/s]\n2026-01-02 04:39:25,559 | INFO | ============================================================\n2026-01-02 04:39:25,560 | INFO | ðŸ“Š DATA ANALYSIS SUMMARY\n2026-01-02 04:39:25,560 | INFO | ============================================================\n2026-01-02 04:39:25,560 | INFO | Content images found:        599\n2026-01-02 04:39:25,560 | INFO | Target images scanned:       8,985\n2026-01-02 04:39:25,560 | INFO |   â”œâ”€ Parse errors:          0\n2026-01-02 04:39:25,560 | INFO |   â””â”€ Style mismatches:      0\n2026-01-02 04:39:25,560 | INFO | Target images after filter:  8,985\n2026-01-02 04:39:25,560 | INFO | Missing content images:      0\n2026-01-02 04:39:25,560 | INFO | Final valid pairs:           8,985\n2026-01-02 04:39:25,560 | INFO | ============================================================\n2026-01-02 04:39:25,560 | INFO | \n============================================================\n2026-01-02 04:39:25,560 | INFO | CREATING TRAIN/VAL SPLITS (random char & style)\n2026-01-02 04:39:25,560 | INFO | ============================================================\n2026-01-02 04:39:25,561 | INFO | \nðŸ“Š Split Statistics:\n2026-01-02 04:39:25,561 | INFO |   Total chars: 599 â†’ train: 480, val: 119\n2026-01-02 04:39:25,561 | INFO |   Total styles: 15 â†’ train: 12, val: 3\n2026-01-02 04:39:25,561 | INFO |   train:\n2026-01-02 04:39:25,561 | INFO |     Chars: 480\n2026-01-02 04:39:25,562 | INFO |     Styles: 12\n2026-01-02 04:39:25,562 | INFO |   val:\n2026-01-02 04:39:25,562 | INFO |     Chars: 119\n2026-01-02 04:39:25,562 | INFO |     Styles: 3\n2026-01-02 04:39:25,562 | INFO | \nðŸ“ CREATING TRAIN SPLIT...\n2026-01-02 04:39:25,562 | INFO |   ðŸ“¥ Copying content images for train...\n2026-01-02 04:39:25,684 | INFO |   ðŸ“¥ Copying target images for train...        \n2026-01-02 04:39:27,113 | INFO |   âœ“ train: 480 content, 5,760 target (skipped: 0)\n2026-01-02 04:39:27,113 | INFO |   ðŸ“‹ Filtering checkpoint for train...\n2026-01-02 04:39:27,227 | INFO |     âœ“ Saved: 5,760/8,985 generations           \n2026-01-02 04:39:27,229 | INFO | ðŸ“ CREATING VAL SPLIT...\n2026-01-02 04:39:27,229 | INFO |   ðŸ“¥ Copying content images for val...\n2026-01-02 04:39:27,256 | INFO |   ðŸ“¥ Copying target images for val...          \n2026-01-02 04:39:27,356 | INFO |   âœ“ val: 119 content, 357 target (skipped: 0)  \n2026-01-02 04:39:27,356 | INFO |   ðŸ“‹ Filtering checkpoint for val...\n2026-01-02 04:39:27,408 | INFO |     âœ“ Saved: 357/8,985 generations             \n2026-01-02 04:39:27,410 | INFO | âœ“ Saved split metadata to my_dataset/split_info.json\n2026-01-02 04:39:27,412 | INFO | \n============================================================\n2026-01-02 04:39:27,412 | INFO | âœ“ SPLIT CREATION COMPLETE\n2026-01-02 04:39:27,412 | INFO | ============================================================\n2026-01-02 04:39:27,412 | INFO | \nâœ… Created:\n2026-01-02 04:39:27,412 | INFO |   ðŸ“ train/\n2026-01-02 04:39:27,412 | INFO |     â”œâ”€â”€ ContentImage/ (training chars)\n2026-01-02 04:39:27,412 | INFO |     â”œâ”€â”€ TargetImage/ (training styles)\n2026-01-02 04:39:27,412 | INFO |     â””â”€â”€ results_checkpoint.json (filtered)\n2026-01-02 04:39:27,412 | INFO |   ðŸ“ val/\n2026-01-02 04:39:27,412 | INFO |     â”œâ”€â”€ ContentImage/ (validation chars)\n2026-01-02 04:39:27,412 | INFO |     â”œâ”€â”€ TargetImage/ (validation styles)\n2026-01-02 04:39:27,412 | INFO |     â””â”€â”€ results_checkpoint.json (filtered)\n2026-01-02 04:39:27,412 | INFO | \nðŸ’¡ Guarantees:\n2026-01-02 04:39:27,412 | INFO |   âœ“ Every target has matching content\n2026-01-02 04:39:27,412 | INFO |   âœ“ Checkpoint contains only relevant generations\n2026-01-02 04:39:27,412 | INFO |   âœ“ Train and val are completely disjoint\n","output_type":"stream"}],"execution_count":17},{"id":"79508d80-fac1-4318-9174-a32613a557e3","cell_type":"code","source":"!uv pip install --upgrade pyarrow datasets","metadata":{"trusted":true,"id":"79508d80-fac1-4318-9174-a32613a557e3"},"outputs":[],"execution_count":null},{"id":"48f97e84-cd8c-49a9-86bd-fce456be56a4","cell_type":"code","source":"# remove_unparseable_files.py\n\nwith open(\"my_dataset/unparseable_files.txt\", \"r\", encoding=\"utf-8\") as f:\n    paths = [line.strip() for line in f if line.strip()]\n\nimport os\n\nfor path in paths:\n    try:\n        if os.path.exists(path):\n            os.remove(path)\n            print(f\"Deleted: {path}\")\n        else:\n            print(f\"Not found: {path}\")\n    except Exception as e:\n        print(f\"Error deleting {path}: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"vRL8QovYCvLY","cell_type":"code","source":"HF_USERNAME = \"dzungpham\"\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train_original\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/train\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token {HF_TOKEN}\n\n# Train Split\n!python FontDiffusion/create_hf_dataset.py \\\n  --data_dir \"my_dataset/val\" \\\n  --repo_id dzungpham/font-diffusion-generated-data \\\n  --split \"val\" \\\n  --token {HF_TOKEN}\n","metadata":{"id":"vRL8QovYCvLY","outputId":"08301c52-4ae1-4268-c516-2ff8bd834783","colab":{"base_uri":"https://localhost:8080/"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T04:39:37.656344Z","iopub.execute_input":"2026-01-02T04:39:37.656640Z","iopub.status.idle":"2026-01-02T04:40:55.252069Z","shell.execute_reply.started":"2026-01-02T04:39:37.656615Z","shell.execute_reply":"2026-01-02T04:40:55.251050Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/train_original\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\nâœ“ Validated directory structure\n  Content images: my_dataset/train_original/ContentImage\n  Target images: my_dataset/train_original/TargetImage\n  Results checkpoint: my_dataset/train_original/results_checkpoint.json\n\n============================================================\nBUILDING DATASET\n============================================================\n\nâœ“ Loaded results_checkpoint.json\n  Generations: 8985\n  Characters: 599\n  Styles: 15\n\nðŸ–¼ï¸  Loading 8985 image pairs...\nLoading image pairs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.98k/8.98k [00:07<00:00, 1.18kpair/s]\nâœ“ Loaded 8985 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: train_original\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                      | 0/8985 [00:00<?, ? examples/s]\u001b[A\nMap:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹      | 6601/8985 [00:00<00:00, 17523.15 examples/s]\u001b[A\nMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8985/8985 [00:00<00:00, 15307.79 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/2 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.89ba/s]\u001b[A\nUploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.25s/ shards]\n\nâœ“ Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\nâœ… COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/train\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\nâœ“ Validated directory structure\n  Content images: my_dataset/train/ContentImage\n  Target images: my_dataset/train/TargetImage\n  Results checkpoint: my_dataset/train/results_checkpoint.json\n\n============================================================\nBUILDING DATASET\n============================================================\n\nâœ“ Loaded results_checkpoint.json\n  Generations: 5760\n  Characters: 480\n  Styles: 12\n\nðŸ–¼ï¸  Loading 5760 image pairs...\nLoading image pairs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.76k/5.76k [00:04<00:00, 1.16kpair/s]\nâœ“ Loaded 5760 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: train\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap:   0%|                                      | 0/5760 [00:00<?, ? examples/s]\u001b[A\nMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5760/5760 [00:00<00:00, 14851.57 examples/s]\u001b[A\n\nCreating parquet from Arrow format:   0%|                 | 0/1 [00:00<?, ?ba/s]\u001b[A\nCreating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.85ba/s]\u001b[A\nUploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.09 shards/s]\nREADME.md: 3.05kB [00:00, 12.0MB/s]\n\nâœ“ Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\nâœ… COMPLETE!\n\n============================================================\nFONTDIFFUSION DATASET CREATOR\n============================================================\n\nData dir: my_dataset/val\nRepo: dzungpham/font-diffusion-generated-data\nPush to Hub: True\nâœ“ Validated directory structure\n  Content images: my_dataset/val/ContentImage\n  Target images: my_dataset/val/TargetImage\n  Results checkpoint: my_dataset/val/results_checkpoint.json\n\n============================================================\nBUILDING DATASET\n============================================================\n\nâœ“ Loaded results_checkpoint.json\n  Generations: 357\n  Characters: 119\n  Styles: 3\n\nðŸ–¼ï¸  Loading 357 image pairs...\nLoading image pairs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 1.20kpair/s]\nâœ“ Loaded 357 samples\n\n============================================================\nPUSHING TO HUB\n============================================================\nRepository: dzungpham/font-diffusion-generated-data\nSplit: val\nUploading the dataset shards:   0%|                  | 0/1 [00:00<?, ? shards/s]\nMap: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [00:00<00:00, 19035.45 examples/s]\u001b[A\n\nCreating parquet from Arrow format: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 80.84ba/s]\u001b[A\nUploading the dataset shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:11<00:00, 11.31s/ shards]\nREADME.md: 3.05kB [00:00, 13.0MB/s]\n\nâœ“ Successfully pushed to Hub!\n  URL: https://huggingface.co/datasets/dzungpham/font-diffusion-generated-data\n\nâœ… COMPLETE!\n","output_type":"stream"}],"execution_count":18},{"id":"a87caab2","cell_type":"code","source":"import torch, gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"id":"a87caab2","papermill":{"duration":1.992585,"end_time":"2025-12-30T18:55:24.769269","exception":false,"start_time":"2025-12-30T18:55:22.776684","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"267634e8","cell_type":"code","source":"# TRAINING PHASE 1\nif is_colab:\n  !uv pip install --upgrade \"huggingface-hub>=0.34.0,<1.0\"\nelse:\n  !uv pip install --upgrade \"huggingface-hub==0.25.2\"\nimport wandb\n\n!accelerate launch FontDiffusion/train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_1\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --gradient_accumulation_steps=2 \\\n    --perceptual_coefficient=0.05 \\\n    --offset_coefficient=0.7 \\\n    --max_train_steps=200 \\\n    --ckpt_interval=100 \\\n    --log_interval=50 \\\n    --learning_rate=1e-4 \\\n    --lr_scheduler=\"linear\" \\\n    --lr_warmup_steps=10000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"","metadata":{"id":"267634e8","papermill":{"duration":0.021927,"end_time":"2025-12-30T18:55:24.807644","exception":false,"start_time":"2025-12-30T18:55:24.785717","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T04:43:59.401134Z","iopub.execute_input":"2026-01-02T04:43:59.401482Z","iopub.status.idle":"2026-01-02T04:47:50.896613Z","shell.execute_reply.started":"2026-01-02T04:43:59.401454Z","shell.execute_reply":"2026-01-02T04:47:50.895674Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 78ms\u001b[0m\u001b[0m                                         \u001b[0m\n\u001b[2mAudited \u001b[1m12 packages\u001b[0m \u001b[2min 0.12ms\u001b[0m\u001b[0m\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nThe following values were not passed to `accelerate launch` and had defaults used instead:\n\t`--num_processes` was set to a value of `2`\n\t\tMore than one GPU was found, enabling multi-GPU training.\n\t\tIf this was unintended please pass in `--num_processes=1`.\n\t`--num_machines` was set to a value of `1`\n\t`--mixed_precision` was set to a value of `'no'`\n\t`--dynamo_backend` was set to a value of `'no'`\nTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/diffusers/utils/outputs.py:63: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n2026-01-02 04:44:09.202585: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2026-01-02 04:44:09.202600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767329049.225566    1532 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767329049.225569    1531 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767329049.233230    1531 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1767329049.233268    1532 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)pygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n\nHello from the pygame community. https://www.pygame.org/contribute.html\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  MCADownBlock2D\nLoad the down block  MCADownBlock2D\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 1 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nThe style_attention cross attention dim in Down Block 2 layer is 1024\nLoad the down block  DownBlock2D\nLoad the down block  DownBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nLoad the up block  StyleRSIUpBlock2D\nLoad the up block  UpBlock2D\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nParam count for Ds initialized parameters: 20591296\nGet CG-GAN Style Encoder!\nParam count for Ds initialized parameters: 1187008\nGet CG-GAN Content Encoder!\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20260102_044419-e28gq05h\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-butterfly-21\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/e28gq05h\u001b[0m\nSteps:   0%|                                            | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n/usr/local/lib/python3.11/dist-packages/diffusers/configuration_utils.py:134: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n/kaggle/working/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n  style_img_feature, _, _ = self.style_encoder(style_images)\n/kaggle/working/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n  style_img_feature, _, _ = self.style_encoder(style_images)\n/kaggle/working/FontDiffusion/src/model.py:42: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  content_img_feature, content_residual_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:42: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  content_img_feature, content_residual_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:47: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  style_content_feature, style_content_res_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:47: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n  style_content_feature, style_content_res_features = self.content_encoder(\n/kaggle/working/FontDiffusion/src/model.py:59: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n  out = self.unet(\n/kaggle/working/FontDiffusion/src/model.py:59: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n  out = self.unet(\nSteps:   0%|                       | 0/200 [00:01<?, ?it/s, lr=0, step_loss=5.7]/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [128, 128, 1, 1], strides() = [128, 1, 128, 128]\nbucket_view.sizes() = [128, 128, 1, 1], strides() = [128, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:841: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [128, 128, 1, 1], strides() = [128, 1, 128, 128]\nbucket_view.sizes() = [128, 128, 1, 1], strides() = [128, 1, 1, 1] (Triggered internally at /pytorch/torch/csrc/distributed/c10d/reducer.cpp:334.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nSteps:  50%|â–ˆâ–ˆâ–ˆâ–Œ   | 100/200 [03:23<03:38,  2.19s/it, lr=9.9e-7, step_loss=4.36]Traceback (most recent call last):\n  File \"/kaggle/working/FontDiffusion/train.py\", line 348, in <module>\n    main()\n  File \"/kaggle/working/FontDiffusion/train.py\", line 313, in main\n    torch.save(model.unet.state_dict(), f\"{save_dir}/unet.pth\")\n               ^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1964, in __getattr__\n    raise AttributeError(\nAttributeError: 'DistributedDataParallel' object has no attribute 'unet'\n[rank0]: Traceback (most recent call last):\n[rank0]:   File \"/kaggle/working/FontDiffusion/train.py\", line 348, in <module>\n[rank0]:     main()\n[rank0]:   File \"/kaggle/working/FontDiffusion/train.py\", line 313, in main\n[rank0]:     torch.save(model.unet.state_dict(), f\"{save_dir}/unet.pth\")\n[rank0]:                ^^^^^^^^^^\n[rank0]:   File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1964, in __getattr__\n[rank0]:     raise AttributeError(\n[rank0]: AttributeError: 'DistributedDataParallel' object has no attribute 'unet'\n\u001b[1;34mwandb\u001b[0m: \n\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33mdandy-butterfly-21\u001b[0m at: \u001b[34mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/e28gq05h\u001b[0m\n\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20260102_044419-e28gq05h/logs\u001b[0m\nW0102 04:47:49.693000 1523 torch/distributed/elastic/multiprocessing/api.py:908] Sending process 1532 closing signal SIGTERM\nE0102 04:47:49.907000 1523 torch/distributed/elastic/multiprocessing/api.py:882] failed (exitcode: 1) local_rank: 0 (pid: 1531) of binary: /usr/bin/python3\nTraceback (most recent call last):\n  File \"/usr/local/bin/accelerate\", line 10, in <module>\n    sys.exit(main())\n             ^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n    args.func(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 977, in launch_command\n    multi_gpu_launcher(args)\n  File \"/usr/local/lib/python3.11/dist-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n    distrib_run.run(args)\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/run.py\", line 927, in run\n    elastic_launch(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 156, in __call__\n    return launch_agent(self._config, self._entrypoint, list(args))\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/torch/distributed/launcher/api.py\", line 293, in launch_agent\n    raise ChildFailedError(\ntorch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n============================================================\nFontDiffusion/train.py FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2026-01-02_04:47:49\n  host      : 0e1df859923c\n  rank      : 0 (local_rank: 0)\n  exitcode  : 1 (pid: 1531)\n  error_file: <N/A>\n  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n============================================================\n","output_type":"stream"}],"execution_count":21},{"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f","cell_type":"code","source":"!ls -lr outputs/FontDiffuser","metadata":{"trusted":true,"id":"cb2a3326-6bfa-4fba-bbcc-e2e7be996c7f"},"outputs":[],"execution_count":null},{"id":"97f8136e","cell_type":"code","source":"# TRAINING PHASE 2\n!wandb login\n!python FontDiffusion/my_train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_2\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --phase_2 \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_2000\" \\\n    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n    --sc_coefficient=0.05 \\\n    --num_neg=13 \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.4 \\\n    --max_train_steps=100 \\\n    --ckpt_interval=50 \\\n    --gradient_accumulation_steps=2 \\\n    --log_interval=50 \\\n    --learning_rate=1e-5 \\\n    --lr_scheduler=\"constant\" \\\n    --lr_warmup_steps=1000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"\n","metadata":{"id":"97f8136e","papermill":{"duration":0.022471,"end_time":"2025-12-30T18:55:24.845778","exception":false,"start_time":"2025-12-30T18:55:24.823307","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"88c45e2f","cell_type":"code","source":"!python FontDiffusion/pth2safetensors.py \\\n    --weights_dir \"ckpt\" \\\n    --repo_id \"dzungpham/font-diffusion-weights\" \\\n    --token \"{HF_TOKEN}\"","metadata":{"id":"88c45e2f","papermill":{"duration":0.217876,"end_time":"2025-12-30T18:55:25.079820","exception":false,"start_time":"2025-12-30T18:55:24.861944","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"5868b20b","cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\nfrom typing import List\ndef find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n\ndef zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n    folder_name = folder_path.name\n    zip_path = output_base_path / f\"{folder_name}.zip\"\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for file_path in folder_path.rglob(\"*\"):\n                if file_path.is_file():\n                    arcname = file_path.relative_to(folder_path.parent)\n                    zipf.write(file_path, arcname)\n        print(f\"   âœ… Created ZIP: {zip_path.name}\")\n        return True\n    except Exception as exc:\n        print(f\"   âŒ Failed to zip {folder_name}: {exc}\")\n        return False\n\ndef zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n    base = Path(output_base_path)\n    base.mkdir(parents=True, exist_ok=True)\n    result_folders = find_result_folders(base, pattern_name)\n    if not result_folders:\n        print(f\"âš ï¸ No folders matching '*dataset' found in '{output_base_path}'.\")\n        return\n    print(f\"ðŸ” Found {len(result_folders)} result folder(s) to zip.\")\n    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n    print(f\"\\nâœ… DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        zip_stats_results_folders(\n            output_base_path=OUTPUT_PATH,\n            pattern_name=\"my_dataset\")\n    except Exception as e:\n        print(f\"âŒ An error occurred: {e}\")","metadata":{"id":"5868b20b","papermill":{"duration":0.031197,"end_time":"2025-12-30T18:55:25.126961","exception":false,"start_time":"2025-12-30T18:55:25.095764","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}