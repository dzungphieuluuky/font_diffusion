{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\n\n# 1. *** FIX: Clear problematic environment variable for matplotlib ***\n# This prevents the \"ValueError: Key backend: 'module://matplotlib_inline.backend_inline'\" error\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git\n\n!uv pip install --upgrade pip\n!uv pip install -r FontDiffusion/requirements.txt\n!uv pip install gdown\n# 3. Install PyTorch 1.13\nprint(\"\\nâ¬‡ï¸ Installing PyTorch 1.13 (Required for this model)...\")\n# Force reinstall torch 1.13 to match the model's training environment\n!uv pip uninstall torch torchvision\n!uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n\n# 4. Install other dependencies\nprint(\"\\nâ¬‡ï¸ Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n!sudo apt-get update && sudo apt-get install dos2unix\nprint(\"\\nâœ… Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BWFvN9XJxf9K","outputId":"ba1d7c30-ac4c-4271-fcf3-3ee6ed0fd72c"},"outputs":[{"output_type":"stream","name":"stdout","text":["MPLBACKEND environment variable cleared.\n","Cloning into 'FontDiffusion'...\n","remote: Enumerating objects: 15052, done.\u001b[K\n","remote: Counting objects: 100% (2865/2865), done.\u001b[K\n","remote: Compressing objects: 100% (2792/2792), done.\u001b[K\n","remote: Total 15052 (delta 92), reused 2838 (delta 71), pack-reused 12187 (from 3)\u001b[K\n","Receiving objects: 100% (15052/15052), 246.86 MiB | 20.03 MiB/s, done.\n","Resolving deltas: 100% (480/480), done.\n","Updating files: 100% (110/110), done.\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 112ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 106ms\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 68ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m116 packages\u001b[0m \u001b[2min 659ms\u001b[0m\u001b[0m\n","\u001b[2K  \u001b[31mÃ—\u001b[0m Failed to build `tokenizers==0.13.3`\n","\u001b[31m  â”œâ”€â–¶ \u001b[0mThe build backend returned an error\n","\u001b[31m  â•°â”€â–¶ \u001b[0mCall to `setuptools.build_meta.build_wheel` failed (exit status: 1)\n","\n","\u001b[31m      \u001b[0m\u001b[31m[stdout]\u001b[39m\n","\u001b[31m      \u001b[0mrunning bdist_wheel\n","\u001b[31m      \u001b[0mrunning build\n","\u001b[31m      \u001b[0mrunning build_py\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/models\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/decoders\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/processors\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/trainers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/byte_level_bpe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_unigram.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/char_level_bpe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_bpe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/base_tokenizer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/bert_wordpiece.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcreating build/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer-styles.css ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mrunning build_ext\n","\u001b[31m      \u001b[0mrunning build_rust\n","\n","\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n","\u001b[31m      \u001b[0m/root/.cache/uv/builds-v0/.tmpsz6cXS/lib/python3.12/site-packages/setuptools/dist.py:759:\n","\u001b[31m      \u001b[0mSetuptoolsDeprecationWarning: License classifiers are deprecated.\n","\u001b[31m      \u001b[0m!!\n","\n","\u001b[31m      \u001b[0m\n","\u001b[31m      \u001b[0m********************************************************************************\n","\u001b[31m      \u001b[0m        Please consider removing the following classifiers in favor of a\n","\u001b[31m      \u001b[0mSPDX license expression:\n","\n","\u001b[31m      \u001b[0m        License :: OSI Approved :: Apache Software License\n","\n","\u001b[31m      \u001b[0m        See\n","\u001b[31m      \u001b[0mhttps://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license\n","\u001b[31m      \u001b[0mfor details.\n","\u001b[31m      \u001b[0m\n","\u001b[31m      \u001b[0m********************************************************************************\n","\n","\u001b[31m      \u001b[0m!!\n","\u001b[31m      \u001b[0m  self._finalize_license_expression()\n","\u001b[31m      \u001b[0merror: can't find Rust compiler\n","\n","\u001b[31m      \u001b[0mIf you are using an outdated pip version, it is possible a prebuilt\n","\u001b[31m      \u001b[0mwheel is available for this package but pip is not able to install from\n","\u001b[31m      \u001b[0mit. Installing from the wheel would avoid the need for a Rust compiler.\n","\n","\u001b[31m      \u001b[0mTo update pip, run:\n","\n","\u001b[31m      \u001b[0m    pip install --upgrade pip\n","\n","\u001b[31m      \u001b[0mand then retry package installation.\n","\n","\u001b[31m      \u001b[0mIf you did intend to build this package from source, try installing\n","\u001b[31m      \u001b[0ma Rust compiler from your system package manager and ensure it is\n","\u001b[31m      \u001b[0mon the PATH during installation. Alternatively, rustup (available at\n","\u001b[31m      \u001b[0mhttps://rustup.rs) is the recommended way to download and update the\n","\u001b[31m      \u001b[0mRust compiler toolchain.\n","\n","\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n","\u001b[31m      \u001b[0menvironment.\n","\u001b[36m  help: \u001b[0m`\u001b[36mtokenizers\u001b[39m` (\u001b[36mv0.13.3\u001b[39m) was included because `\u001b[36mtransformers\u001b[39m` (\u001b[36mv4.33.1\u001b[39m)\n","        depends on `\u001b[36mtokenizers\u001b[39m`\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m\n","\n","â¬‡ï¸ Installing PyTorch 1.13 (Required for this model)...\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2mUninstalled \u001b[1m2 packages\u001b[0m \u001b[2min 806ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.0+cu126\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.0+cu126\u001b[0m\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K  \u001b[31mÃ—\u001b[0m No solution found when resolving dependencies:\n","\u001b[31m  â•°â”€â–¶ \u001b[0mBecause torch==1.13.1+cu117 has no wheels with a matching Python ABI\n","\u001b[31m      \u001b[0mtag (e.g., `\u001b[36mcp312\u001b[39m`) and you require torch==1.13.1+cu117, we can conclude\n","\u001b[31m      \u001b[0mthat your requirements are unsatisfiable.\n","\n","\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m `\u001b[36mtorch\u001b[39m` was found on \u001b[36mhttps://download.pytorch.org/whl/cu117\u001b[39m, but\n","\u001b[31m      \u001b[0mnot at the requested version (\u001b[36mtorch==1.13.1+cu117\u001b[39m). A compatible version\n","\u001b[31m      \u001b[0mmay be available on a subsequent index (e.g., \u001b[36mhttps://pypi.org/simple\u001b[39m).\n","\u001b[31m      \u001b[0mBy default, uv will only consider versions that are published on the\n","\u001b[31m      \u001b[0mfirst index that contains a given package, to avoid dependency confusion\n","\u001b[31m      \u001b[0mattacks. If all indexes are equally trusted, use `\u001b[32m--index-strategy\n","\u001b[31m      \u001b[0munsafe-best-match\u001b[39m` to consider all versions from all indexes, regardless\n","\u001b[31m      \u001b[0mof the order in which they were defined.\n","\n","\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.12\u001b[39m (`\u001b[36mcp312\u001b[39m`), but we only found wheels for\n","\u001b[31m      \u001b[0m`\u001b[36mtorch\u001b[39m` (\u001b[36mv1.13.1+cu117\u001b[39m) with the following Python ABI tags: `\u001b[36mcp37m\u001b[39m`,\n","\u001b[31m      \u001b[0m`\u001b[36mcp38\u001b[39m`, `\u001b[36mcp39\u001b[39m`, `\u001b[36mcp310\u001b[39m`, `\u001b[36mcp311\u001b[39m`\n","\n","â¬‡ï¸ Installing Dependencies (Manually fixed)...\n","  \u001b[31mÃ—\u001b[0m No solution found when resolving dependencies:\n","\u001b[31m  â•°â”€â–¶ \u001b[0mBecause torch==1.13.1 has no wheels with a matching Python ABI tag\n","\u001b[31m      \u001b[0m(e.g., `\u001b[36mcp312\u001b[39m`) and xformers==0.0.16 depends on torch==1.13.1, we can\n","\u001b[31m      \u001b[0mconclude that xformers==0.0.16 cannot be used.\n","\u001b[31m      \u001b[0mAnd because you require xformers==0.0.16, we can conclude that your\n","\u001b[31m      \u001b[0mrequirements are unsatisfiable.\n","\n","\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m You require \u001b[36mCPython 3.12\u001b[39m (`\u001b[36mcp312\u001b[39m`), but we only found wheels for\n","\u001b[31m      \u001b[0m`\u001b[36mtorch\u001b[39m` (\u001b[36mv1.13.1\u001b[39m) with the following Python ABI tags: `\u001b[36mcp37m\u001b[39m`, `\u001b[36mcp38\u001b[39m`,\n","\u001b[31m      \u001b[0m`\u001b[36mcp39\u001b[39m`, `\u001b[36mcp310\u001b[39m`, `\u001b[36mcp311\u001b[39m`\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m47 packages\u001b[0m \u001b[2min 87ms\u001b[0m\u001b[0m\n","\u001b[2K  \u001b[31mÃ—\u001b[0m Failed to build `tokenizers==0.13.3`\n","\u001b[31m  â”œâ”€â–¶ \u001b[0mThe build backend returned an error\n","\u001b[31m  â•°â”€â–¶ \u001b[0mCall to `setuptools.build_meta.build_wheel` failed (exit status: 1)\n","\n","\u001b[31m      \u001b[0m\u001b[31m[stdout]\u001b[39m\n","\u001b[31m      \u001b[0mrunning bdist_wheel\n","\u001b[31m      \u001b[0mrunning build\n","\u001b[31m      \u001b[0mrunning build_py\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/byte_level_bpe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_unigram.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/char_level_bpe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/sentencepiece_bpe.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/base_tokenizer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/implementations/bert_wordpiece.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/implementations\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/__init__.py ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/models/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/models\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/decoders/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/decoders\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/normalizers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/normalizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/pre_tokenizers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/pre_tokenizers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/processors/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/processors\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/trainers/__init__.pyi ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/trainers\n","\u001b[31m      \u001b[0mcopying py_src/tokenizers/tools/visualizer-styles.css ->\n","\u001b[31m      \u001b[0mbuild/lib.linux-x86_64-cpython-312/tokenizers/tools\n","\u001b[31m      \u001b[0mrunning build_ext\n","\u001b[31m      \u001b[0mrunning build_rust\n","\n","\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n","\u001b[31m      \u001b[0m/root/.cache/uv/builds-v0/.tmpXIlyt8/lib/python3.12/site-packages/setuptools/dist.py:759:\n","\u001b[31m      \u001b[0mSetuptoolsDeprecationWarning: License classifiers are deprecated.\n","\u001b[31m      \u001b[0m!!\n","\n","\u001b[31m      \u001b[0m\n","\u001b[31m      \u001b[0m********************************************************************************\n","\u001b[31m      \u001b[0m        Please consider removing the following classifiers in favor of a\n","\u001b[31m      \u001b[0mSPDX license expression:\n","\n","\u001b[31m      \u001b[0m        License :: OSI Approved :: Apache Software License\n","\n","\u001b[31m      \u001b[0m        See\n","\u001b[31m      \u001b[0mhttps://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license\n","\u001b[31m      \u001b[0mfor details.\n","\u001b[31m      \u001b[0m\n","\u001b[31m      \u001b[0m********************************************************************************\n","\n","\u001b[31m      \u001b[0m!!\n","\u001b[31m      \u001b[0m  self._finalize_license_expression()\n","\u001b[31m      \u001b[0merror: can't find Rust compiler\n","\n","\u001b[31m      \u001b[0mIf you are using an outdated pip version, it is possible a prebuilt\n","\u001b[31m      \u001b[0mwheel is available for this package but pip is not able to install from\n","\u001b[31m      \u001b[0mit. Installing from the wheel would avoid the need for a Rust compiler.\n","\n","\u001b[31m      \u001b[0mTo update pip, run:\n","\n","\u001b[31m      \u001b[0m    pip install --upgrade pip\n","\n","\u001b[31m      \u001b[0mand then retry package installation.\n","\n","\u001b[31m      \u001b[0mIf you did intend to build this package from source, try installing\n","\u001b[31m      \u001b[0ma Rust compiler from your system package manager and ensure it is\n","\u001b[31m      \u001b[0mon the PATH during installation. Alternatively, rustup (available at\n","\u001b[31m      \u001b[0mhttps://rustup.rs) is the recommended way to download and update the\n","\u001b[31m      \u001b[0mRust compiler toolchain.\n","\n","\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This usually indicates a problem with the package or the build\n","\u001b[31m      \u001b[0menvironment.\n","\u001b[36m  help: \u001b[0m`\u001b[36mtokenizers\u001b[39m` (\u001b[36mv0.13.3\u001b[39m) was included because `\u001b[36mtransformers\u001b[39m` (\u001b[36mv4.33.1\u001b[39m)\n","        depends on `\u001b[36mtokenizers\u001b[39m`\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m91 packages\u001b[0m \u001b[2min 55ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m13 packages\u001b[0m \u001b[2min 33.61s\u001b[0m\u001b[0m\n","\u001b[2mUninstalled \u001b[1m21 packages\u001b[0m \u001b[2min 241ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m25 packages\u001b[0m \u001b[2min 238ms\u001b[0m\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==24.1.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1maiofiles\u001b[0m\u001b[2m==23.2.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.50.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.14.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==0.7.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1minfo-nce-pytorch\u001b[0m\u001b[2m==0.1.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mkornia\u001b[0m\u001b[2m==0.8.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mkornia-rs\u001b[0m\u001b[2m==0.1.10\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.0.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.6.4.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.6.80\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.0.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.11.1.6\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.7.77\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.1.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.4.2\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.6.85\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.6.77\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.1\u001b[0m\n"," \u001b[31m-\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==11.0.3\u001b[0m\n","\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `typer==0.20.0` does not have an extra named `all`\u001b[0m\n","\u001b[2mUsing Python 3.12.12 environment at: /usr\u001b[0m\n","\u001b[2K\u001b[2mResolved \u001b[1m38 packages\u001b[0m \u001b[2min 72ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m\n","\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 8ms\u001b[0m\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mpytorch-fid\u001b[0m\u001b[2m==0.3.0\u001b[0m\n"," \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n","Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n","Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n","Get:4 https://cli.github.com/packages stable/main amd64 Packages [345 B]\n","Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n","Get:15 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\n","Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\n","Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n","Get:21 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\n","Get:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\n","Fetched 38.3 MB in 5s (8,199 kB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following NEW packages will be installed:\n","  dos2unix\n","0 upgraded, 1 newly installed, 0 to remove and 54 not upgraded.\n","Need to get 384 kB of archives.\n","After this operation, 1,367 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dos2unix amd64 7.4.2-2 [384 kB]\n","Fetched 384 kB in 1s (336 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package dos2unix.\n","(Reading database ... 121689 files and directories currently installed.)\n","Preparing to unpack .../dos2unix_7.4.2-2_amd64.deb ...\n","Unpacking dos2unix (7.4.2-2) ...\n","Setting up dos2unix (7.4.2-2) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","\n","âœ… Environment setup complete. You can now proceed to Block 2 (Inference).\n"]}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom IPython import get_ipython\n\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"âœ… Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"âœ… Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"âš ï¸ Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"âš ï¸ Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"ğŸ“‚ Data Path: {base_data_path}\")\n    print(f\"ğŸ“¦ Output Path: {base_output_path}\")\n\n    return base_data_path, base_output_path, environment_name\n\n\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxdyquWfaqdm","outputId":"aaf97a2b-65a4-4a29-c69f-5c0c38638c3e"},"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Environment: Google Colab\n","ğŸ“‚ Data Path: /content/\n","ğŸ“¦ Output Path: /content/\n"]}],"execution_count":1},{"cell_type":"code","source":"import os\nimport wandb\n\nif \"colab\" in ENV_NAME:\n    from google.colab import userdata\n\n    try:\n        # Ensure 'WANDB_API_KEY' is the exact name in your Colab Secrets (the key icon)\n        wandb_key = userdata.get(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Colab Secrets: {e}\")\n\n# 2. Check if running in Kaggle\nelif \"kaggle\" in ENV_NAME:\n    try:\n        from kaggle_secrets import UserSecretsClient\n\n        user_secrets = UserSecretsClient()\n        wandb_key = user_secrets.get_secret(\"WANDB_API_KEY\")\n        wandb.login(key=wandb_key)\n    except Exception as e:\n        print(f\"Could not retrieve W&B API key from Kaggle Secrets: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h06w314Jaqdm","outputId":"75176f26-5b20-4ea6-d788-ee5be8d780e3"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"execution_count":2},{"cell_type":"code","source":"import gdown\n\nif not os.path.exists(\"ckpt\"):\n  url = \"https://drive.google.com/drive/folders/12hfuZ9MQvXqcteNuz7JQ2B_mUcTr-5jZ\"\n  gdown.download_folder(url, quiet=True, use_cookies=False)","metadata":{"id":"9PsLgUs0cYmO"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -q -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecfc18e0","outputId":"06c02820-3c0c-4246-f079-945e7a40d742"},"outputs":[{"output_type":"stream","name":"stdout","text":["No .zip files found in /content/.\n"]}],"execution_count":4},{"cell_type":"code","source":"# @title Checking checkpoint files (.pth)\nimport os\nimport time\n\nCHECKPOINT_DIR = os.path.join(INPUT_PATH, \"ckpt\")\nprint(CHECKPOINT_DIR)\n# Create the checkpoint directory\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\n# Wait loop to check if files exist\nrequired_files = [\"unet.pth\", \"content_encoder.pth\", \"style_encoder.pth\"]\n\nwhile True:\n    missing = [f for f in required_files if not os.path.exists(f\"{CHECKPOINT_DIR}/{f}\")]\n\n    if not missing:\n        print(\"\\nâœ… All weights found! You can proceed to the next step.\")\n        break\n    else:\n        print(f\"Waiting for files... Missing: {missing}\")\n        print(\"Upload them to the 'ckpt' folder now.\")\n        time.sleep(10) # Checks every 10 seconds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JBflCTABxlF4","outputId":"6b03581b-e20c-4d44-8d7c-bd3d63f5ff4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ckpt\n","\n","âœ… All weights found! You can proceed to the next step.\n"]}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nnom_tu_tao_300_df = pd.read_csv(f\"{INPUT_PATH}/Ds_300_ChuNom_TuTao.csv\")\nnom_tu_tao = nom_tu_tao_300_df['word'].tolist()\n\nwith open(f\"{OUTPUT_PATH}/nom_tu_tao.txt\", \"w\", encoding=\"utf-8\") as f:\n    f.write(\"\\n\".join(nom_tu_tao))\nkieu = [ğ¤¾“,ğ¢†¥,ğ¥ª,æ†,ğ Š›,äº›,ğ¡¦‚,æ‰,ğ¡¦‚,å‘½,çª–,ğ±ºµ,æ„,é¥’,ğ£¦†,æˆˆ,æ²¡,å±€,ğ£·­,æ©·,ä»,èª¿,ğ¬–‰,ğ§¡Š,ãŒ,ğ¤´¬,ç–¸,ğ¢š¸,ğ¨”,ä¹‹,å½¼,å—‡,æ–¯,è±Š,ğ¡—¶,æ’‘,æ¶“,è²,ğ¦Ÿ,ç´…,æ‰“,ã­´,ç¨¿,ğ¦¹³,å,ğ± ,ğ “€,ç•‘,é¢¨,æƒ…,å›º,éŒ„,ç¾¤,å‚³,å²,æ’‘,æµª,ğ¢†¥,ó°¸,é–,æœ,æ˜,ğ¦Šš,æ–¹,ğª¹š,ğ£¼½,ğ „©,äº¬,å‡­,é„,å›º,èŒ¹,å“¡,å¤–,æˆ·,ç‹,å®¶,è³‡,æ“¬,æ‹±,å¸¸,å¸¸,å ›,ä¸­]\nprint(\",\".join(kieu))","metadata":{"id":"Mx5uS5WQaqdn","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"448e1707-8e07-4cdb-db28-f319e3a9d533"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid non-printable character U+F07B8 (ipython-input-1462724732.py, line 7)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1462724732.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    kieu = [ğ¤¾“,ğ¢†¥,ğ¥ª,æ†,ğ Š›,äº›,ğ¡¦‚,æ‰,ğ¡¦‚,å‘½,çª–,ğ±ºµ,æ„,é¥’,ğ£¦†,æˆˆ,æ²¡,å±€,ğ£·­,æ©·,ä»,èª¿,ğ¬–‰,ğ§¡Š,ãŒ,ğ¤´¬,ç–¸,ğ¢š¸,ğ¨”,ä¹‹,å½¼,å—‡,æ–¯,è±Š,ğ¡—¶,æ’‘,æ¶“,è²,ğ¦Ÿ,ç´…,æ‰“,ã­´,ç¨¿,ğ¦¹³,å,ğ± ,ğ “€,ç•‘,é¢¨,æƒ…,å›º,éŒ„,ç¾¤,å‚³,å²,æ’‘,æµª,ğ¢†¥,ó°¸,é–,æœ,æ˜,ğ¦Šš,æ–¹,ğª¹š,ğ£¼½,ğ „©,äº¬,å‡­,é„,å›º,èŒ¹,å“¡,å¤–,æˆ·,ç‹,å®¶,è³‡,æ“¬,æ‹±,å¸¸,å¸¸,å ›,ä¸­]\u001b[0m\n\u001b[0m                                                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid non-printable character U+F07B8\n"]}],"execution_count":25},{"cell_type":"code","source":"%cd FontDiffusion\n!python sample_optimized.py \\\n    --ckpt_dir=\"../ckpt/\" \\\n    --style_image_path=\"/content/FontDiffusion/DVSKTT_ref.jpg\" \\\n    --save_image \\\n    --ttf_path=\"/content/FontDiffusion/fonts/NomNaTong-Regular.otf\" \\\n    --character_input \\\n    --content_character=\"ğ¤¾“,ğ¢†¥,ğ¥ª,æ†,ğ Š›,äº›,ğ¡¦‚,æ‰,ğ¡¦‚,å‘½,çª–,ğ±ºµ,æ„,é¥’,ğ£¦†,æˆˆ,æ²¡,å±€,ğ£·­,æ©·,ä»,èª¿,ğ¬–‰,ğ§¡Š,ãŒ,ğ¤´¬,ç–¸,ğ¢š¸,ğ¨”,ä¹‹,å½¼,å—‡,æ–¯,è±Š,ğ¡—¶,æ’‘,æ¶“,è²,ğ¦Ÿ,ç´…,æ‰“,ã­´,ç¨¿,ğ¦¹³,å,ğ± ,ğ “€,ç•‘,é¢¨,æƒ…,å›º,éŒ„,ç¾¤,å‚³,å²,æ’‘,æµª,ğ¢†¥,ó°¸,é–,æœ,æ˜,ğ¦Šš,æ–¹,ğª¹š,ğ£¼½,ğ „©,äº¬,å‡­,é„,å›º,èŒ¹,å“¡,å¤–,æˆ·,ç‹,å®¶,è³‡,æ“¬,æ‹±,å¸¸,å¸¸,å ›,ä¸­\" \\\n    --save_image_dir=\"../kieu_output/\" \\\n    --device=\"cuda:0\" \\\n    --algorithm_type=\"dpmsolver++\" \\\n    --guidance_type=\"classifier-free\" \\\n    --guidance_scale=7.5 \\\n    --num_inference_steps=20 \\\n    --method=\"multistep\" \\\n    --channels_last","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gma02BZvhx8I","outputId":"a78c5252-10d9-4df7-e06a-ca46bbddc68c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'FontDiffusion'\n","/content/FontDiffusion\n","pygame 2.6.1 (SDL 2.28.4, Python 3.12.12)\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n","\n","============================================================\n","FONTDIFFUSER - OPTIMIZED SAMPLING\n","============================================================\n","Model: ../ckpt/\n","Device: cuda:0\n","FP16: False\n","Channels Last: True\n","Batch Size: 1\n","============================================================\n","\n","Loading FontDiffuser pipeline...\n","Load the down block  DownBlock2D\n","Load the down block  MCADownBlock2D\n","The style_attention cross attention dim in Down Block 1 layer is 1024\n","The style_attention cross attention dim in Down Block 2 layer is 1024\n","Load the down block  MCADownBlock2D\n","The style_attention cross attention dim in Down Block 1 layer is 1024\n","The style_attention cross attention dim in Down Block 2 layer is 1024\n","Load the down block  DownBlock2D\n","Load the up block  UpBlock2D\n","Load the up block  StyleRSIUpBlock2D\n","Load the up block  StyleRSIUpBlock2D\n","Load the up block  UpBlock2D\n","Param count for Ds initialized parameters: 20591296\n","Get CG-GAN Style Encoder!\n","Param count for Ds initialized parameters: 1187008\n","Get CG-GAN Content Encoder!\n","âœ“ Loaded model state_dict successfully\n","Converting to channels-last memory format...\n","2025-12-28 09:38:05.460578: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1766914685.478906   11059 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1766914685.485995   11059 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1766914685.504579   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1766914685.504606   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1766914685.504610   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1766914685.504616   11059 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-12-28 09:38:05.509381: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","âœ“ Model moved to device\n","âœ“ Loaded training DDPM scheduler successfully\n","âœ“ Loaded DPM-Solver pipeline successfully\n","\n","============================================================\n","BATCH MODE ACTIVATED\n","Characters: 84\n","============================================================\n","âœ“ Font loaded: NomNaTong-Regular\n","\n","[Font 1/1] NomNaTong-Regular\n","------------------------------------------------------------\n","Available characters: 84/84\n","error: XDG_RUNTIME_DIR not set in the environment.\n","ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n","ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n","ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n","ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n","ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n","ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n","Sampling 84 characters with DPM-Solver++ ...\n","/content/FontDiffusion/src/model.py:88: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.style_encoder'.\n","  style_img_feature, _, style_residual_features = self.style_encoder(style_images)\n","/content/FontDiffusion/src/model.py:94: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n","  content_img_feture, content_residual_features = self.content_encoder(content_images)\n","/content/FontDiffusion/src/model.py:97: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.content_encoder'.\n","  style_content_feature, style_content_res_features = self.content_encoder(style_images)\n","/content/FontDiffusion/src/model.py:102: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModelDPM' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModelDPM's config object instead, e.g. 'unet.config.unet'.\n","  out = self.unet(\n","âœ“ Generated 84 images in 171.99s (2.048s/img)\n","âœ“ Saved 84 images to ../kieu_output/NomNaTong-Regular\n","\n","============================================================\n","âœ“ BATCH PROCESSING COMPLETE\n","============================================================\n"]}],"execution_count":27},{"cell_type":"code","source":"                                                        # @title Zipping the results folder\n!zip -r {OUTPUT_PATH}/kieu_output.zip {OUTPUT_PATH}/kieu_output\nprint(f\"Finish zipped the output data, ready for downloading\")","metadata":{"id":"kTz9WZ9ylBZx","colab":{"base_uri":"https://localhost:8080/"},"outputId":"beee5c89-037b-4336-fe52-3499e403b128"},"outputs":[{"output_type":"stream","name":"stdout","text":["  adding: content//kieu_output/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ©·/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ©·/out_single.png (deflated 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ „©/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ „©/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å¸¸/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å¸¸/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç•‘/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç•‘/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğª¹š/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğª¹š/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æƒ…/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æƒ…/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ’‘/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ’‘/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é–/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é–/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ²¡/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ²¡/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¦Šš/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¦Šš/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/éŒ„/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/éŒ„/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å‚³/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å‚³/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ–¯/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ–¯/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å±€/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å±€/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ‰“/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ‰“/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ã­´/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ã­´/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ä¸­/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ä¸­/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ£¦†/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ£¦†/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¤´¬/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¤´¬/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/äº›/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/äº›/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ±ºµ/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ±ºµ/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ‹±/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ‹±/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/èŒ¹/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/èŒ¹/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å‡­/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å‡­/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ó°¸/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ó°¸/out_single.png (deflated 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é„/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é„/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ£¼½/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ£¼½/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ± / (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ± /out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ãŒ/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ãŒ/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¦Ÿ/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¦Ÿ/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/çª–/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/çª–/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¡—¶/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¡—¶/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å›º/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å›º/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ–¹/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ–¹/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç–¸/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç–¸/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å®¶/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å®¶/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/äº¬/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/äº¬/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å‘½/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å‘½/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å—‡/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å—‡/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æœ/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æœ/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ£·­/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ£·­/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¨”/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¨”/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¡¦‚/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¡¦‚/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ä»/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ä»/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/è³‡/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/è³‡/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é¥’/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é¥’/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å¤–/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å¤–/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ†/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ†/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç‹/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç‹/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ‰/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ‰/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¢š¸/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¢š¸/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¦¹³/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¦¹³/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æˆˆ/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æˆˆ/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å“¡/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å“¡/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ„/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ„/out_single.png (deflated 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç¨¿/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç¨¿/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å½¼/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å½¼/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¢†¥/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¢†¥/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç´…/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç´…/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ§¡Š/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ§¡Š/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æµª/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æµª/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¬–‰/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¬–‰/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/è²/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/è²/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¥ª/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¥ª/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/è±Š/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/è±Š/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å ›/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å ›/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç¾¤/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ç¾¤/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¤¾“/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ¤¾“/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ “€/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ “€/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é¢¨/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/é¢¨/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æˆ·/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æˆ·/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ“¬/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ“¬/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å²/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å²/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ˜/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ˜/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ¶“/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/æ¶“/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ Š›/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ğ Š›/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ä¹‹/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/ä¹‹/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/å/out_single.png (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/èª¿/ (stored 0%)\n","  adding: content//kieu_output/NomNaTong-Regular/èª¿/out_single.png (stored 0%)\n","  adding: content//kieu_output/sampling_config.yaml (deflated 50%)\n","Finish zipped the output data, ready for downloading\n"]}],"execution_count":28},{"cell_type":"code","source":"# @title Happy Christmasâœ¨\n# !rm -r -f FontDiffusion","metadata":{"id":"SIH9c0l-mRqB"},"outputs":[],"execution_count":24}]}