{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# @title Environment Setup\nimport os\nimport sys\nif 'MPLBACKEND' in os.environ:\n    del os.environ['MPLBACKEND']\n    print(\"MPLBACKEND environment variable cleared.\")\n\n# 2. Clone the repository\n!rm -rf FontDiffusion\n!git clone https://github.com/dzungphieuluuky/FontDiffusion.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-30T12:21:30.229410Z","iopub.execute_input":"2025-12-30T12:21:30.229657Z","iopub.status.idle":"2025-12-30T12:21:42.643575Z","shell.execute_reply.started":"2025-12-30T12:21:30.229636Z","shell.execute_reply":"2025-12-30T12:21:42.642649Z"},"id":"BWFvN9XJxf9K","outputId":"d1e6ea13-90a3-4efc-d682-f3d24f7d17c9","trusted":true},"outputs":[{"name":"stdout","text":"MPLBACKEND environment variable cleared.\nCloning into 'FontDiffusion'...\nremote: Enumerating objects: 20050, done.\u001b[K\nremote: Counting objects: 100% (4862/4862), done.\u001b[K\nremote: Compressing objects: 100% (4849/4849), done.\u001b[K\nremote: Total 20050 (delta 28), reused 4838 (delta 13), pack-reused 15188 (from 3)\u001b[K\nReceiving objects: 100% (20050/20050), 277.13 MiB | 35.06 MiB/s, done.\nResolving deltas: 100% (591/591), done.\nUpdating files: 100% (134/134), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom IPython import get_ipython\nfrom typing import Optional\n\ndef configure_environment_paths():\n    \"\"\"Detect environment and configure paths\"\"\"\n    try:\n        if \"google.colab\" in str(get_ipython()):\n            print(\"‚úÖ Environment: Google Colab\")\n            base_data_path = \"/content/\"\n            base_output_path = \"/content/\"\n            environment_name = \"colab\"\n        elif os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n            print(\"‚úÖ Environment: Kaggle\")\n            base_data_path = \"/kaggle/input/\"\n            base_output_path = \"/kaggle/working/\"\n            environment_name = \"kaggle\"\n        else:\n            print(\"‚ö†Ô∏è Environment: Local/Unknown\")\n            base_data_path = \"./data/\"\n            base_output_path = \"./output/\"\n            environment_name = \"local\"\n    except NameError:\n        print(\"‚ö†Ô∏è Non-interactive session. Using local paths.\")\n        base_data_path = \"./data/\"\n        base_output_path = \"./output/\"\n        environment_name = \"local\"\n    os.makedirs(base_output_path, exist_ok=True)\n    print(f\"üìÇ Data Path: {base_data_path}\")\n    print(f\"üì¶ Output Path: {base_output_path}\")\n    return base_data_path, base_output_path, environment_name\ndef load_secret(key_name: str) -> Optional[str]:\n    \"\"\"\n    Loads a secret key from the appropriate environment (Colab, Kaggle, or local env vars).\n    Args:\n        key_name (str): The name of the secret key to load (e.g., \"WANDB_API_KEY\", \"HF_TOKEN\").\n    Returns:\n        Optional[str]: The secret key value if found, otherwise None.\n    \"\"\"\n    env = ENV_NAME\n    secret_value = None\n    print(f\"Attempting to load secret '{key_name}' from '{env}' environment...\")\n    try:\n        if env == \"colab\":\n            from google.colab import userdata\n            secret_value = userdata.get(key_name)\n        elif env == \"kaggle\":\n            from kaggle_secrets import UserSecretsClient\n            user_secrets = UserSecretsClient()\n            secret_value = user_secrets.get_secret(key_name)\n        else: # Local environment\n            secret_value = os.getenv(key_name)\n        if not secret_value:\n            print(f\"‚ö†Ô∏è Secret '{key_name}' not found in the {env} environment.\")\n            return None\n        print(f\"‚úÖ Successfully loaded secret '{key_name}'.\")\n        return secret_value\n    except Exception as e:\n        print(f\"‚ùå An error occurred while loading secret '{key_name}': {e}\")\n        return None\nINPUT_PATH, OUTPUT_PATH, ENV_NAME = configure_environment_paths()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-30T12:21:42.645512Z","iopub.execute_input":"2025-12-30T12:21:42.645812Z","iopub.status.idle":"2025-12-30T12:21:42.655513Z","shell.execute_reply.started":"2025-12-30T12:21:42.645784Z","shell.execute_reply":"2025-12-30T12:21:42.654663Z"},"id":"sxdyquWfaqdm","outputId":"34240e47-89c7-4fdd-e8ab-862f0538a3b2","trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Environment: Kaggle\nüìÇ Data Path: /kaggle/input/\nüì¶ Output Path: /kaggle/working/\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!uv pip install --upgrade pip\n!uv pip install -r FontDiffusion/requirements.txt\n!uv pip install gdown\n# 3. Install PyTorch 1.13\n%cd {OUTPUT_PATH}\nprint(\"\\n‚¨áÔ∏è Installing PyTorch 1.13 (Required for this model)...\")\n# Force reinstall torch 1.13 to match the model's training environment\n# !uv pip uninstall torch torchvision\n# !uv pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 --extra-index-url https://download.pytorch.org/whl/cu117\n!uv pip install torch torchvision\n# 4. Install other dependencies\nprint(\"\\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\")\n# Install xformers compatible with Torch 1.13\n!uv pip install xformers==0.0.16 -q\n\n# Install original dependencies\n!uv pip install transformers==4.33.1 accelerate==0.23.0 diffusers==0.22.0\n!uv pip install gradio==4.8.0 pyyaml pygame opencv-python info-nce-pytorch kornia\n# -----------------------------------------------------------------\n!uv pip install lpips scikit-image pytorch-fid\n!sudo apt-get update && sudo apt-get install dos2unix\n!uv pip install wandb\nprint(\"\\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ET_mqyek9bwj","outputId":"72a8181b-4ab5-4cb2-bd4e-af5bd843896d","trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:21:42.656303Z","iopub.execute_input":"2025-12-30T12:21:42.656586Z","iopub.status.idle":"2025-12-30T12:23:11.851925Z","shell.execute_reply.started":"2025-12-30T12:21:42.656561Z","shell.execute_reply":"2025-12-30T12:23:11.851165Z"}},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m1 package\u001b[0m \u001b[2min 159ms\u001b[0m\u001b[0m                                          \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 112ms\u001b[0m\u001b[0m                                              \n\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 142ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.1.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==25.3\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m127 packages\u001b[0m \u001b[2min 938ms\u001b[0m\u001b[0m                                       \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m34 packages\u001b[0m \u001b[2min 43.89s\u001b[0m\u001b[0m                                           \n\u001b[2mUninstalled \u001b[1m28 packages\u001b[0m \u001b[2min 1.97s\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m34 packages\u001b[0m \u001b[2min 301ms\u001b[0m\u001b[0m                              \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==1.9.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==0.23.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.34.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==5.38.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgradio\u001b[0m\u001b[2m==4.8.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==1.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mgradio-client\u001b[0m\u001b[2m==0.7.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1minfo-nce-pytorch\u001b[0m\u001b[2m==0.1.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mlpips\u001b[0m\u001b[2m==0.1.4\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==2.1.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.5.3.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cublas-cu12\u001b[0m\u001b[2m==12.8.4.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-cupti-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-nvrtc-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cuda-runtime-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.3.0.75\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cudnn-cu12\u001b[0m\u001b[2m==9.10.2.21\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.2.3.61\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufft-cu12\u001b[0m\u001b[2m==11.3.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cufile-cu12\u001b[0m\u001b[2m==1.13.1.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.6.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-curand-cu12\u001b[0m\u001b[2m==10.3.9.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.6.3.83\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusolver-cu12\u001b[0m\u001b[2m==11.7.3.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.1.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparse-cu12\u001b[0m\u001b[2m==12.5.8.93\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.6.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-cusparselt-cu12\u001b[0m\u001b[2m==0.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.21.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nccl-cu12\u001b[0m\u001b[2m==2.27.5\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.5.82\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvjitlink-cu12\u001b[0m\u001b[2m==12.8.93\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvshmem-cu12\u001b[0m\u001b[2m==3.3.20\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.4.127\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnvidia-nvtx-cu12\u001b[0m\u001b[2m==12.8.90\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.12.0.88\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mopencv-python\u001b[0m\u001b[2m==4.11.0.86\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpytorch-fid\u001b[0m\u001b[2m==0.3.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.14.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.21.2\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.13.3\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.13.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtomlkit\u001b[0m\u001b[2m==0.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.6.0+cu124 (from https://download.pytorch.org/whl/cu124/torch-2.6.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.9.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.21.0+cu124 (from https://download.pytorch.org/whl/cu124/torchvision-0.21.0%2Bcu124-cp311-cp311-linux_x86_64.whl)\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.24.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.53.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.33.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.2.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mtriton\u001b[0m\u001b[2m==3.5.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==15.0.1\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mwebsockets\u001b[0m\u001b[2m==11.0.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mxformers\u001b[0m\u001b[2m==0.0.33.post2\u001b[0m\n\u001b[1m\u001b[33mwarning\u001b[39m\u001b[0m\u001b[1m:\u001b[0m \u001b[1mThe package `typer==0.16.0` does not have an extra named `all`\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 112ms\u001b[0m\u001b[0m\n/kaggle/working\n\n‚¨áÔ∏è Installing PyTorch 1.13 (Required for this model)...\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m2 packages\u001b[0m \u001b[2min 102ms\u001b[0m\u001b[0m\n\n‚¨áÔ∏è Installing Dependencies (Manually fixed)...\n  \u001b[31m√ó\u001b[0m Failed to build `xformers==0.0.16`\n\u001b[31m  ‚îú‚îÄ‚ñ∂ \u001b[0mThe build backend returned an error\n\u001b[31m  ‚ï∞‚îÄ‚ñ∂ \u001b[0mCall to `setuptools.build_meta:__legacy__.build_wheel` failed (exit\n\u001b[31m      \u001b[0mstatus: 1)\n\n\u001b[31m      \u001b[0m\u001b[31m[stderr]\u001b[39m\n\u001b[31m      \u001b[0mError in sitecustomize; set PYTHONVERBOSE for traceback:\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'wrapt'\n\u001b[31m      \u001b[0mTraceback (most recent call last):\n\u001b[31m      \u001b[0m  File \"<string>\", line 14, in <module>\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpROAIMS/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 331, in get_requires_for_build_wheel\n\u001b[31m      \u001b[0m    return self._get_build_requires(config_settings, requirements=[])\n\u001b[31m      \u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpROAIMS/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 301, in _get_build_requires\n\u001b[31m      \u001b[0m    self.run_setup()\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpROAIMS/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 512, in run_setup\n\u001b[31m      \u001b[0m    super().run_setup(setup_script=setup_script)\n\u001b[31m      \u001b[0m  File\n\u001b[31m      \u001b[0m\"/root/.cache/uv/builds-v0/.tmpROAIMS/lib/python3.11/site-packages/setuptools/build_meta.py\",\n\u001b[31m      \u001b[0mline 317, in run_setup\n\u001b[31m      \u001b[0m    exec(code, locals())\n\u001b[31m      \u001b[0m  File \"<string>\", line 23, in <module>\n\u001b[31m      \u001b[0mModuleNotFoundError: No module named 'torch'\n\n\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m This error likely indicates that `\u001b[36mxformers@0.0.16\u001b[39m` depends\n\u001b[31m      \u001b[0mon `\u001b[36mtorch\u001b[39m`, but doesn't declare it as a build dependency. If\n\u001b[31m      \u001b[0m`\u001b[36mxformers\u001b[39m` is a first-party package, consider adding `\u001b[36mtorch\u001b[39m` to its\n\u001b[31m      \u001b[0m`\u001b[32mbuild-system.requires\u001b[39m`. Otherwise, `\u001b[32muv pip install torch\u001b[39m` into the\n\u001b[31m      \u001b[0menvironment and re-run with `\u001b[32m--no-build-isolation\u001b[39m`.\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m6 packages\u001b[0m \u001b[2min 116ms\u001b[0m\u001b[0m\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m3 packages\u001b[0m \u001b[2min 105ms\u001b[0m\u001b[0m\nGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \nGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,225 kB]\nGet:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\nHit:7 http://archive.ubuntu.com/ubuntu jammy InRelease                         \nGet:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,860 kB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:10 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\nGet:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,572 kB] \nGet:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\nGet:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\nHit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\nHit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \nGet:17 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\nGet:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,966 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [37.2 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\nFetched 38.5 MB in 3s (14.5 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  dos2unix\n0 upgraded, 1 newly installed, 0 to remove and 192 not upgraded.\nNeed to get 384 kB of archives.\nAfter this operation, 1,367 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dos2unix amd64 7.4.2-2 [384 kB]\nFetched 384 kB in 0s (1,642 kB/s)\ndebconf: unable to initialize frontend: Dialog\ndebconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\ndebconf: falling back to frontend: Readline\nSelecting previously unselected package dos2unix.\n(Reading database ... 128639 files and directories currently installed.)\nPreparing to unpack .../dos2unix_7.4.2-2_amd64.deb ...\nUnpacking dos2unix (7.4.2-2) ...\nSetting up dos2unix (7.4.2-2) ...\nProcessing triggers for man-db (2.10.2-1) ...\n\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 99ms\u001b[0m\u001b[0m\n\n‚úÖ Environment setup complete. You can now proceed to Block 2 (Inference).\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import gdown\n%cd {OUTPUT_PATH}\nif not os.path.exists(\"ckpt\"):\n  url = \"https://drive.google.com/drive/folders/12hfuZ9MQvXqcteNuz7JQ2B_mUcTr-5jZ\"\n  gdown.download_folder(url, quiet=True, use_cookies=False)","metadata":{"execution":{"iopub.status.busy":"2025-12-30T12:23:11.853042Z","iopub.execute_input":"2025-12-30T12:23:11.853834Z","iopub.status.idle":"2025-12-30T12:23:22.669639Z","shell.execute_reply.started":"2025-12-30T12:23:11.853803Z","shell.execute_reply":"2025-12-30T12:23:22.669052Z"},"id":"9PsLgUs0cYmO","trusted":true,"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8094bdf0-c849-4c25-ece8-138626bf620c"},"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# @title Unzipping all archived files\nimport os\nimport glob\nfrom zipfile import ZipFile\n\nzip_file_paths = glob.glob(os.path.join(INPUT_PATH, '*.zip'))\n\nif not zip_file_paths:\n    print(f'No .zip files found in {INPUT_PATH}.')\nelse:\n    for zip_file_path in zip_file_paths:\n        if os.path.exists(zip_file_path):\n            print(f'Unzipping {zip_file_path}...')\n            !unzip -o {zip_file_path} -d ./\n            print(f'Unzipping of {zip_file_path} complete.')\n        else:\n            print(f'Error: The file {zip_file_path} was not found (post-glob check).')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-30T12:23:22.671069Z","iopub.execute_input":"2025-12-30T12:23:22.671391Z","iopub.status.idle":"2025-12-30T12:23:22.677958Z","shell.execute_reply.started":"2025-12-30T12:23:22.671363Z","shell.execute_reply":"2025-12-30T12:23:22.677272Z"},"id":"ecfc18e0","outputId":"10caea34-d3f7-4e97-8210-a035b6315a6e","trusted":true},"outputs":[{"name":"stdout","text":"No .zip files found in /kaggle/input/.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# @title Checking checkpoint files (.pth)\nimport os\nimport time\n\nCHECKPOINT_DIR = os.path.join(OUTPUT_PATH, \"ckpt\")\nprint(CHECKPOINT_DIR)\nos.makedirs(CHECKPOINT_DIR, exist_ok=True)\nrequired_files = [\"unet.pth\", \"content_encoder.pth\", \"style_encoder.pth\"]\nwhile True:\n    missing = [f for f in required_files if not os.path.exists(f\"{CHECKPOINT_DIR}/{f}\")]\n    if not missing:\n        print(\"\\n‚úÖ All weights found! You can proceed to the next step.\")\n        break\n    else:\n        print(f\"Waiting for files... Missing: {missing}\")\n        print(\"Upload them to the 'ckpt' folder now.\")\n        time.sleep(10) # Checks every 10 seconds","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-30T12:23:22.678603Z","iopub.execute_input":"2025-12-30T12:23:22.678833Z","iopub.status.idle":"2025-12-30T12:23:22.693378Z","shell.execute_reply.started":"2025-12-30T12:23:22.678816Z","shell.execute_reply":"2025-12-30T12:23:22.692753Z"},"id":"JBflCTABxlF4","outputId":"ad4e8eb2-c813-4e52-dfe2-e68779779a5c","trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/working/ckpt\n\n‚úÖ All weights found! You can proceed to the next step.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nimport os\n\ndef convert_csv_to_chars_txt(input_csv_path: str, output_txt_path: str, column_name: str = 'word'):\n    \"\"\"\n    Reads a CSV file, extracts text from a specified column, and writes each character\n    to a new line in a plain text file.\n\n    Args:\n        input_csv_path (str): The full path to the input CSV file.\n        output_txt_path (str): The full path for the output text file.\n        column_name (str): The name of the column in the CSV file containing the text.\n    \"\"\"\n    if not os.path.exists(input_csv_path):\n        print(f\"Error: Input CSV file not found at '{input_csv_path}'. Please ensure the file is uploaded.\")\n        return\n\n    try:\n        df = pd.read_csv(input_csv_path)\n    except Exception as e:\n        print(f\"Error reading CSV file '{input_csv_path}': {e}\")\n        return\n\n    if column_name not in df.columns:\n        print(f\"Error: Column '{column_name}' not found in the CSV file '{input_csv_path}'.\")\n        return\n\n    all_characters = []\n    # Ensure the column values are treated as strings before iterating over them\n    for item in df[column_name].astype(str).dropna().tolist():\n        for char in item:\n            all_characters.append(char)\n\n    # Ensure output directory exists\n    os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)\n\n    with open(output_txt_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(\"\\n\".join(all_characters))\n    print(f\"Successfully converted '{input_csv_path}' to '{output_txt_path}', with one character per line.\")\n\n# --- Example Usage (demonstration with a dummy file) ---\n# As the original file 'Ds_300_ChuNom_TuTao.csv' was not found in the previous execution,\n# let's create a dummy file to demonstrate the function's usage.\nprint(\"\\n--- Demonstrating function with a dummy CSV file ---\")\ndummy_csv_path = os.path.join(OUTPUT_PATH, \"dummy_data.csv\")\ndummy_output_txt_path = os.path.join(OUTPUT_PATH, \"dummy_chars.txt\")\n\n# Create a dummy CSV file\ndummy_data = {'word': ['hello', 'world', 'python']}\npd.DataFrame(dummy_data).to_csv(dummy_csv_path, index=False)\nprint(f\"Created a dummy CSV file at: {dummy_csv_path}\")\n\nconvert_csv_to_chars_txt(dummy_csv_path, dummy_output_txt_path)\n\n# --- How to use with your actual file ---\n# Uncomment the lines below and replace 'your_actual_file.csv' and 'your_output.txt'\n# with the correct paths for your use case.\n#\n# original_csv_file = os.path.join(INPUT_PATH, \"Ds_300_ChuNom_TuTao.csv\") # Or the full path to your CSV\n# original_output_txt = os.path.join(OUTPUT_PATH, \"nom_tu_tao.txt\") # Or your desired output path\n# convert_csv_to_chars_txt(original_csv_file, original_output_txt)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-30T12:23:22.695018Z","iopub.execute_input":"2025-12-30T12:23:22.695257Z","iopub.status.idle":"2025-12-30T12:23:23.046408Z","shell.execute_reply.started":"2025-12-30T12:23:22.695241Z","shell.execute_reply":"2025-12-30T12:23:23.045864Z"},"id":"Mx5uS5WQaqdn","outputId":"6e7bfbad-064c-4324-8cbd-53f8bc4038dc","trusted":true},"outputs":[{"name":"stdout","text":"\n--- Demonstrating function with a dummy CSV file ---\nCreated a dummy CSV file at: /kaggle/working/dummy_data.csv\nSuccessfully converted '/kaggle/working/dummy_data.csv' to '/kaggle/working/dummy_chars.txt', with one character per line.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!ls -r -t {OUTPUT_PATH}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:29:30.016245Z","iopub.execute_input":"2025-12-30T12:29:30.016575Z","iopub.status.idle":"2025-12-30T12:29:30.135578Z","shell.execute_reply.started":"2025-12-30T12:29:30.016543Z","shell.execute_reply":"2025-12-30T12:29:30.134924Z"}},"outputs":[{"name":"stdout","text":"FontDiffusion  ckpt  dummy_data.csv  dummy_chars.txt  my_dataset\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"%cd {OUTPUT_PATH}\nHF_TOKEN = load_secret(\"HF_TOKEN\")\nHF_USERNAME = \"dzungpham\"\n\n# ==========================================\n# EXPORT / DOWNLOAD DATASET COMMANDS\n# ==========================================\n\n# Train Split\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/train\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train\" \\\n  --token HF_TOKEN\n# Validation: Unseen Both\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val_unseen_both\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val_unseen_both\" \\\n  --token HF_TOKEN\n\n# Validation: Seen Style, Unseen Char\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val_seen_style_unseen_char\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val_seen_style_unseen_char\" \\\n  --token HF_TOKEN\n\n# Validation: Unseen Style, Seen Char\n!python FontDiffusion/export_hf_dataset_to_disk.py \\\n  --output_dir \"my_dataset/val_unseen_style_seen_char\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"val_unseen_style_seen_char\" \\\n  --token HF_TOKEN","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-30T12:28:10.986534Z","iopub.execute_input":"2025-12-30T12:28:10.987191Z","iopub.status.idle":"2025-12-30T12:28:46.082444Z","shell.execute_reply.started":"2025-12-30T12:28:10.987156Z","shell.execute_reply":"2025-12-30T12:28:46.081747Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working\nAttempting to load secret 'HF_TOKEN' from 'kaggle' environment...\n‚úÖ Successfully loaded secret 'HF_TOKEN'.\n\n============================================================\nFONTDIFFUSION DATASET EXPORTER\n============================================================\n‚úì Created output directories:\n  Root: my_dataset/train\n  Content: my_dataset/train/ContentImage\n  Target: my_dataset/train/TargetImage\n\n============================================================\nLOADING DATASET\n============================================================\n\nLoading from Hub: dzungpham/font-diffusion-generated-data\nREADME.md: 1.28kB [00:00, 784kB/s]\ndata/train-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà| 15.0M/15.0M [00:01<00:00, 13.8MB/s]\ndata/val-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 262k/262k [00:00<00:00, 2.60MB/s]\ndata/val_seen_style_unseen_char-00000-of(‚Ä¶): 100%|‚ñà| 820k/820k [00:00<00:00, 1.1\ndata/val_unseen_style_seen_char-00000-of(‚Ä¶): 100%|‚ñà| 4.69M/4.69M [00:00<00:00, 5\ndata/train_original-00000-of-00001.parqu(‚Ä¶): 100%|‚ñà| 68.3M/68.3M [00:01<00:00, 4\ntest-00000-of-00001.parquet: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79.8k/79.8k [00:00<00:00, 5.47MB/s]\nGenerating train split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà| 1639/1639 [00:00<00:00, 17909.71 examples/s]\nGenerating val split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:00<00:00, 6703.74 examples/s]\nGenerating val_unseen_both split: 100%|‚ñà| 24/24 [00:00<00:00, 8423.00 examples/s\nGenerating val_seen_style_unseen_char split: 100%|‚ñà| 88/88 [00:00<00:00, 19385.4\nGenerating val_unseen_style_seen_char split: 100%|‚ñà| 447/447 [00:00<00:00, 30516\nGenerating train_original split: 100%|‚ñà| 4470/4470 [00:00<00:00, 23213.52 exampl\nGenerating test split: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 1732.18 examples/s]\n‚úì Loaded dataset with 1639 samples\n  Columns: ['character', 'char_index', 'style', 'style_index', 'content_image', 'target_image', 'font']\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nFound:\n  11 unique styles\n  1 unique characters\n  149 character indices\n\n‚úì Created 11 style directories\n\n------------------------------------------------------------\nExporting content images...\n------------------------------------------------------------\nüñºÔ∏è  Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1639/1639 [00:01<00:00, 1205.86it/s]\n‚úì Exported 149 content images\n\n------------------------------------------------------------\nExporting target images...\n------------------------------------------------------------\nüé® Styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1639/1639 [00:03<00:00, 440.53it/s]\n‚úì Exported 1639 target images\n\n------------------------------------------------------------\nSaving metadata...\n------------------------------------------------------------\n‚úì Saved metadata to my_dataset/train/results.json\n  Total generations: 1639\n  Styles: 11\n  Characters: 1\n\n============================================================\nEXPORT SUMMARY\n============================================================\n\n‚úì Export Statistics:\n  Root: my_dataset/train\n  Total samples: 1639\n  Styles: 11\n  Characters: 1\n  Target images: 1639\n\n‚úì Directory Structure:\n  my_dataset/train/\n  ‚îú‚îÄ‚îÄ ContentImage/ (11 images)\n  ‚îú‚îÄ‚îÄ TargetImage/\n  ‚îÇ   ‚îú‚îÄ‚îÄ style10/ (149 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style11/ (149 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style12/ (149 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ ... (8 more styles)\n  ‚îî‚îÄ‚îÄ results.json\n\n‚úì Summary saved to my_dataset/train/export_summary.json\n\n‚úì Export completed successfully!\n\n============================================================\nFONTDIFFUSION DATASET EXPORTER\n============================================================\n‚úì Created output directories:\n  Root: my_dataset/val_unseen_both\n  Content: my_dataset/val_unseen_both/ContentImage\n  Target: my_dataset/val_unseen_both/TargetImage\n\n============================================================\nLOADING DATASET\n============================================================\n\nLoading from Hub: dzungpham/font-diffusion-generated-data\n‚úì Loaded dataset with 24 samples\n  Columns: ['character', 'char_index', 'style', 'style_index', 'content_image', 'target_image', 'font']\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nFound:\n  3 unique styles\n  1 unique characters\n  8 character indices\n\n‚úì Created 3 style directories\n\n------------------------------------------------------------\nExporting content images...\n------------------------------------------------------------\nüñºÔ∏è  Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:00<00:00, 498.47it/s]\n‚úì Exported 8 content images\n\n------------------------------------------------------------\nExporting target images...\n------------------------------------------------------------\nüé® Styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:00<00:00, 467.97it/s]\n‚úì Exported 24 target images\n\n------------------------------------------------------------\nSaving metadata...\n------------------------------------------------------------\n‚úì Saved metadata to my_dataset/val_unseen_both/results.json\n  Total generations: 24\n  Styles: 3\n  Characters: 1\n\n============================================================\nEXPORT SUMMARY\n============================================================\n\n‚úì Export Statistics:\n  Root: my_dataset/val_unseen_both\n  Total samples: 24\n  Styles: 3\n  Characters: 1\n  Target images: 24\n\n‚úì Directory Structure:\n  my_dataset/val_unseen_both/\n  ‚îú‚îÄ‚îÄ ContentImage/ (0 images)\n  ‚îú‚îÄ‚îÄ TargetImage/\n  ‚îÇ   ‚îú‚îÄ‚îÄ style0/ (8 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style1/ (8 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style6/ (8 images)\n  ‚îî‚îÄ‚îÄ results.json\n\n‚úì Summary saved to my_dataset/val_unseen_both/export_summary.json\n\n‚úì Export completed successfully!\n\n============================================================\nFONTDIFFUSION DATASET EXPORTER\n============================================================\n‚úì Created output directories:\n  Root: my_dataset/val_seen_style_unseen_char\n  Content: my_dataset/val_seen_style_unseen_char/ContentImage\n  Target: my_dataset/val_seen_style_unseen_char/TargetImage\n\n============================================================\nLOADING DATASET\n============================================================\n\nLoading from Hub: dzungpham/font-diffusion-generated-data\n‚úì Loaded dataset with 88 samples\n  Columns: ['character', 'char_index', 'style', 'style_index', 'content_image', 'target_image', 'font']\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nFound:\n  11 unique styles\n  1 unique characters\n  8 character indices\n\n‚úì Created 11 style directories\n\n------------------------------------------------------------\nExporting content images...\n------------------------------------------------------------\nüñºÔ∏è  Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:00<00:00, 937.05it/s]\n‚úì Exported 8 content images\n\n------------------------------------------------------------\nExporting target images...\n------------------------------------------------------------\nüé® Styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 88/88 [00:00<00:00, 447.41it/s]\n‚úì Exported 88 target images\n\n------------------------------------------------------------\nSaving metadata...\n------------------------------------------------------------\n‚úì Saved metadata to my_dataset/val_seen_style_unseen_char/results.json\n  Total generations: 88\n  Styles: 11\n  Characters: 1\n\n============================================================\nEXPORT SUMMARY\n============================================================\n\n‚úì Export Statistics:\n  Root: my_dataset/val_seen_style_unseen_char\n  Total samples: 88\n  Styles: 11\n  Characters: 1\n  Target images: 88\n\n‚úì Directory Structure:\n  my_dataset/val_seen_style_unseen_char/\n  ‚îú‚îÄ‚îÄ ContentImage/ (0 images)\n  ‚îú‚îÄ‚îÄ TargetImage/\n  ‚îÇ   ‚îú‚îÄ‚îÄ style10/ (8 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style11/ (8 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style12/ (8 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ ... (8 more styles)\n  ‚îî‚îÄ‚îÄ results.json\n\n‚úì Summary saved to my_dataset/val_seen_style_unseen_char/export_summary.json\n\n‚úì Export completed successfully!\n\n============================================================\nFONTDIFFUSION DATASET EXPORTER\n============================================================\n‚úì Created output directories:\n  Root: my_dataset/val_unseen_style_seen_char\n  Content: my_dataset/val_unseen_style_seen_char/ContentImage\n  Target: my_dataset/val_unseen_style_seen_char/TargetImage\n\n============================================================\nLOADING DATASET\n============================================================\n\nLoading from Hub: dzungpham/font-diffusion-generated-data\n‚úì Loaded dataset with 447 samples\n  Columns: ['character', 'char_index', 'style', 'style_index', 'content_image', 'target_image', 'font']\n\n============================================================\nEXPORTING DATASET TO DISK\n============================================================\n\nFound:\n  3 unique styles\n  1 unique characters\n  149 character indices\n\n‚úì Created 3 style directories\n\n------------------------------------------------------------\nExporting content images...\n------------------------------------------------------------\nüñºÔ∏è  Processing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 447/447 [00:00<00:00, 862.93it/s]\n‚úì Exported 149 content images\n\n------------------------------------------------------------\nExporting target images...\n------------------------------------------------------------\nüé® Styles: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 447/447 [00:00<00:00, 496.98it/s]\n‚úì Exported 447 target images\n\n------------------------------------------------------------\nSaving metadata...\n------------------------------------------------------------\n‚úì Saved metadata to my_dataset/val_unseen_style_seen_char/results.json\n  Total generations: 447\n  Styles: 3\n  Characters: 1\n\n============================================================\nEXPORT SUMMARY\n============================================================\n\n‚úì Export Statistics:\n  Root: my_dataset/val_unseen_style_seen_char\n  Total samples: 447\n  Styles: 3\n  Characters: 1\n  Target images: 447\n\n‚úì Directory Structure:\n  my_dataset/val_unseen_style_seen_char/\n  ‚îú‚îÄ‚îÄ ContentImage/ (3 images)\n  ‚îú‚îÄ‚îÄ TargetImage/\n  ‚îÇ   ‚îú‚îÄ‚îÄ style0/ (149 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style1/ (149 images)\n  ‚îÇ   ‚îú‚îÄ‚îÄ style6/ (149 images)\n  ‚îî‚îÄ‚îÄ results.json\n\n‚úì Summary saved to my_dataset/val_unseen_style_seen_char/export_summary.json\n\n‚úì Export completed successfully!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!uv pip install --upgrade diffusers \"huggingface-hub>=0.15.1,<1.0\"\n%cd {OUTPUT_PATH}\n!python FontDiffusion/sample_batch.py \\\n    --characters \"FontDiffusion/NomTuTao/Ds_10k_ChuNom_TuTao.txt\" \\\n    --style_images \"FontDiffusion/styles_images\" \\\n    --ckpt_dir \"ckpt/\" \\\n    --ttf_path \"FontDiffusion/fonts\" \\\n    --output_dir \"my_dataset\" \\\n    --resume_from \"my_dataset/results.json\" \\\n    --num_inference_steps 20 \\\n    --guidance_scale 7.5 \\\n    --start_line 1 \\\n    --end_line 100 \\\n    --batch_size 24 \\\n    --save_interval 5 \\\n    --channels_last \\\n    --seed 42 \\\n    --compile \\\n    --enable_xformers","metadata":{"execution":{"iopub.status.busy":"2025-12-30T12:29:47.615999Z","iopub.execute_input":"2025-12-30T12:29:47.616303Z","iopub.status.idle":"2025-12-30T12:31:36.341638Z","shell.execute_reply.started":"2025-12-30T12:29:47.616273Z","shell.execute_reply":"2025-12-30T12:31:36.340886Z"},"id":"gma02BZvhx8I","trusted":true},"outputs":[{"name":"stdout","text":"\u001b[2mUsing Python 3.11.13 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m24 packages\u001b[0m \u001b[2min 176ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[2mPrepared \u001b[1m10 packages\u001b[0m \u001b[2min 542ms\u001b[0m\u001b[0m                                            \n\u001b[2mUninstalled \u001b[1m10 packages\u001b[0m \u001b[2min 101ms\u001b[0m\u001b[0m\n\u001b[2K\u001b[2mInstalled \u001b[1m10 packages\u001b[0m \u001b[2min 37ms\u001b[0m\u001b[0m                               \u001b[0m\n \u001b[31m-\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.11.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.10.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.11.12\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.22.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mdiffusers\u001b[0m\u001b[2m==0.36.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfilelock\u001b[0m\u001b[2m==3.20.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.10.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mfsspec\u001b[0m\u001b[2m==2025.12.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.7.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.7.1\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==2.4.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==10.4.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.5.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.6.2\u001b[0m\n/kaggle/working\nThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n0it [00:00, ?it/s]\n/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:311: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n  torch.utils._pytree._register_pytree_node(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\npygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\nHello from the pygame community. https://www.pygame.org/contribute.html\n\n============================================================\nFONTDIFFUSER STANDARD FORMAT GENERATION\n============================================================\nLoading characters from lines 1 to 100 (total: 10174 lines)\nSuccessfully loaded 100 single characters.\n\nInitializing font manager...\n\n============================================================\nLoading 15 fonts from directory...\n============================================================\nerror: XDG_RUNTIME_DIR not set in the environment.\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HAN NOM A\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HAN NOM B\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: Han-Nom Kai 1.00\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: Han-Nom-Khai-Regular-300623\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: Han-nom Minh 1.42\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HanaMinA\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HanaMinA\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HanaMinB\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HanaMinB\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: HanaMinC\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: NomNaTong-Regular\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: NomNaTong-Regular\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: NomNaTong-Regular2\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: NomNaTongLight\nALSA lib confmisc.c:855:(parse_card) cannot find card '0'\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\nALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\nALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\nALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\nALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\nALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n‚úì Loaded: NomNaTongLight2\n============================================================\nSuccessfully loaded 12 fonts\n\n\nüìä Configuration:\n  Number of Characters: 100 (lines 1-100)\n  Number of Styles: 15\n  Output Directory: my_dataset\n\n============================================================\nGenerating Content Images\nUsing 12 fonts\nCharacters: 100\n============================================================\nüìù Content images:   0%|                                | 0/100 [00:00<?, ?it/s]^C\nüìù Content images:   0%|                                | 0/100 [01:30<?, ?it/s]\n\n\n‚ö† Generation interrupted by user!\nüíæ Saving checkpoint before exit...\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ==========================================\n# CREATE / UPLOAD DATASET COMMANDS\n# ==========================================\n# Train Split\n!python create_hf_dataset.py \\\n  --data_dir \"my_dataset/train_original\" \\\n  --repo_id {HF_USERNAME}/font-diffusion-generated-data \\\n  --split \"train_original\" \\\n  --private \\\n  --token HF_TOKEN","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch, gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zXSQHJ3xVOSc","outputId":"a7f1d4de-bbb0-40cf-e528-2854c3d57770"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["15"]},"metadata":{},"execution_count":15}],"execution_count":15},{"cell_type":"code","source":"!wandb login\n!accelerate launch FontDiffusion/train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_1\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.7 \\\n    --max_train_steps=2000 \\\n    --ckpt_interval=1000 \\\n    --gradient_accumulation_steps=1 \\\n    --log_interval=50 \\\n    --learning_rate=1e-4 \\\n    --lr_scheduler=\"linear\" \\\n    --lr_warmup_steps=10000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxxJ9qy4KIZH","outputId":"ec12896b-9325-4b13-f7aa-d180caa26b55"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_processes` was set to a value of `1`\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","pygame 2.6.1 (SDL 2.28.4, Python 3.12.12)\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n","Load the down block  DownBlock2D\n","Load the down block  MCADownBlock2D\n","The style_attention cross attention dim in Down Block 1 layer is 1024\n","The style_attention cross attention dim in Down Block 2 layer is 1024\n","Load the down block  MCADownBlock2D\n","The style_attention cross attention dim in Down Block 1 layer is 1024\n","The style_attention cross attention dim in Down Block 2 layer is 1024\n","Load the down block  DownBlock2D\n","Load the up block  UpBlock2D\n","Load the up block  StyleRSIUpBlock2D\n","Load the up block  StyleRSIUpBlock2D\n","Load the up block  UpBlock2D\n","Param count for Ds initialized parameters: 20591296\n","Get CG-GAN Style Encoder!\n","Param count for Ds initialized parameters: 1187008\n","Get CG-GAN Content Encoder!\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","2025-12-30 09:02:29.404316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1767085349.425904   23390 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1767085349.433107   23390 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1767085349.452667   23390 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1767085349.452696   23390 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1767085349.452702   23390 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1767085349.452706   23390 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-12-30 09:02:29.457713: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251230_090236-s4kszdja\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrim-resonance-8\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/s4kszdja\u001b[0m\n","Steps:   0% 0/2000 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/diffusers/configuration_utils.py:141: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n","  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n","/content/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n","  style_img_feature, _, _ = self.style_encoder(style_images)\n","/content/FontDiffusion/src/model.py:40: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n","  content_img_feature, content_residual_features = self.content_encoder(content_images)\n","/content/FontDiffusion/src/model.py:43: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n","  style_content_feature, style_content_res_features = self.content_encoder(style_images)\n","/content/FontDiffusion/src/model.py:49: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n","  out = self.unet(\n","Steps:  50% 1000/2000 [16:44<16:44,  1.00s/it, lr=9.99e-6, step_loss=1.3]/content/FontDiffusion/train.py:253: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n","  torch.save(model.unet.state_dict(), f\"{save_dir}/unet.pth\")\n","/content/FontDiffusion/train.py:254: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n","  torch.save(model.style_encoder.state_dict(), f\"{save_dir}/style_encoder.pth\")\n","/content/FontDiffusion/train.py:255: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n","  torch.save(model.content_encoder.state_dict(), f\"{save_dir}/content_encoder.pth\")\n","Save the checkpoint on global step 1000\n","Steps: 100% 2000/2000 [33:37<00:00,  1.01s/it, lr=2e-5, step_loss=0.573]Save the checkpoint on global step 2000\n","Steps: 100% 2000/2000 [33:42<00:00,  1.01s/it, lr=2e-5, step_loss=0.917]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Finishing up...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Finishing up...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m Finishing up...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m Finishing up...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 1991-1999, summary, console lines 17-18 (0.1s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ‚ñá‚ñà‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.91669\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mtrim-resonance-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1/runs/s4kszdja\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251230_090236-s4kszdja/logs\u001b[0m\n","Steps: 100% 2000/2000 [33:43<00:00,  1.01s/it, lr=2e-5, step_loss=0.917]\n"]}],"execution_count":13},{"cell_type":"code","source":"!wandb login\n!accelerate launch FontDiffusion/train.py \\\n    --seed=123 \\\n    --experience_name=\"FontDiffuser_training_phase_2\" \\\n    --data_root=\"my_dataset\" \\\n    --output_dir=\"outputs/FontDiffuser\" \\\n    --report_to=\"wandb\" \\\n    --phase_2 \\\n    --phase_1_ckpt_dir=\"outputs/FontDiffuser/global_step_2000\" \\\n    --scr_ckpt_path=\"ckpt/scr_210000.pth\" \\\n    --sc_coefficient=0.05 \\\n    --num_neg=13 \\\n    --resolution=96 \\\n    --style_image_size=96 \\\n    --content_image_size=96 \\\n    --content_encoder_downsample_size=3 \\\n    --channel_attn=True \\\n    --content_start_channel=64 \\\n    --style_start_channel=64 \\\n    --train_batch_size=8 \\\n    --perceptual_coefficient=0.03 \\\n    --offset_coefficient=0.4 \\\n    --max_train_steps=100 \\\n    --ckpt_interval=50 \\\n    --gradient_accumulation_steps=2 \\\n    --log_interval=50 \\\n    --learning_rate=1e-5 \\\n    --lr_scheduler=\"constant\" \\\n    --lr_warmup_steps=1000 \\\n    --drop_prob=0.1 \\\n    --mixed_precision=\"no\"\n","metadata":{"id":"J4bplsS6pQna","outputId":"fc94a537-dc2d-45f8-ce33-905b978d6439","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","The following values were not passed to `accelerate launch` and had defaults used instead:\n","\t`--num_processes` was set to a value of `1`\n","\t`--num_machines` was set to a value of `1`\n","\t`--mixed_precision` was set to a value of `'no'`\n","\t`--dynamo_backend` was set to a value of `'no'`\n","To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n","pygame 2.6.1 (SDL 2.28.4, Python 3.12.12)\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n","Load the down block  DownBlock2D\n","Load the down block  MCADownBlock2D\n","The style_attention cross attention dim in Down Block 1 layer is 1024\n","The style_attention cross attention dim in Down Block 2 layer is 1024\n","Load the down block  MCADownBlock2D\n","The style_attention cross attention dim in Down Block 1 layer is 1024\n","The style_attention cross attention dim in Down Block 2 layer is 1024\n","Load the down block  DownBlock2D\n","Load the up block  UpBlock2D\n","Load the up block  StyleRSIUpBlock2D\n","Load the up block  StyleRSIUpBlock2D\n","Load the up block  UpBlock2D\n","Param count for Ds initialized parameters: 20591296\n","Get CG-GAN Style Encoder!\n","Param count for Ds initialized parameters: 1187008\n","Get CG-GAN Content Encoder!\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Loaded SCR module for supervision successfully!\n","2025-12-30 09:59:30.277739: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1767088770.295759   37515 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1767088770.301586   37515 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1767088770.316529   37515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1767088770.316550   37515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1767088770.316554   37515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1767088770.316557   37515 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","2025-12-30 09:59:30.320454: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungngocpham171\u001b[0m (\u001b[33mdungngocpham171-university-of-science\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m Waiting for wandb.init()...\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20251230_095937-me0n9ti7\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnorthern-field-2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_2/runs/me0n9ti7\u001b[0m\n","Steps:   0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/diffusers/configuration_utils.py:141: FutureWarning: Accessing config attribute `num_train_timesteps` directly via 'DDPMScheduler' object attribute is deprecated. Please access 'num_train_timesteps' over 'DDPMScheduler's config object instead, e.g. 'scheduler.config.num_train_timesteps'.\n","  deprecate(\"direct config name access\", \"1.0.0\", deprecation_message, standard_warn=False)\n","/content/FontDiffusion/src/model.py:34: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n","  style_img_feature, _, _ = self.style_encoder(style_images)\n","/content/FontDiffusion/src/model.py:40: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n","  content_img_feature, content_residual_features = self.content_encoder(content_images)\n","/content/FontDiffusion/src/model.py:43: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n","  style_content_feature, style_content_res_features = self.content_encoder(style_images)\n","/content/FontDiffusion/src/model.py:49: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n","  out = self.unet(\n","Steps:  50% 50/100 [02:21<02:26,  2.93s/it, lr=1e-5, step_loss=0.645]/content/FontDiffusion/train.py:253: FutureWarning: Accessing config attribute `unet` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'unet' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.unet'.\n","  torch.save(model.unet.state_dict(), f\"{save_dir}/unet.pth\")\n","/content/FontDiffusion/train.py:254: FutureWarning: Accessing config attribute `style_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'style_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.style_encoder'.\n","  torch.save(model.style_encoder.state_dict(), f\"{save_dir}/style_encoder.pth\")\n","/content/FontDiffusion/train.py:255: FutureWarning: Accessing config attribute `content_encoder` directly via 'FontDiffuserModel' object attribute is deprecated. Please access 'content_encoder' over 'FontDiffuserModel's config object instead, e.g. 'unet.config.content_encoder'.\n","  torch.save(model.content_encoder.state_dict(), f\"{save_dir}/content_encoder.pth\")\n","Save the checkpoint on global step 50\n","Steps: 100% 100/100 [04:56<00:00,  2.92s/it, lr=1e-5, step_loss=0.663]Save the checkpoint on global step 100\n","Steps: 100% 100/100 [05:07<00:00,  2.92s/it, lr=1e-5, step_loss=0.676]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚¢ø\u001b[0m updating run metadata (0.0s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£ª\u001b[0m updating run metadata (0.0s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£Ω\u001b[0m updating run metadata (0.0s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£æ\u001b[0m updating run metadata (0.0s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178m‚£∑\u001b[0m uploading history steps 99-99, summary, console lines 17-18 (0.1s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_loss ‚ñÑ‚ñá‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÇ‚ñá‚ñÉ‚ñÖ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÇ\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.66958\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mnorthern-field-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_2/runs/me0n9ti7\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at: \u001b[34m\u001b[4mhttps://wandb.ai/dungngocpham171-university-of-science/FontDiffuser_training_phase_2\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20251230_095937-me0n9ti7/logs\u001b[0m\n","Steps: 100% 100/100 [05:08<00:00,  3.08s/it, lr=1e-5, step_loss=0.676]\n"]}],"execution_count":20},{"cell_type":"code","source":"import os\nimport zipfile\nfrom pathlib import Path\nfrom typing import List\ndef find_result_folders(base_path: Path, pattern_name: str) -> List[Path]:\n    return [p for p in base_path.glob(pattern_name) if p.is_dir()]\n\ndef zip_folder(folder_path: Path, output_base_path: Path) -> bool:\n    folder_name = folder_path.name\n    zip_path = output_base_path / f\"{folder_name}.zip\"\n    try:\n        print(f\"   -> Zipping folder: {folder_name}...\")\n        with zipfile.ZipFile(zip_path, mode=\"w\", compression=zipfile.ZIP_DEFLATED) as zipf:\n            for file_path in folder_path.rglob(\"*\"):\n                if file_path.is_file():\n                    arcname = file_path.relative_to(folder_path.parent)\n                    zipf.write(file_path, arcname)\n        print(f\"   ‚úÖ Created ZIP: {zip_path.name}\")\n        return True\n    except Exception as exc:\n        print(f\"   ‚ùå Failed to zip {folder_name}: {exc}\")\n        return False\n\ndef zip_stats_results_folders(output_base_path: str, pattern_name: str) -> None:\n    base = Path(output_base_path)\n    base.mkdir(parents=True, exist_ok=True)\n    result_folders = find_result_folders(base, pattern_name)\n    if not result_folders:\n        print(f\"‚ö†Ô∏è No folders matching '*dataset' found in '{output_base_path}'.\")\n        return\n    print(f\"üîç Found {len(result_folders)} result folder(s) to zip.\")\n    successful = sum(1 for folder in result_folders if zip_folder(folder, base))\n    print(f\"\\n‚úÖ DONE! Successfully zipped {successful} out of {len(result_folders)} folder(s).\")\n\nif __name__ == \"__main__\":\n    try:\n        output_root = os.getenv(\"OUTPUT_PATH\") or globals().get(\"OUTPUT_PATH\")\n        if not output_root:\n            raise ValueError(\"OUTPUT_PATH not defined\")\n        zip_stats_results_folders(\n            output_base_path=OUTPUT_PATH,\n            pattern_name=\"outputs/FontDiffuser/global_step_50\")\n    except Exception as e:\n        print(f\"‚ùå An error occurred: {e}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-28T10:30:43.330470Z","iopub.status.idle":"2025-12-28T10:30:43.330877Z","shell.execute_reply":"2025-12-28T10:30:43.330691Z","shell.execute_reply.started":"2025-12-28T10:30:43.330672Z"},"id":"kTz9WZ9ylBZx","outputId":"64057e8e-fd1a-496d-c080-f862d1241f20","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":["üîç Found 1 result folder(s) to zip.\n","   -> Zipping folder: global_step_50...\n","   ‚úÖ Created ZIP: global_step_50.zip\n","\n","‚úÖ DONE! Successfully zipped 1 out of 1 folder(s).\n"]}],"execution_count":22},{"cell_type":"code","source":"import json\nfrom pathlib import Path\nfrom typing import Dict\n\n# Import Hugging Face libraries\nfrom datasets import load_dataset, Dataset, Features, Value, Image\n\ndef generate_metadata_from_results(output_dir: Path, results_filename: str = \"results.json\") -> Path:\n    \"\"\"\n    Generates a metadata.jsonl file assuming the generation script was run\n    from the parent directory of `output_dir`.\n\n    This is designed for a common Colab/Kaggle workflow where scripts are run\n    from `/content/` and outputs are saved to `/content/my_dataset/`.\n\n    Args:\n        output_dir (Path): The root directory of the generated output\n                           (e.g., Path(\"/content/my_dataset\")).\n        results_filename (str): The name of the JSON file containing generation logs.\n\n    Returns:\n        Path: The path to the newly created metadata.jsonl file.\n    \"\"\"\n    results_file = output_dir / results_filename\n    metadata_file = output_dir / \"metadata.jsonl\"\n\n    # The directory from which the original script was run (e.g., /content/)\n    execution_context_dir = output_dir.parent\n\n    print(f\"Reading generation data from: {results_file}\")\n    if not results_file.is_file():\n        raise FileNotFoundError(f\"The results file was not found at {results_file}\")\n\n    with results_file.open(\"r\", encoding=\"utf-8\") as f:\n        results_data = json.load(f)\n\n    print(f\"Generating metadata file at: {metadata_file}\")\n    records_written = 0\n    with metadata_file.open(\"w\", encoding=\"utf-8\") as f:\n        for gen_info in results_data.get(\"generations\", []):\n            try:\n                # Path from JSON, e.g., \"my_dataset/TargetImage.png/...\"\n                path_from_json = gen_info[\"output_path\"]\n\n                # --- THIS IS THE KEY LOGIC ---\n                # 1. Reconstruct the full, absolute path.\n                #    Combines the execution context with the relative path from the file.\n                #    e.g., Path(\"/content\") + \"my_dataset/...\" -> Path(\"/content/my_dataset/...\")\n                absolute_path = (execution_context_dir / path_from_json).resolve()\n\n                # 2. Make the path relative to the dataset's root directory.\n                #    This makes the final metadata portable.\n                #    e.g., Path(\"/content/my_dataset/...\").relative_to(Path(\"/content/my_dataset\"))\n                #          -> \"TargetImage.png/...\"\n                relative_path_for_metadata = absolute_path.relative_to(output_dir)\n                # ---------------------------\n\n                metadata_entry = {\n                    \"file_name\": str(relative_path_for_metadata),\n                    \"character\": gen_info.get(\"character\", \"unknown\"),\n                    \"style\": gen_info.get(\"style\", \"unknown\"),\n                    \"font\": gen_info.get(\"font\", \"unknown\"),\n                }\n                f.write(json.dumps(metadata_entry) + \"\\n\")\n                records_written += 1\n            except (KeyError, ValueError) as e:\n                print(f\"Skipping a record due to an error: {e}\")\n\n    print(f\"‚úÖ Metadata generation complete. {records_written} records written.\")\n    return metadata_file\n\n# Note: The `load_dataset_from_metadata` function you provided in the last\n# prompt does not need to be changed. It is already robust and will work\n# perfectly with the output of this new generation function.\n\n\ndef load_dataset_from_metadata(metadata_path: Path, base_data_dir: Path) -> Dataset:\n    \"\"\"\n    Loads a Hugging Face Dataset using a metadata.jsonl file.\n\n    This function reads the metadata, resolves the relative image paths,\n    and loads the images into a structured Dataset object.\n\n    Args:\n        metadata_path (Path): Path to the generated metadata.jsonl file.\n        base_data_dir (Path): The root directory where the image files are located.\n                              This is used to resolve the relative paths in the metadata.\n\n    Returns:\n        Dataset: The loaded and structured Hugging Face Dataset.\n    \"\"\"\n    print(f\"Loading dataset using metadata: {metadata_path}\")\n    if not metadata_path.is_file():\n        raise FileNotFoundError(f\"The metadata file was not found at {metadata_path}\")\n\n    # 1. Load the JSON data first. This will create a dataset with a 'file_name' column.\n    dataset = load_dataset(\"json\", data_files=str(metadata_path), split=\"train\")\n\n    # 2. Define a function to resolve the relative file_name to a full path for loading.\n    #    The `datasets.Image()` feature needs a complete path to open the file.\n    def resolve_image_path(example: Dict) -> Dict:\n        # Use pathlib's `/` operator for clean path joining\n        example[\"image\"] = str(base_data_dir / example[\"file_name\"])\n        return example\n\n    print(\"Resolving image paths...\")\n    dataset = dataset.map(resolve_image_path)\n\n    # 3. Cast the 'image' column (which now contains full paths) to the Image feature type.\n    #    This tells the library to actually load the pixels from the paths.\n    print(\"Casting paths to images...\")\n    dataset = dataset.cast_column(\"image\", Image())\n\n    print(\"‚úÖ Dataset loaded successfully with image data.\")\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2025-12-28T10:30:43.331996Z","iopub.status.idle":"2025-12-28T10:30:43.332314Z","shell.execute_reply":"2025-12-28T10:30:43.332159Z","shell.execute_reply.started":"2025-12-28T10:30:43.332143Z"},"id":"SIH9c0l-mRqB","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\nfrom datasets import load_dataset, Dataset, Features, Value, Image # Ensure all imports\nimport json # Ensure json is imported\n\n# (Assume you have already defined `load_dataset_from_metadata` from the previous prompt)\n\n# --- Step 1: Define your paths based on the Colab environment ---\n# This makes the code clean and easy to read.\nROOT_PATH = Path(\"/content/\")\nOUTPUT_DIR_NAME = \"my_dataset\"\nFULL_OUTPUT_PATH = ROOT_PATH / OUTPUT_DIR_NAME\n\n# --- Step 2: Run your generation script from the root path ---\n# (This is a placeholder for your actual generation command)\n#\n# !python FontDiffusion/sample_batch.py \\\n#     --output_dir {OUTPUT_DIR_NAME} \\\n#     ... other args ...\n#\n# This will create the directory /content/my_dataset/ and populate it.\n\n# --- Step 3: Generate the metadata file ---\n# The function now correctly understands the path structure.\ntry:\n    print(f\"Starting metadata generation for directory: {FULL_OUTPUT_PATH}\")\n    generated_metadata_path = generate_metadata_from_results(\n        output_dir=FULL_OUTPUT_PATH\n    )\nexcept FileNotFoundError as e:\n    print(f\"‚ùå ERROR: {e}\")\n    print(\"Please ensure your generation script has run successfully and created a results.json file.\")\n\n# --- Step 4: Load the structured dataset using the metadata ---\n# This part is unchanged and works as intended.\ntry:\n    my_structured_dataset = load_dataset_from_metadata(\n        metadata_path=generated_metadata_path,\n        base_data_dir=FULL_OUTPUT_PATH\n    )\n\n    # --- Step 5: Verify and use your dataset ---\n    print(\"\\n\" + \"=\"*50)\n    print(\"  ‚úÖ DATASET LOADED SUCCESSFULLY\")\n    print(\"=\"*50)\n    print(my_structured_dataset)\n\n    print(\"\\n--- Example Record ---\")\n    if len(my_structured_dataset) > 0:\n        example = my_structured_dataset[0]\n        print(f\"Character: {example['character']}\")\n        print(f\"Style: {example['style']}\")\n        print(f\"Font: {example['font']}\")\n        print(\"Image object:\", example['image'])\n\n        # In Colab/Jupyter, this will render the image directly in the output\n        display(example['image'])\n    else:\n        print(\"Dataset is empty. Check for errors during metadata generation.\")\n\nexcept (NameError, FileNotFoundError) as e:\n    print(f\"‚ùå ERROR: Could not load the dataset. Did the metadata generation fail? Details: {e}\")","metadata":{"id":"NfAXWsvdQ_iv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install the library if you haven't already\nfrom huggingface_hub import HfApi, notebook_login\n\n# 1. Login to Hugging Face\n# This will use the token from your Kaggle/Colab secrets\nnotebook_login()\n\n# 2. Define your local path and the repository ID on the Hub\n# This is the directory containing ContentImage/, TargetImage/, etc.\nlocal_output_dir = Path(OUTPUT_PATH) / \"my_dataset\"\nrepo_id = \"dzungpham/font-diffusion-generated-data\" # Choose a name for your repo\n\n# 3. Create the repository and upload the folder\napi = HfApi()\n\nprint(f\"Creating repository '{repo_id}' on the Hub...\")\napi.create_repo(\n    repo_id=repo_id,\n    repo_type=\"dataset\", # Can be 'dataset' or 'model'\n    private=True,      # Set to False if you want it public\n    exist_ok=True      # Don't fail if it already exists\n)\n\nprint(f\"Uploading folder '{local_output_dir}' to '{repo_id}'...\")\n# This command will recursively upload everything, preserving the structure.\napi.upload_folder(\n    folder_path=local_output_dir,\n    repo_id=repo_id,\n    repo_type=\"dataset\"\n)\n\nprint(\"‚úÖ Upload complete! Your file tree is now on the Hub.\")","metadata":{"id":"gpj8EL50PA7q"},"outputs":[],"execution_count":null}]}